{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "d230cf8de72e867e5717d0f5cf531d71189c7e5bd77bc2a42cd05122b296a561"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "##  Lenet5 Models -JackieN \n",
    "This File Produces A number of Lenet5 Models and Predictions based on varying degrees of cleaned Train data.\n",
    "\n",
    "Based on https://medium.com/@mgazar/lenet-5-in-9-lines-of-code-using-keras-ac99294c8086 and \n",
    "\n",
    "https://deepai.org/publication/towards-good-practices-on-building-effective-cnn-baseline-model-for-person-re-identification#:~:text=The%20last%20key%20practice%20is%20to%20train%20CNN,based%20on%20the%20adaptive%20estimates%20of%20lower-order%20moments.\n",
    "\n",
    "The best score produced from the model using the clean data with all outliers removed is: 3.23581  \n",
    "\n",
    "Placing at position 72 on the leaderboard\n",
    "\n",
    "![](https://i.imgur.com/JwXgz3C.jpg)\n",
    " "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the utils path to point to the utils directory locally\n",
    "UTILS_PATH = \"c:/Users/mspuc/OneDrive/Berkeley/A - W207/Final/blackboxes/utils\"\n",
    "\n",
    "import os, sys\n",
    "sys.path.append(UTILS_PATH)\n",
    "from load_models import LoadTrainModels\n",
    "from predict_models import PredictModels\n",
    "#from utils.predict_model import *\n",
    "#from utils.predict_model import load_models, transform_data\n",
    "import imp\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model dir: C:/data/Jackie_Lenet5/\nPickle dir: C:/Data/CleanTrain/\n"
     ]
    }
   ],
   "source": [
    "### this is gold right here.\n",
    "#import imp\n",
    "#imp.reload()\n",
    "\n",
    "file_path = \"C:/Data/CleanTrain/\"\n",
    "trainer = LoadTrainModels(\"C:/data/Jackie_Lenet5\", file_path)\n",
    "\n",
    "trainer.print_paths()"
   ]
  },
  {
   "source": [
    "### For every version of a clean Train file in a given path, create and save a model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.2144e-04 - mae: 0.0085 - mse: 1.2144e-04 - val_loss: 2.9721e-04 - val_mae: 0.0116 - val_mse: 2.9721e-04\n",
      "\n",
      "Epoch 00123: val_mae did not improve from 0.01044\n",
      "Epoch 124/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 1.2686e-04 - mae: 0.0089 - mse: 1.2686e-04 - val_loss: 2.8982e-04 - val_mae: 0.0115 - val_mse: 2.8982e-04\n",
      "\n",
      "Epoch 00124: val_mae did not improve from 0.01044\n",
      "Epoch 125/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 1.0516e-04 - mae: 0.0078 - mse: 1.0516e-04 - val_loss: 3.1923e-04 - val_mae: 0.0124 - val_mse: 3.1923e-04\n",
      "\n",
      "Epoch 00125: val_mae did not improve from 0.01044\n",
      "Epoch 126/300\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 8.9481e-05 - mae: 0.0070 - mse: 8.9481e-05 - val_loss: 3.2857e-04 - val_mae: 0.0141 - val_mse: 3.2857e-04\n",
      "\n",
      "Epoch 00126: val_mae did not improve from 0.01044\n",
      "Epoch 127/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 1.6323e-04 - mae: 0.0101 - mse: 1.6323e-04 - val_loss: 2.8518e-04 - val_mae: 0.0114 - val_mse: 2.8518e-04\n",
      "\n",
      "Epoch 00127: val_mae did not improve from 0.01044\n",
      "Epoch 128/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 9.8569e-05 - mae: 0.0077 - mse: 9.8569e-05 - val_loss: 3.2875e-04 - val_mae: 0.0118 - val_mse: 3.2875e-04\n",
      "\n",
      "Epoch 00128: val_mae did not improve from 0.01044\n",
      "Epoch 129/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 8.2633e-05 - mae: 0.0067 - mse: 8.2633e-05 - val_loss: 3.2966e-04 - val_mae: 0.0137 - val_mse: 3.2966e-04\n",
      "\n",
      "Epoch 00129: val_mae did not improve from 0.01044\n",
      "Epoch 130/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 9.2384e-05 - mae: 0.0076 - mse: 9.2384e-05 - val_loss: 2.5769e-04 - val_mae: 0.0106 - val_mse: 2.5769e-04\n",
      "\n",
      "Epoch 00130: val_mae did not improve from 0.01044\n",
      "Epoch 131/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 1.2299e-04 - mae: 0.0088 - mse: 1.2299e-04 - val_loss: 2.8243e-04 - val_mae: 0.0110 - val_mse: 2.8243e-04\n",
      "\n",
      "Epoch 00131: val_mae did not improve from 0.01044\n",
      "Epoch 132/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 9.4087e-05 - mae: 0.0074 - mse: 9.4087e-05 - val_loss: 3.8815e-04 - val_mae: 0.0127 - val_mse: 3.8815e-04\n",
      "\n",
      "Epoch 00132: val_mae did not improve from 0.01044\n",
      "Epoch 133/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 1.1682e-04 - mae: 0.0082 - mse: 1.1682e-04 - val_loss: 3.3522e-04 - val_mae: 0.0150 - val_mse: 3.3522e-04\n",
      "\n",
      "Epoch 00133: val_mae did not improve from 0.01044\n",
      "Epoch 134/300\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 1.6061e-04 - mae: 0.0102 - mse: 1.6061e-04 - val_loss: 2.7847e-04 - val_mae: 0.0114 - val_mse: 2.7847e-04\n",
      "\n",
      "Epoch 00134: val_mae did not improve from 0.01044\n",
      "Epoch 135/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 8.2811e-05 - mae: 0.0067 - mse: 8.2811e-05 - val_loss: 3.0687e-04 - val_mae: 0.0123 - val_mse: 3.0687e-04\n",
      "\n",
      "Epoch 00135: val_mae did not improve from 0.01044\n",
      "Epoch 136/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 1.6897e-04 - mae: 0.0106 - mse: 1.6897e-04 - val_loss: 3.0061e-04 - val_mae: 0.0113 - val_mse: 3.0061e-04\n",
      "\n",
      "Epoch 00136: val_mae did not improve from 0.01044\n",
      "Epoch 137/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 7.9000e-05 - mae: 0.0068 - mse: 7.9000e-05 - val_loss: 4.4815e-04 - val_mae: 0.0130 - val_mse: 4.4815e-04\n",
      "\n",
      "Epoch 00137: val_mae did not improve from 0.01044\n",
      "Epoch 138/300\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 9.2847e-05 - mae: 0.0069 - mse: 9.2847e-05 - val_loss: 2.7413e-04 - val_mae: 0.0112 - val_mse: 2.7413e-04\n",
      "\n",
      "Epoch 00138: val_mae did not improve from 0.01044\n",
      "Epoch 139/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 7.6451e-05 - mae: 0.0067 - mse: 7.6451e-05 - val_loss: 3.3698e-04 - val_mae: 0.0128 - val_mse: 3.3698e-04\n",
      "\n",
      "Epoch 00139: val_mae did not improve from 0.01044\n",
      "Epoch 140/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 1.0324e-04 - mae: 0.0078 - mse: 1.0324e-04 - val_loss: 3.5538e-04 - val_mae: 0.0131 - val_mse: 3.5538e-04\n",
      "\n",
      "Epoch 00140: val_mae did not improve from 0.01044\n",
      "Epoch 141/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 1.0888e-04 - mae: 0.0081 - mse: 1.0888e-04 - val_loss: 3.0412e-04 - val_mae: 0.0122 - val_mse: 3.0412e-04\n",
      "\n",
      "Epoch 00141: val_mae did not improve from 0.01044\n",
      "Epoch 142/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 8.2823e-05 - mae: 0.0071 - mse: 8.2823e-05 - val_loss: 2.8696e-04 - val_mae: 0.0120 - val_mse: 2.8696e-04\n",
      "\n",
      "Epoch 00142: val_mae did not improve from 0.01044\n",
      "Epoch 143/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 1.1072e-04 - mae: 0.0084 - mse: 1.1072e-04 - val_loss: 3.5633e-04 - val_mae: 0.0124 - val_mse: 3.5633e-04\n",
      "\n",
      "Epoch 00143: val_mae did not improve from 0.01044\n",
      "Epoch 144/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 9.9728e-05 - mae: 0.0077 - mse: 9.9728e-05 - val_loss: 2.7545e-04 - val_mae: 0.0121 - val_mse: 2.7545e-04\n",
      "\n",
      "Epoch 00144: val_mae did not improve from 0.01044\n",
      "Epoch 145/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 7.8435e-05 - mae: 0.0070 - mse: 7.8435e-05 - val_loss: 2.9017e-04 - val_mae: 0.0119 - val_mse: 2.9017e-04\n",
      "\n",
      "Epoch 00145: val_mae did not improve from 0.01044\n",
      "Epoch 146/300\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 6.7109e-05 - mae: 0.0063 - mse: 6.7109e-05 - val_loss: 3.2456e-04 - val_mae: 0.0113 - val_mse: 3.2456e-04\n",
      "\n",
      "Epoch 00146: val_mae did not improve from 0.01044\n",
      "Epoch 147/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 7.9808e-05 - mae: 0.0066 - mse: 7.9808e-05 - val_loss: 2.8570e-04 - val_mae: 0.0113 - val_mse: 2.8570e-04\n",
      "\n",
      "Epoch 00147: val_mae did not improve from 0.01044\n",
      "Epoch 148/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 7.0380e-05 - mae: 0.0063 - mse: 7.0380e-05 - val_loss: 3.5344e-04 - val_mae: 0.0142 - val_mse: 3.5344e-04\n",
      "\n",
      "Epoch 00148: val_mae did not improve from 0.01044\n",
      "Epoch 149/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 8.3976e-05 - mae: 0.0068 - mse: 8.3976e-05 - val_loss: 2.7229e-04 - val_mae: 0.0114 - val_mse: 2.7229e-04\n",
      "\n",
      "Epoch 00149: val_mae did not improve from 0.01044\n",
      "Epoch 150/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 1.5071e-04 - mae: 0.0097 - mse: 1.5071e-04 - val_loss: 2.6378e-04 - val_mae: 0.0109 - val_mse: 2.6378e-04\n",
      "\n",
      "Epoch 00150: val_mae did not improve from 0.01044\n",
      "Epoch 151/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 7.9863e-05 - mae: 0.0067 - mse: 7.9863e-05 - val_loss: 2.5771e-04 - val_mae: 0.0108 - val_mse: 2.5771e-04\n",
      "\n",
      "Epoch 00151: val_mae did not improve from 0.01044\n",
      "Epoch 152/300\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 9.9398e-05 - mae: 0.0081 - mse: 9.9398e-05 - val_loss: 2.4238e-04 - val_mae: 0.0106 - val_mse: 2.4238e-04\n",
      "\n",
      "Epoch 00152: val_mae did not improve from 0.01044\n",
      "Epoch 153/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 5.6612e-05 - mae: 0.0056 - mse: 5.6612e-05 - val_loss: 3.0126e-04 - val_mae: 0.0115 - val_mse: 3.0126e-04\n",
      "\n",
      "Epoch 00153: val_mae did not improve from 0.01044\n",
      "Epoch 154/300\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 9.6649e-05 - mae: 0.0075 - mse: 9.6649e-05 - val_loss: 3.0288e-04 - val_mae: 0.0117 - val_mse: 3.0288e-04\n",
      "\n",
      "Epoch 00154: val_mae did not improve from 0.01044\n",
      "Epoch 155/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 9.4565e-05 - mae: 0.0077 - mse: 9.4565e-05 - val_loss: 3.0008e-04 - val_mae: 0.0112 - val_mse: 3.0008e-04\n",
      "\n",
      "Epoch 00155: val_mae did not improve from 0.01044\n",
      "Epoch 156/300\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 6.2142e-05 - mae: 0.0058 - mse: 6.2142e-05 - val_loss: 3.4592e-04 - val_mae: 0.0149 - val_mse: 3.4592e-04\n",
      "\n",
      "Epoch 00156: val_mae did not improve from 0.01044\n",
      "Epoch 157/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 1.1893e-04 - mae: 0.0089 - mse: 1.1893e-04 - val_loss: 3.2838e-04 - val_mae: 0.0143 - val_mse: 3.2838e-04\n",
      "\n",
      "Epoch 00157: val_mae did not improve from 0.01044\n",
      "Epoch 158/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 1.1497e-04 - mae: 0.0087 - mse: 1.1497e-04 - val_loss: 3.0422e-04 - val_mae: 0.0109 - val_mse: 3.0422e-04\n",
      "\n",
      "Epoch 00158: val_mae did not improve from 0.01044\n",
      "Epoch 159/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 7.7762e-05 - mae: 0.0065 - mse: 7.7762e-05 - val_loss: 2.8845e-04 - val_mae: 0.0114 - val_mse: 2.8845e-04\n",
      "\n",
      "Epoch 00159: val_mae did not improve from 0.01044\n",
      "Epoch 160/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 9.0087e-05 - mae: 0.0073 - mse: 9.0087e-05 - val_loss: 3.0505e-04 - val_mae: 0.0125 - val_mse: 3.0505e-04\n",
      "\n",
      "Epoch 00160: val_mae did not improve from 0.01044\n",
      "Epoch 161/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 6.6962e-05 - mae: 0.0063 - mse: 6.6962e-05 - val_loss: 2.8324e-04 - val_mae: 0.0107 - val_mse: 2.8324e-04\n",
      "\n",
      "Epoch 00161: val_mae did not improve from 0.01044\n",
      "Epoch 162/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 7.1969e-05 - mae: 0.0065 - mse: 7.1969e-05 - val_loss: 3.5132e-04 - val_mae: 0.0153 - val_mse: 3.5132e-04\n",
      "\n",
      "Epoch 00162: val_mae did not improve from 0.01044\n",
      "Epoch 163/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 1.7197e-04 - mae: 0.0110 - mse: 1.7197e-04 - val_loss: 3.2933e-04 - val_mae: 0.0129 - val_mse: 3.2933e-04\n",
      "\n",
      "Epoch 00163: val_mae did not improve from 0.01044\n",
      "Epoch 164/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 7.4457e-05 - mae: 0.0066 - mse: 7.4457e-05 - val_loss: 2.8883e-04 - val_mae: 0.0119 - val_mse: 2.8883e-04\n",
      "\n",
      "Epoch 00164: val_mae did not improve from 0.01044\n",
      "Epoch 165/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 1.2431e-04 - mae: 0.0089 - mse: 1.2431e-04 - val_loss: 2.5066e-04 - val_mae: 0.0106 - val_mse: 2.5066e-04\n",
      "\n",
      "Epoch 00165: val_mae did not improve from 0.01044\n",
      "Epoch 166/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 6.1737e-05 - mae: 0.0061 - mse: 6.1737e-05 - val_loss: 3.4170e-04 - val_mae: 0.0133 - val_mse: 3.4170e-04\n",
      "\n",
      "Epoch 00166: val_mae did not improve from 0.01044\n",
      "Epoch 167/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 9.5367e-05 - mae: 0.0074 - mse: 9.5367e-05 - val_loss: 2.8618e-04 - val_mae: 0.0118 - val_mse: 2.8618e-04\n",
      "\n",
      "Epoch 00167: val_mae did not improve from 0.01044\n",
      "Epoch 168/300\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 6.0182e-05 - mae: 0.0057 - mse: 6.0182e-05 - val_loss: 2.7050e-04 - val_mae: 0.0101 - val_mse: 2.7050e-04\n",
      "\n",
      "Epoch 00168: val_mae improved from 0.01044 to 0.01009, saving model to C:/data/Jackie_Lenet5\\clean_w_outliers_Lenet5.h5\n",
      "Epoch 169/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 4.2628e-05 - mae: 0.0046 - mse: 4.2628e-05 - val_loss: 2.9397e-04 - val_mae: 0.0130 - val_mse: 2.9397e-04\n",
      "\n",
      "Epoch 00169: val_mae did not improve from 0.01009\n",
      "Epoch 170/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 5.9740e-05 - mae: 0.0058 - mse: 5.9740e-05 - val_loss: 3.6441e-04 - val_mae: 0.0119 - val_mse: 3.6441e-04\n",
      "\n",
      "Epoch 00170: val_mae did not improve from 0.01009\n",
      "Epoch 171/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 6.9089e-05 - mae: 0.0062 - mse: 6.9089e-05 - val_loss: 2.5758e-04 - val_mae: 0.0108 - val_mse: 2.5758e-04\n",
      "\n",
      "Epoch 00171: val_mae did not improve from 0.01009\n",
      "Epoch 172/300\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 6.9963e-05 - mae: 0.0064 - mse: 6.9963e-05 - val_loss: 6.2271e-04 - val_mae: 0.0216 - val_mse: 6.2271e-04\n",
      "\n",
      "Epoch 00172: val_mae did not improve from 0.01009\n",
      "Epoch 173/300\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 2.2912e-04 - mae: 0.0118 - mse: 2.2912e-04 - val_loss: 2.7208e-04 - val_mae: 0.0105 - val_mse: 2.7208e-04\n",
      "\n",
      "Epoch 00173: val_mae did not improve from 0.01009\n",
      "Epoch 174/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 7.8355e-05 - mae: 0.0070 - mse: 7.8355e-05 - val_loss: 2.5454e-04 - val_mae: 0.0104 - val_mse: 2.5454e-04\n",
      "\n",
      "Epoch 00174: val_mae did not improve from 0.01009\n",
      "Epoch 175/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 5.7087e-05 - mae: 0.0059 - mse: 5.7087e-05 - val_loss: 2.4556e-04 - val_mae: 0.0101 - val_mse: 2.4556e-04\n",
      "\n",
      "Epoch 00175: val_mae did not improve from 0.01009\n",
      "Epoch 176/300\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 4.8094e-05 - mae: 0.0052 - mse: 4.8094e-05 - val_loss: 3.0000e-04 - val_mae: 0.0116 - val_mse: 3.0000e-04\n",
      "\n",
      "Epoch 00176: val_mae did not improve from 0.01009\n",
      "Epoch 177/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 7.5589e-05 - mae: 0.0064 - mse: 7.5589e-05 - val_loss: 2.3291e-04 - val_mae: 0.0101 - val_mse: 2.3291e-04\n",
      "\n",
      "Epoch 00177: val_mae did not improve from 0.01009\n",
      "Epoch 178/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 5.2636e-05 - mae: 0.0055 - mse: 5.2636e-05 - val_loss: 2.5321e-04 - val_mae: 0.0105 - val_mse: 2.5321e-04\n",
      "\n",
      "Epoch 00178: val_mae did not improve from 0.01009\n",
      "Epoch 179/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 5.0053e-05 - mae: 0.0051 - mse: 5.0053e-05 - val_loss: 2.4401e-04 - val_mae: 0.0104 - val_mse: 2.4401e-04\n",
      "\n",
      "Epoch 00179: val_mae did not improve from 0.01009\n",
      "Epoch 180/300\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 4.9076e-05 - mae: 0.0052 - mse: 4.9076e-05 - val_loss: 2.4784e-04 - val_mae: 0.0099 - val_mse: 2.4784e-04\n",
      "\n",
      "Epoch 00180: val_mae improved from 0.01009 to 0.00986, saving model to C:/data/Jackie_Lenet5\\clean_w_outliers_Lenet5.h5\n",
      "Epoch 181/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 6.2673e-05 - mae: 0.0062 - mse: 6.2673e-05 - val_loss: 2.5178e-04 - val_mae: 0.0103 - val_mse: 2.5178e-04\n",
      "\n",
      "Epoch 00181: val_mae did not improve from 0.00986\n",
      "Epoch 182/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 5.6227e-05 - mae: 0.0056 - mse: 5.6227e-05 - val_loss: 2.9694e-04 - val_mae: 0.0125 - val_mse: 2.9694e-04\n",
      "\n",
      "Epoch 00182: val_mae did not improve from 0.00986\n",
      "Epoch 183/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 9.8055e-05 - mae: 0.0082 - mse: 9.8055e-05 - val_loss: 3.0221e-04 - val_mae: 0.0112 - val_mse: 3.0221e-04\n",
      "\n",
      "Epoch 00183: val_mae did not improve from 0.00986\n",
      "Epoch 184/300\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 6.1765e-05 - mae: 0.0057 - mse: 6.1765e-05 - val_loss: 2.7306e-04 - val_mae: 0.0110 - val_mse: 2.7306e-04\n",
      "\n",
      "Epoch 00184: val_mae did not improve from 0.00986\n",
      "Epoch 185/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 9.1138e-05 - mae: 0.0075 - mse: 9.1138e-05 - val_loss: 2.8290e-04 - val_mae: 0.0108 - val_mse: 2.8290e-04\n",
      "\n",
      "Epoch 00185: val_mae did not improve from 0.00986\n",
      "Epoch 186/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 6.9043e-05 - mae: 0.0065 - mse: 6.9043e-05 - val_loss: 2.9038e-04 - val_mae: 0.0124 - val_mse: 2.9038e-04\n",
      "\n",
      "Epoch 00186: val_mae did not improve from 0.00986\n",
      "Epoch 187/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 8.1739e-05 - mae: 0.0072 - mse: 8.1739e-05 - val_loss: 2.6494e-04 - val_mae: 0.0113 - val_mse: 2.6494e-04\n",
      "\n",
      "Epoch 00187: val_mae did not improve from 0.00986\n",
      "Epoch 188/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 5.7294e-05 - mae: 0.0059 - mse: 5.7294e-05 - val_loss: 2.7572e-04 - val_mae: 0.0112 - val_mse: 2.7572e-04\n",
      "\n",
      "Epoch 00188: val_mae did not improve from 0.00986\n",
      "Epoch 189/300\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 6.4904e-05 - mae: 0.0061 - mse: 6.4904e-05 - val_loss: 2.9400e-04 - val_mae: 0.0128 - val_mse: 2.9400e-04\n",
      "\n",
      "Epoch 00189: val_mae did not improve from 0.00986\n",
      "Epoch 190/300\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 6.4800e-05 - mae: 0.0063 - mse: 6.4800e-05 - val_loss: 2.8148e-04 - val_mae: 0.0113 - val_mse: 2.8148e-04\n",
      "\n",
      "Epoch 00190: val_mae did not improve from 0.00986\n",
      "Epoch 191/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 7.7769e-05 - mae: 0.0071 - mse: 7.7769e-05 - val_loss: 3.2765e-04 - val_mae: 0.0130 - val_mse: 3.2765e-04\n",
      "\n",
      "Epoch 00191: val_mae did not improve from 0.00986\n",
      "Epoch 192/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 7.6059e-05 - mae: 0.0067 - mse: 7.6059e-05 - val_loss: 2.9165e-04 - val_mae: 0.0135 - val_mse: 2.9165e-04\n",
      "\n",
      "Epoch 00192: val_mae did not improve from 0.00986\n",
      "Epoch 193/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 6.9266e-05 - mae: 0.0066 - mse: 6.9266e-05 - val_loss: 2.7142e-04 - val_mae: 0.0113 - val_mse: 2.7142e-04\n",
      "\n",
      "Epoch 00193: val_mae did not improve from 0.00986\n",
      "Epoch 194/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 4.6953e-05 - mae: 0.0050 - mse: 4.6953e-05 - val_loss: 2.9362e-04 - val_mae: 0.0107 - val_mse: 2.9362e-04\n",
      "\n",
      "Epoch 00194: val_mae did not improve from 0.00986\n",
      "Epoch 195/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 5.1729e-05 - mae: 0.0053 - mse: 5.1729e-05 - val_loss: 2.8246e-04 - val_mae: 0.0125 - val_mse: 2.8246e-04\n",
      "\n",
      "Epoch 00195: val_mae did not improve from 0.00986\n",
      "Epoch 196/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 5.6580e-05 - mae: 0.0058 - mse: 5.6580e-05 - val_loss: 2.7568e-04 - val_mae: 0.0122 - val_mse: 2.7568e-04\n",
      "\n",
      "Epoch 00196: val_mae did not improve from 0.00986\n",
      "Epoch 197/300\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 8.9577e-05 - mae: 0.0078 - mse: 8.9577e-05 - val_loss: 2.5859e-04 - val_mae: 0.0107 - val_mse: 2.5859e-04\n",
      "\n",
      "Epoch 00197: val_mae did not improve from 0.00986\n",
      "Epoch 198/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 7.0066e-05 - mae: 0.0067 - mse: 7.0066e-05 - val_loss: 2.9239e-04 - val_mae: 0.0120 - val_mse: 2.9239e-04\n",
      "\n",
      "Epoch 00198: val_mae did not improve from 0.00986\n",
      "Epoch 199/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 6.5049e-05 - mae: 0.0061 - mse: 6.5049e-05 - val_loss: 2.5445e-04 - val_mae: 0.0112 - val_mse: 2.5445e-04\n",
      "\n",
      "Epoch 00199: val_mae did not improve from 0.00986\n",
      "Epoch 200/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 4.4886e-05 - mae: 0.0049 - mse: 4.4886e-05 - val_loss: 2.7376e-04 - val_mae: 0.0109 - val_mse: 2.7376e-04\n",
      "\n",
      "Epoch 00200: val_mae did not improve from 0.00986\n",
      "Epoch 201/300\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 5.1263e-05 - mae: 0.0055 - mse: 5.1263e-05 - val_loss: 2.4258e-04 - val_mae: 0.0099 - val_mse: 2.4258e-04\n",
      "\n",
      "Epoch 00201: val_mae did not improve from 0.00986\n",
      "Epoch 202/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 6.2889e-05 - mae: 0.0060 - mse: 6.2889e-05 - val_loss: 2.5996e-04 - val_mae: 0.0105 - val_mse: 2.5996e-04\n",
      "\n",
      "Epoch 00202: val_mae did not improve from 0.00986\n",
      "Epoch 203/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 4.8915e-05 - mae: 0.0054 - mse: 4.8915e-05 - val_loss: 2.5986e-04 - val_mae: 0.0109 - val_mse: 2.5986e-04\n",
      "\n",
      "Epoch 00203: val_mae did not improve from 0.00986\n",
      "Epoch 204/300\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 1.1473e-04 - mae: 0.0086 - mse: 1.1473e-04 - val_loss: 3.0210e-04 - val_mae: 0.0124 - val_mse: 3.0210e-04\n",
      "\n",
      "Epoch 00204: val_mae did not improve from 0.00986\n",
      "Epoch 205/300\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 5.3324e-05 - mae: 0.0055 - mse: 5.3324e-05 - val_loss: 2.8680e-04 - val_mae: 0.0115 - val_mse: 2.8680e-04\n",
      "\n",
      "Epoch 00205: val_mae did not improve from 0.00986\n",
      "Epoch 206/300\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 4.2699e-05 - mae: 0.0051 - mse: 4.2699e-05 - val_loss: 3.0297e-04 - val_mae: 0.0115 - val_mse: 3.0297e-04\n",
      "\n",
      "Epoch 00206: val_mae did not improve from 0.00986\n",
      "Epoch 207/300\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 8.6910e-05 - mae: 0.0075 - mse: 8.6910e-05 - val_loss: 2.4279e-04 - val_mae: 0.0104 - val_mse: 2.4279e-04\n",
      "\n",
      "Epoch 00207: val_mae did not improve from 0.00986\n",
      "Epoch 00207: early stopping\n",
      "Done fitting\n",
      "clean_w_outliers_Lenet5 model created and file saved for future use.\n",
      "End model and train\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#reload(LoadTrainModels)\n",
    "\n",
    "#Clean file path\n",
    "file_path = \"C:/Data/CleanTrain/\"\n",
    "#files = os.listdir(\"../CleanTrain\")\n",
    "files = os.listdir(file_path)\n",
    "\n",
    "#For every version of a cleaned Train file in CleanTrain directory, create and save a model\n",
    "for filename in files: \n",
    "    print(\"Opening file: \", filename)\n",
    "    clean_file = \"\".join((file_path,filename))\n",
    "    train_data = pickle.load( open( clean_file, \"rb\" ) )\n",
    "    train_data = train_data.drop(['level_0', 'check_sum', 'index'], axis=1,errors='ignore')\n",
    "    print(\"Train Shape:\", train_data.shape)\n",
    "\n",
    "    filename = str(filename).replace('.p', '').strip()\n",
    "    print(\"Begin model and train:\")\n",
    "    model_name = \"\".join((filename,\"_Lenet5\"))\n",
    "    print(\"Model name:\", model_name)\n",
    "    model, history = trainer.train_model(model_name, train_data, bright_and_dim = True,hoizontal_flip = True)\n",
    "    #model, history = trainer.train_lenet5(model_name, train_data,verbose = True)\n",
    "    print(\"End model and train\")    \n",
    "    print()"
   ]
  },
  {
   "source": [
    "### For every model file in a given path, predict using the model and save the predictions in CSV file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model dir: C:/Data/Jackie_Lenet5/\n",
      "Pickle dir: C:/data/Predictions/\n",
      "Working with:  clean_all_outliers_Lenet5\n",
      "Begin Predict\n",
      "Scaling 1783 images...\n",
      "Scaling of 1783 observations complete.\n",
      "Begining the split of Test\n",
      "got unique ids\n",
      "test subset shape: (1783, 4)\n",
      "End with the split of Test\n",
      "(27124, 4)\n",
      "before melt: (1783, 30)\n",
      "after melt: (53490, 3)\n",
      "after merge: (27124, 2)\n",
      "C:/data/Predictions/clean_all_outliers_Lenet5Pred.csv\n",
      "Predictions written \n",
      "End model and train\n",
      "\n",
      "Working with:  clean_duplicates_Lenet5\n",
      "Begin Predict\n",
      "Scaling 1783 images...\n",
      "Scaling of 1783 observations complete.\n",
      "Begining the split of Test\n",
      "got unique ids\n",
      "test subset shape: (1783, 4)\n",
      "End with the split of Test\n",
      "(27124, 4)\n",
      "before melt: (1783, 30)\n",
      "after melt: (53490, 3)\n",
      "after merge: (27124, 2)\n",
      "C:/data/Predictions/clean_duplicates_Lenet5Pred.csv\n",
      "Predictions written \n",
      "End model and train\n",
      "\n",
      "Working with:  clean_o_dups_Lenet5\n",
      "Begin Predict\n",
      "Scaling 1783 images...\n",
      "Scaling of 1783 observations complete.\n",
      "Begining the split of Test\n",
      "got unique ids\n",
      "test subset shape: (1783, 4)\n",
      "End with the split of Test\n",
      "(27124, 4)\n",
      "before melt: (1783, 30)\n",
      "after melt: (53490, 3)\n",
      "after merge: (27124, 2)\n",
      "C:/data/Predictions/clean_o_dups_Lenet5Pred.csv\n",
      "Predictions written \n",
      "End model and train\n",
      "\n",
      "Working with:  clean_o_outliers_Lenet5\n",
      "Begin Predict\n",
      "Scaling 1783 images...\n",
      "Scaling of 1783 observations complete.\n",
      "Begining the split of Test\n",
      "got unique ids\n",
      "test subset shape: (1783, 4)\n",
      "End with the split of Test\n",
      "(27124, 4)\n",
      "before melt: (1783, 30)\n",
      "after melt: (53490, 3)\n",
      "after merge: (27124, 2)\n",
      "C:/data/Predictions/clean_o_outliers_Lenet5Pred.csv\n",
      "Predictions written \n",
      "End model and train\n",
      "\n",
      "Working with:  clean_wo_dups_Lenet5\n",
      "Begin Predict\n",
      "Scaling 1783 images...\n",
      "Scaling of 1783 observations complete.\n",
      "Begining the split of Test\n",
      "got unique ids\n",
      "test subset shape: (1783, 4)\n",
      "End with the split of Test\n",
      "(27124, 4)\n",
      "before melt: (1783, 30)\n",
      "after melt: (53490, 3)\n",
      "after merge: (27124, 2)\n",
      "C:/data/Predictions/clean_wo_dups_Lenet5Pred.csv\n",
      "Predictions written \n",
      "End model and train\n",
      "\n",
      "Working with:  clean_w_dups_Lenet5\n",
      "Begin Predict\n",
      "Scaling 1783 images...\n",
      "Scaling of 1783 observations complete.\n",
      "Begining the split of Test\n",
      "got unique ids\n",
      "test subset shape: (1783, 4)\n",
      "End with the split of Test\n",
      "(27124, 4)\n",
      "before melt: (1783, 30)\n",
      "after melt: (53490, 3)\n",
      "after merge: (27124, 2)\n",
      "C:/data/Predictions/clean_w_dups_Lenet5Pred.csv\n",
      "Predictions written \n",
      "End model and train\n",
      "\n",
      "Working with:  clean_w_outliers_Lenet5\n",
      "Begin Predict\n",
      "Scaling 1783 images...\n",
      "Scaling of 1783 observations complete.\n",
      "Begining the split of Test\n",
      "got unique ids\n",
      "test subset shape: (1783, 4)\n",
      "End with the split of Test\n",
      "(27124, 4)\n",
      "before melt: (1783, 30)\n",
      "after melt: (53490, 3)\n",
      "after merge: (27124, 2)\n",
      "C:/data/Predictions/clean_w_outliers_Lenet5Pred.csv\n",
      "Predictions written \n",
      "End model and train\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Time to make some predictions\n",
    "\n",
    "id_lookup = pickle.load( open( \"../Data/id_lookup.p\", \"rb\" ) )\n",
    "test = pickle.load( open( \"../Data/test.p\", \"rb\" ) )\n",
    "\n",
    "#Using local paths as this is way faster...\n",
    "#Where the models are:\n",
    "file_path = \"C:/Data/Jackie_Lenet5\"\n",
    "#Where we want the predictions stored\n",
    "pred_path = \"C:/data/Predictions/\"\n",
    "\n",
    "predictor = PredictModels(file_path,pred_path , id_lookup)\n",
    "\n",
    "predictor.print_paths()\n",
    "\n",
    "files = os.listdir(file_path)\n",
    "#For every model in file_path, predict using the model and save the predictions in CSV file\n",
    "for filename in files:\n",
    "    if \".h5\" in filename:\n",
    "        base_name = filename[:-3]\n",
    "        model_json = ''.join((base_name,\".json\"))\n",
    "        print(\"Working with: \", base_name)\n",
    "        print(\"Begin Predict\")\n",
    "        Y= predictor.predict_lenet5(base_name, filename, model_json, test)\n",
    "        print(\"End model and train\")    \n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}