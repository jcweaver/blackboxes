{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "898O9xB_RdDX"
   },
   "source": [
    "# Initial Models\n",
    "\n",
    "These are basic SciKitLearn models to test whether our initial EDA and data cleaning approaches were leading anywhere. We were also hoping that we could use these to guide us in creating our eventual CNN models. Unfortunately, none of them performed well, though surprisingly KNN and DT regressors did perform better than we expected (though still poorly overall and in comparison to how CNN's perform). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pa1jlrmjRdDg"
   },
   "outputs": [],
   "source": [
    "# Import the necessary packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# Import SKLearn packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VxVZc4oaRdDh"
   },
   "outputs": [],
   "source": [
    "# Extract data \n",
    "\n",
    "IdLookupTable = pd.read_csv('data/IdLookupTable.csv', header=0, sep=',', quotechar='\"')\n",
    "\n",
    "SampleSubmission = pd.read_csv('data/SampleSubmission.csv', header=0, sep=',', quotechar='\"')\n",
    "\n",
    "# Load pickles\n",
    "\n",
    "train_data = pickle.load(open('data/train.p', 'rb'))\n",
    "\n",
    "test_data = pickle.load(open('data/test.p', 'rb'))\n",
    "\n",
    "clean_train = pickle.load(open('data/clean_train.p', 'rb'))\n",
    "\n",
    "clean_test = pickle.load(open('data/clean_test.p', 'rb'))\n",
    "\n",
    "augmented_data = pickle.load(open('data/augmented_train.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0jUIqFBuRdDh"
   },
   "outputs": [],
   "source": [
    "# Drop the extra columns\n",
    "\n",
    "train_data = train_data.drop(['index', 'check_sum'], axis=1)\n",
    "\n",
    "test_data = test_data.drop(['index', 'check_sum'], axis=1)\n",
    "\n",
    "clean_train = clean_train.drop(['level_0', 'check_sum'], axis=1)\n",
    "\n",
    "clean_test = clean_test.drop(['index', 'check_sum'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UH-AMEl-RdDi"
   },
   "source": [
    "## Function to Plot Images and Keypoints, and Score Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-jtq1b3CRdDj"
   },
   "outputs": [],
   "source": [
    "# def plot_img(data, indexes, columns=5, points=1):\n",
    "    \n",
    "#     # Determine size of image array\n",
    "#     plt.figure(figsize = (15,10))\n",
    "#     rows = len(indexes)//columns + 1\n",
    "    \n",
    "#     # Transform image strings into arrays\n",
    "#     for index, value in enumerate(indexes):\n",
    "#         #image_array = np.fromstring(data.loc[value, 'image'], sep = ' ').astype(int).reshape(96, 96)\n",
    "#         image_array = data.loc[value, 'image'].reshape(96, 96)\n",
    "#         # Optional add keypoints\n",
    "#         if points == 1:\n",
    "#             keypoints = train_data.loc[value].drop('image').values.astype(float).reshape(-1, 2)\n",
    "#         else:\n",
    "#             keypoints = []\n",
    "            \n",
    "#         # Plot figure matrix \n",
    "#         plt.subplot(rows, columns, index+1)\n",
    "#         plt.title('Training Sample: {}'.format(index+1))\n",
    "#         plt.axis('off')\n",
    "#         plt.imshow(image_array, cmap='gray')\n",
    "#         plt.tight_layout()\n",
    "#         # Add keypoints\n",
    "#         plt.scatter(keypoints[:, 0], keypoints[:, 1], s = 10, marker='.', c = 'red')\n",
    "#     plt.show() \n",
    "    \n",
    "#     return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9i1ti0ZPRdDj"
   },
   "outputs": [],
   "source": [
    "# plot_img(train_data, range(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Get Model Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yDhCSYTWRdDl"
   },
   "outputs": [],
   "source": [
    "def regression_results(y_true, y_pred):\n",
    "\n",
    "    # Regression metrics\n",
    "    explained_variance = metrics.explained_variance_score(y_true, y_pred)\n",
    "    mean_absolute_error = metrics.mean_absolute_error(y_true, y_pred) \n",
    "    mse = metrics.mean_squared_error(y_true, y_pred) \n",
    "    #mean_squared_log_error=metrics.mean_squared_log_error(y_true, y_pred)\n",
    "    median_absolute_error = metrics.median_absolute_error(y_true, y_pred)\n",
    "    r2 = metrics.r2_score(y_true, y_pred)\n",
    "\n",
    "    print('explained_variance: ', round(explained_variance,4))    \n",
    "    #print('mean_squared_log_error: ', round(mean_squared_log_error,4))\n",
    "    print('r2: ', round(r2,4))\n",
    "    print('MAE: ', round(mean_absolute_error,4))\n",
    "    print('MSE: ', round(mse,4))\n",
    "    print('RMSE: ', round(np.sqrt(mse),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Plot Consecutive Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZsLKf3m0RdDm"
   },
   "outputs": [],
   "source": [
    "def new_plot_img(images, labels, indexes, columns=5, points=1):\n",
    "\n",
    "    # Determine size of image array\n",
    "    plt.figure(figsize = (15,10))\n",
    "    rows = len(indexes)//columns + 1\n",
    "    \n",
    "    # Transform image strings into arrays\n",
    "    for index, value in enumerate(indexes):\n",
    "        image_array = images[value].reshape(96, 96)\n",
    "         # Optional add keypoints\n",
    "        if points == 1:\n",
    "            keypoints = labels[value].reshape(-1, 2)\n",
    "        else:\n",
    "            keypoints = []\n",
    "            \n",
    "        # Plot figure matrix \n",
    "        plt.subplot(rows, columns, index + 1)\n",
    "        plt.title('Training Sample: {}'.format(index+1))\n",
    "        plt.axis('off')\n",
    "        plt.imshow(image_array, cmap='gray')\n",
    "        plt.tight_layout()\n",
    "        # Add keypoints\n",
    "        if points == 1:\n",
    "            plt.scatter(keypoints[:, 0], keypoints[:, 1], s = 10, marker = '.', c = 'red')\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    plt.show() \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Plot Random Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fhUgHzDZRdDm"
   },
   "outputs": [],
   "source": [
    "def new_random_img(images, labels, indexes, columns = 5, points=1):\n",
    "    \n",
    "    rand_list = np.random.randint(len(images), size=len(indexes))\n",
    "    \n",
    "    # Determine size of image array\n",
    "    plt.figure(figsize = (15,10))\n",
    "    rows = len(indexes)//columns + 1\n",
    "    \n",
    "    # Transform image strings into arrays\n",
    "    for index, value in enumerate(list(rand_list)):\n",
    "        image_array = images[value].reshape(96, 96)\n",
    "         # Optional add keypoints\n",
    "        if points == 1:\n",
    "            keypoints = labels[value].reshape(-1, 2)\n",
    "        else:\n",
    "            keypoints = []\n",
    "            \n",
    "        # Plot figure matrix \n",
    "        plt.subplot(rows, columns, index + 1)\n",
    "        plt.title('Training Sample: {}'.format(index+1))\n",
    "        plt.axis('off')\n",
    "        plt.imshow(image_array, cmap = 'gray')\n",
    "        plt.tight_layout()\n",
    "        # Add keypoints\n",
    "        if points == 1:\n",
    "            plt.scatter(keypoints[:, 0], keypoints[:, 1], s = 10, marker = '.', c = 'red')\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    plt.show() \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sicSZEAJRdDn"
   },
   "source": [
    "## Prep Data\n",
    "\n",
    "Uses a simple mean fill function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xaqo-1Z-RdDn"
   },
   "outputs": [],
   "source": [
    "# Define feature and target columns\n",
    "feature_col, target_cols = 'image', list(train_data.drop('image', axis = 1).columns)\n",
    "\n",
    "# Fill NA's with mean of column\n",
    "train_data[target_cols] = train_data[target_cols].fillna(train_data[target_cols].mean())\n",
    "\n",
    "# Specify image dimensions\n",
    "width  = 96\n",
    "height = 96\n",
    "channels = 1\n",
    "\n",
    "# Create image array in numpy (reshaped)\n",
    "train_images = np.array(train_data[feature_col].tolist(), dtype = 'float')\n",
    "train_labels = train_data[target_cols].to_numpy()\n",
    "\n",
    "# (Optional) Normalize?\n",
    "normalized_train_images = train_images/255\n",
    "\n",
    "# Prepare train-test split\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(normalized_train_images, train_labels, test_size=0.1, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yKATSCg4RdDo",
    "outputId": "6c0e4a91-111b-45ed-e779-f14f5a921db1"
   },
   "outputs": [],
   "source": [
    "# Check shapes of train test datasets\n",
    "\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Dataset with Mean Fill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7RstvRXnRdDo"
   },
   "source": [
    "## Multiple Linear Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fpx2Y-FPRdDp"
   },
   "source": [
    "### Ordinary Least Squares\n",
    "\n",
    "The most basic multiple regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AoILO0J5RdDp"
   },
   "outputs": [],
   "source": [
    "# Fit model\n",
    "LR1 = LinearRegression()\n",
    "LR1_fit = LR1.fit(train_images, train_labels)\n",
    "\n",
    "# Predict\n",
    "LR1_predict = LR1_fit.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hyhTMle2RdDp",
    "outputId": "772233c9-2cb0-42cc-97f0-da5e9c4385d1"
   },
   "outputs": [],
   "source": [
    "# Get results\n",
    "regression_results(test_labels, LR1_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 587
    },
    "id": "U2HU_qptS4Vs",
    "outputId": "6ecd9775-e002-4d62-a9b1-23962e591dd5"
   },
   "outputs": [],
   "source": [
    "# Plot 20 random images\n",
    "new_random_img(test_images, LR1_predict, range(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hNV_QXELRdDq"
   },
   "source": [
    "### Ridge (L1) Regression\n",
    "\n",
    "Ridge regression is particularly useful to mitigate the problem of multicollinearity in linear regression, which commonly occurs in models with large numbers of parameters. In ridge regression, the cost function is altered by adding a penalty equivalent to square of the magnitude of the coefficients. Ridge regression shrinks the coefficients and it helps to reduce the model complexity and multi-collinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2kgNLU2VRdDq"
   },
   "outputs": [],
   "source": [
    "# Fit model\n",
    "LR2 = Ridge()\n",
    "LR2_fit = LR2.fit(train_images, train_labels)\n",
    "\n",
    "# Predict\n",
    "LR2_predict = LR2_fit.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S6j5UBXsRdDq",
    "outputId": "abe988eb-8a79-4eac-8bc7-2d6661e76f97"
   },
   "outputs": [],
   "source": [
    "# Get results\n",
    "regression_results(test_labels, LR2_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 587
    },
    "id": "fdwmMPg0T3KV",
    "outputId": "020feb5b-5457-4a36-bf50-a46bbbb97611"
   },
   "outputs": [],
   "source": [
    "# Plot 20 random images\n",
    "new_random_img(test_images, LR2_predict, range(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vZIYMIfRdDq"
   },
   "source": [
    "### Lasso (L2) Regression\n",
    "\n",
    "Lasso is short for least absolute shrinkage and selection operator. Instead of taking the square of the coefficients, magnitudes are taken into account. Lasso regression not only helps in reducing over-fitting but it also helps in feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xk-EESZdRdDq"
   },
   "outputs": [],
   "source": [
    "# Fit models\n",
    "LR3 = Lasso()\n",
    "LR3_fit = LR3.fit(train_images, train_labels)\n",
    "\n",
    "# Predict\n",
    "LR3_predict = LR3_fit.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iaioriZuRdDr",
    "outputId": "f868beb0-1589-411a-b2de-6d75378ac201"
   },
   "outputs": [],
   "source": [
    "# Get results\n",
    "regression_results(test_labels, LR3_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5NIm3fwRdDr"
   },
   "source": [
    "## **Decision Tree Regressor**\n",
    "\n",
    "A decision tree breaks down a dataset into smaller and smaller subsets while at the same time an associated decision tree is incrementally developed. The final result is a tree with decision nodes and leaf nodes. Though commonly used for classification problems, decision tree regression can also be achieved. When using a decision tree for classification problems, a metric like information gain can be used. To use a decision tree for regression however, an impurity metric that is suitable for continuous variables is used, such as weighted mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ACrvyJUxRdDr"
   },
   "outputs": [],
   "source": [
    "# Fit models\n",
    "DT1 = DecisionTreeRegressor()\n",
    "DT1_fit = DT1.fit(train_images, train_labels)\n",
    "\n",
    "# Predict\n",
    "DT1_predict = DT1_fit.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h_BPlIUPRdDr",
    "outputId": "139a0f7e-dc1d-4a86-ec3f-1d88f1b73c77"
   },
   "outputs": [],
   "source": [
    "# Get results\n",
    "regression_results(test_labels, DT1_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rwqbq45lRdDs"
   },
   "source": [
    "## **K-Nearest Neighbors Regressor**\n",
    "\n",
    "The k-nearest neighbors algorithm (k-NN) is a non-parametric classification method.  In both cases, the input consists of the k closest training examples in data set. The output depends on whether k-NN is used for classification or regression. In k-NN regression, the output is the property value for the object. This value is the average of the values of k nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K=5 Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IysFt6yURdDs"
   },
   "outputs": [],
   "source": [
    "# Train model with 5 nearest-neighbors\n",
    "KNR1 = KNeighborsRegressor(n_neighbors = 5)\n",
    "KNR1_fit = KNR1.fit(train_images, train_labels)\n",
    "\n",
    "# Predict\n",
    "KNR1_predict = KNR1_fit.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dopQWubURdDs",
    "outputId": "63dc1edf-3ed7-416d-db77-53a48df6de6f"
   },
   "outputs": [],
   "source": [
    "# Get regression results\n",
    "regression_results(test_labels, KNR1_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K=7 Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fbMNZGWURdDt"
   },
   "outputs": [],
   "source": [
    "# Train model with 7 nearest-neighbors\n",
    "KNR3 = KNeighborsRegressor(n_neighbors = 7)\n",
    "KNR3_fit = KNR3.fit(train_images, train_labels)\n",
    "\n",
    "# Predict\n",
    "KNR3_predict = KNR3_fit.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FpCJhOmYRdDt",
    "outputId": "a5558045-4df1-47a8-ebc0-b8644f52e883"
   },
   "outputs": [],
   "source": [
    "# Get results\n",
    "regression_results(test_labels, KNR3_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regression\n",
    "\n",
    "Random forests are a supervised learning technique using ensemble learning for classification or regression problems. The trees in random forests are run in parallel without any interaction while building. It constructs a multitude of decision trees during training and outputs the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Random forests are a meta-estimators (i.e. they combine the results of multiple predictions), aggregating many decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model using 5 estimators (limited without a GPU, SKLearn does not support GPU functionality)\n",
    "RF = RandomForestRegressor(n_estimators=5)\n",
    "RF_fit = RF.fit(train_images, train_labels)\n",
    "\n",
    "# Predict\n",
    "RF_predict = RF_fit.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get results\n",
    "regression_results(test_labels, RF_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wngte1orRdDu"
   },
   "source": [
    "# Dataset With Removed Duplicates and Mean Fill\n",
    "\n",
    "Still uses mean fill to fill in NA values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZOrnQKkjRdDu"
   },
   "outputs": [],
   "source": [
    "# Define feature and target columns\n",
    "feature_col, target_cols = 'image', list(clean_train.drop('image', axis = 1).columns)\n",
    "\n",
    "# Fill NA's with mean of column\n",
    "clean_train[target_cols] = clean_train[target_cols].fillna(clean_train[target_cols].mean())\n",
    "\n",
    "# Specify image dimensions\n",
    "width  = 96\n",
    "height = 96\n",
    "channels = 1\n",
    "\n",
    "# Create image array in numpy (reshaped)\n",
    "clean_train_images = np.array(clean_train[feature_col].tolist(), dtype = 'float')\n",
    "clean_train_labels = clean_train[target_cols].to_numpy()\n",
    "\n",
    "# (Optional) Normalize?\n",
    "normalized_clean_images = clean_train_images/255\n",
    "\n",
    "# Prepare train-test split\n",
    "train_images2, test_images2, train_labels2, test_labels2 = train_test_split(normalized_clean_images, clean_train_labels, test_size=0.1, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sd9pzIRPWM-R"
   },
   "source": [
    "## Multiple Linear Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uaO0xUGwRdDv"
   },
   "source": [
    "### Ordinary Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n_gn8oKORdDv"
   },
   "outputs": [],
   "source": [
    "# Train models\n",
    "LR_1 = LinearRegression()\n",
    "LR_1_fit = LR_1.fit(train_images2, train_labels2)\n",
    "\n",
    "# Predict\n",
    "LR_1_predict = LR_1.predict(test_images2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hf0fhB1YRdDv",
    "outputId": "a7742eff-7401-4f6a-b0d3-869cc8e581f3"
   },
   "outputs": [],
   "source": [
    "# Get results\n",
    "regression_results(test_labels2, LR_1_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-NRluFVRdDw"
   },
   "source": [
    "### Ridge (L1) Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ixQc6X-cRdDw"
   },
   "outputs": [],
   "source": [
    "# Train models\n",
    "LR_2 = Ridge()\n",
    "LR_2_fit = LR_2.fit(train_images2, train_labels2)\n",
    "\n",
    "# Predict\n",
    "LR_2_predict = LR_2.predict(test_images2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get results\n",
    "regression_results(test_labels2, LR_2_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hz6jbEdyRdDw"
   },
   "source": [
    "### Lasso (L2) Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "acPluoUbRdDw"
   },
   "outputs": [],
   "source": [
    "# Train models\n",
    "LR_3 = Lasso()\n",
    "LR_3_fit = LR_3.fit(train_images2, train_labels2)\n",
    "\n",
    "# Predict\n",
    "LR_3_predict = LR_3_fit.predict(test_images2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pMXCkIztRdDx",
    "outputId": "1af9ccca-12bf-44d3-86c6-1fa6694d65c9"
   },
   "outputs": [],
   "source": [
    "# Get results\n",
    "regression_results(test_labels2, LR_3_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3SX_zT6cRdDx"
   },
   "source": [
    "## Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1_6OkUrORdDx"
   },
   "outputs": [],
   "source": [
    "# Train models\n",
    "DT2 = DecisionTreeRegressor()\n",
    "DT2_fit = DT2.fit(train_images2, train_labels2)\n",
    "\n",
    "# Predict\n",
    "DT2_predict = DT2.predict(test_images2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YTluI0MkRdDx",
    "outputId": "7c65364f-0d07-473a-fb6c-597a913fc8d7"
   },
   "outputs": [],
   "source": [
    "# Get results\n",
    "regression_results(test_labels2, DT2_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QAGVAVjcRdDx"
   },
   "source": [
    "## K-Nearest Neighbors Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K=5 Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IBvft9QJRdDx"
   },
   "outputs": [],
   "source": [
    "# Train models\n",
    "KNR_1 = KNeighborsRegressor(n_neighbors = 5)\n",
    "KNR_1_fit = KNR_1.fit(train_images2, train_labels2)\n",
    "\n",
    "# Predict\n",
    "KNR_1_predict = KNR_1.predict(test_images2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xd_VMbB9RdDy",
    "outputId": "50274fe2-765f-4e12-ea6e-4d2e4c2e0eb1"
   },
   "outputs": [],
   "source": [
    "# Get results\n",
    "regression_results(test_labels2, KNR_1_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K=7 Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_QOoD4ohRdDy"
   },
   "outputs": [],
   "source": [
    "# Train models\n",
    "KNR_2 = KNeighborsRegressor(n_neighbors = 7)\n",
    "KNR_2_fit = KNR_2.fit(train_images2, train_labels2)\n",
    "\n",
    "# Predict\n",
    "KNR_2_predict = KNR_2.predict(test_images2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EPDe4b5gRdDy",
    "outputId": "ad6eeae4-a6af-46a9-ddb2-3c9858e94fd8"
   },
   "outputs": [],
   "source": [
    "# Get results\n",
    "regression_results(test_labels2, KNR_2_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models\n",
    "RF2 = RandomForestRegressor(n_estimators=5)\n",
    "RF2_fit = RF2.fit(train_images2, train_labels2)\n",
    "\n",
    "# Predict\n",
    "RF2_predict = RF2_fit.predict(test_images2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get results\n",
    "regression_results(test_labels2, RF2_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-PHiL5rgRdDy"
   },
   "source": [
    "# Augmented Dataset\n",
    "\n",
    "This uses the linear model approach to fill in missing values, as described in the EDA notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t4P5hESvq0XR"
   },
   "outputs": [],
   "source": [
    "# Define feature and target columns\n",
    "feature_col, target_cols = 'image', list(augmented_data.columns)\n",
    "\n",
    "# Specify image dimensions\n",
    "width  = 96\n",
    "height = 96\n",
    "channels = 1\n",
    "\n",
    "# Fill NA's with mean of column - there were still some NA's left with the first version of the linear model.\n",
    "augmented_data = augmented_data.fillna(augmented_data.mean())\n",
    "\n",
    "# Create label array\n",
    "aug_train_labels = augmented_data.to_numpy()\n",
    "\n",
    "# Prepare train-test split\n",
    "train_images3, test_images3, train_labels3, test_labels3 = train_test_split(normalized_train_images, aug_train_labels, test_size=0.1, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNnlkj7DRdD0"
   },
   "source": [
    "### Ordinary Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dE1t-wCARdD0"
   },
   "outputs": [],
   "source": [
    "# Train models\n",
    "LR_1_2 = LinearRegression()\n",
    "LR_1_2_fit = LR_1_2.fit(train_images3, train_labels3)\n",
    "\n",
    "# Predict\n",
    "LR_1_2_predict = LR_1_2_fit.predict(test_images3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F0-SHPDwRdD1",
    "outputId": "e613bf88-a61f-4d96-cee0-6606bd788e41"
   },
   "outputs": [],
   "source": [
    "# Get results\n",
    "regression_results(test_labels3, LR_1_2_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Ruf_l3HRdD1"
   },
   "source": [
    "### Ridge (L1) Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_1t2qblxRdD1"
   },
   "outputs": [],
   "source": [
    "# Train models\n",
    "LR_2_2 = Ridge()\n",
    "LR_2_2_fit = LR_2_2.fit(train_images3, train_labels3)\n",
    "\n",
    "# Predict\n",
    "LR_2_2_predict = LR_2_2_fit.predict(test_images3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bek6LrZ_hK21"
   },
   "outputs": [],
   "source": [
    "# Get results\n",
    "regression_results(test_labels3, LR_2_2_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-V-nD_gRdD2"
   },
   "source": [
    "### Lasso (L2) Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ge2D1F5BRdD2"
   },
   "outputs": [],
   "source": [
    "# Train models\n",
    "LR_3_2 = Lasso()\n",
    "LR_3_2_fit = LR_3_2.fit(train_images3, train_labels3)\n",
    "\n",
    "# Predict\n",
    "LR_3_2_predict = LR_3_2_fit.predict(test_images3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kdvq7ooNRdD2",
    "outputId": "95093465-1fba-47ff-ad84-d3537efcb131"
   },
   "outputs": [],
   "source": [
    "# Get results\n",
    "regression_results(test_labels3, LR_3_2_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4GeL_LCaRdD3"
   },
   "source": [
    "## Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZSqXAN-uRdD3"
   },
   "outputs": [],
   "source": [
    "# Train models\n",
    "DT3 = DecisionTreeRegressor()\n",
    "DT3_fit = DT3.fit(train_images3, train_labels3)\n",
    "\n",
    "# Predict\n",
    "DT3_predict = DT3_fit.predict(test_images3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HqJ5RFWFRdD3",
    "outputId": "2df9cc63-c51a-4cac-f6b3-59ee81a6bbaf"
   },
   "outputs": [],
   "source": [
    "# Get results\n",
    "regression_results(test_labels3, DT3_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "McbP7tPrRdD3"
   },
   "source": [
    "## K-Nearest Neighbors Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K=5 Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bM-_Df0MRdD4"
   },
   "outputs": [],
   "source": [
    "# Train models\n",
    "KNR_1_2 = KNeighborsRegressor(n_neighbors = 5)\n",
    "KNR_1_2_fit = KNR_1_2.fit(train_images3, train_labels3)\n",
    "\n",
    "# Predict\n",
    "KNR_1_2_predict = KNR_1_2_fit.predict(test_images3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1RMudrC2RdD4",
    "outputId": "01642d54-ff27-4716-c691-5b4e7e5bad3e"
   },
   "outputs": [],
   "source": [
    "# Get results\n",
    "regression_results(test_labels3, KNR_1_2_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K=7 Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aUrOfTt-RdD4"
   },
   "outputs": [],
   "source": [
    "# Train models\n",
    "KNR_1_3 = KNeighborsRegressor(n_neighbors = 7)\n",
    "KNR_1_3_fit = KNR_1_3.fit(train_images3, train_labels3)\n",
    "\n",
    "# Predict\n",
    "KNR_1_3_predict = KNR_1_3_fit.predict(test_images3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RAcDKsS1RdD4",
    "outputId": "09768c0c-f557-4c38-a26b-83d8ff87b3b2"
   },
   "outputs": [],
   "source": [
    "# Get results\n",
    "regression_results(test_labels3, KNR_1_3_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models\n",
    "RF3 = RandomForestRegressor(n_estimators=5)\n",
    "RF3_fit = RF3.fit(train_images3, train_labels3)\n",
    "\n",
    "# Predict\n",
    "RF3_predict = RF3_fit.predict(test_images3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get results\n",
    "regression_results(test_labels3, RF3_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Simple Neural Network Model using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note these models are using data without nas\n",
    "#To start, I'm filtering out all data that contains nas\n",
    "#Drop any rows with NA\n",
    "print(\"Before dropping NA\",clean_train.shape)\n",
    "temp_df = clean_train.dropna()\n",
    "print(\"After dropping NA\",temp_df.shape)\n",
    "\n",
    "#Normalizing train\n",
    "X = np.vstack(temp_df['image'].values)/255 #Convert to a 0 to 1 value\n",
    "X = X.astype(np.float32)\n",
    "\n",
    "#Remove index and image from temp_df with [1:-1]\n",
    "y = temp_df[temp_df.columns[1:-1]].values\n",
    "y = (y - 48) / 48  #Convert to a -1 to 1 value \n",
    "y = y.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting into train and dev sets\n",
    "train_images, dev_images, train_labels, dev_labels = train_test_split(X, y, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 1: Intermediate layer 1 level from: https://elix-tech.github.io/ja/2016/06/02/kaggle-facial-keypoints-ja.html\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#Each image is 96x96 so input is 9216\n",
    "#100 neurons in layer\n",
    "model.add(Dense(100, input_dim=9216))\n",
    "\n",
    "#Activation function uses relu ie max(0.0,input)\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(30))\n",
    "\n",
    "#Optimizer = stochastic gradient descent\n",
    "sgd = SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=sgd)\n",
    "hist = model.fit(train_images, train_labels, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return value hist from the model fit can be used to plot\n",
    "plt.plot(hist.history['loss'], linewidth=3, label='train')\n",
    "plt.plot(hist.history['val_loss'], linewidth=3, label='valid')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "#plt.ylim(1e-3, 1e-2)\n",
    "#plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(X,y,axis):\n",
    "  axis.imshow(X.reshape(96,96),cmap='gray')\n",
    "  for i in range(15):\n",
    "    axis.scatter(y[i*2]*48+48,y[i*2+1]*48+48,color=\"green\",marker=\"+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the results on some images\n",
    "y_pred = model.predict(dev_images)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "fig.subplots_adjust(\n",
    "    left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "for i in range(16):\n",
    "    axis = fig.add_subplot(4, 4, i+1, xticks=[], yticks=[])\n",
    "    plot_sample(dev_images[i], dev_labels[i], axis)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_results(dev_labels,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "initial_models.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "tf2-gpu.2-4.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
