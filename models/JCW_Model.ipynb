{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Layered Model & Explorations - JoanieW\n",
    "\n",
    "Based on: https://elix-tech.github.io/ja/2016/06/02/kaggle-facial-keypoints-ja.html#conv\n",
    "\n",
    "And modeled after Jackie's code structure for Lenet5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import imp\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import predict_models, load_models, transform_data\n",
    "from keras.models import Sequential, Model, model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/joanieweaver/Desktop/intro_ml/blackboxes\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model dir: data/models/\n",
      "Pickle dir: cleantrain/\n"
     ]
    }
   ],
   "source": [
    "### this is gold right here.\n",
    "imp.reload(load_models)\n",
    "file_path = \"cleantrain/\"\n",
    "trainer = load_models.LoadTrainModels(\"data/models/\", file_path)\n",
    "\n",
    "trainer.print_paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For every version of a clean Train file in a given path, create and save a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening file:  clean_w_dups.p\n",
      "cleantrain/clean_w_dups.p\n",
      "Train Shape: (6488, 31)\n",
      "Begin model and train:\n",
      "Model name: clean_w_dups_jcw\n",
      "Scaling 6488 images...\n",
      "Scaling of 6488 observations complete.\n",
      "Index(['left_eye_center_x', 'left_eye_center_y', 'right_eye_center_x',\n",
      "       'right_eye_center_y', 'nose_tip_x', 'nose_tip_y',\n",
      "       'mouth_center_bottom_lip_x', 'mouth_center_bottom_lip_y', 'image'],\n",
      "      dtype='object')\n",
      "Begining the split of Train with all features\n",
      "Looking for model JW\n",
      "JW model file not found. Model creation beginning\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 32)        288       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 8, 8, 64)          8192      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 2, 2, 128)         32768     \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 2, 2, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 8)                 4104      \n",
      "=================================================================\n",
      "Total params: 374,952\n",
      "Trainable params: 374,504\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "None\n",
      "Done compiling\n",
      "Epoch 1/300\n",
      "162/162 [==============================] - 4s 19ms/step - loss: 0.0863 - mae: 0.1826 - mse: 0.0863 - val_loss: 0.0140 - val_mae: 0.0914 - val_mse: 0.0140\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 0.09138, saving model to data/models/clean_w_dups_jcw.h5\n",
      "Epoch 2/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.0091 - mae: 0.0706 - mse: 0.0091 - val_loss: 0.0124 - val_mae: 0.0860 - val_mse: 0.0124\n",
      "\n",
      "Epoch 00002: val_mae improved from 0.09138 to 0.08601, saving model to data/models/clean_w_dups_jcw.h5\n",
      "Epoch 3/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.0075 - mae: 0.0629 - mse: 0.0075 - val_loss: 0.0080 - val_mae: 0.0650 - val_mse: 0.0080\n",
      "\n",
      "Epoch 00003: val_mae improved from 0.08601 to 0.06503, saving model to data/models/clean_w_dups_jcw.h5\n",
      "Epoch 4/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0068 - mae: 0.0597 - mse: 0.0068 - val_loss: 0.0076 - val_mae: 0.0635 - val_mse: 0.0076\n",
      "\n",
      "Epoch 00004: val_mae improved from 0.06503 to 0.06350, saving model to data/models/clean_w_dups_jcw.h5\n",
      "Epoch 5/300\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.0064 - mae: 0.0576 - mse: 0.0064 - val_loss: 0.0084 - val_mae: 0.0667 - val_mse: 0.0084\n",
      "\n",
      "Epoch 00005: val_mae did not improve from 0.06350\n",
      "Epoch 6/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.0061 - mae: 0.0569 - mse: 0.0061 - val_loss: 0.0071 - val_mae: 0.0603 - val_mse: 0.0071\n",
      "\n",
      "Epoch 00006: val_mae improved from 0.06350 to 0.06030, saving model to data/models/clean_w_dups_jcw.h5\n",
      "Epoch 7/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0049 - mae: 0.0511 - mse: 0.0049 - val_loss: 0.0073 - val_mae: 0.0612 - val_mse: 0.0073\n",
      "\n",
      "Epoch 00007: val_mae did not improve from 0.06030\n",
      "Epoch 8/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.0046 - mae: 0.0492 - mse: 0.0046 - val_loss: 0.0076 - val_mae: 0.0623 - val_mse: 0.0076\n",
      "\n",
      "Epoch 00008: val_mae did not improve from 0.06030\n",
      "Epoch 9/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0042 - mae: 0.0477 - mse: 0.0042 - val_loss: 0.0071 - val_mae: 0.0601 - val_mse: 0.0071\n",
      "\n",
      "Epoch 00009: val_mae improved from 0.06030 to 0.06015, saving model to data/models/clean_w_dups_jcw.h5\n",
      "Epoch 10/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0040 - mae: 0.0464 - mse: 0.0040 - val_loss: 0.0072 - val_mae: 0.0608 - val_mse: 0.0072\n",
      "\n",
      "Epoch 00010: val_mae did not improve from 0.06015\n",
      "Epoch 11/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.0040 - mae: 0.0466 - mse: 0.0040 - val_loss: 0.0074 - val_mae: 0.0615 - val_mse: 0.0074\n",
      "\n",
      "Epoch 00011: val_mae did not improve from 0.06015\n",
      "Epoch 12/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.0035 - mae: 0.0444 - mse: 0.0035 - val_loss: 0.0069 - val_mae: 0.0589 - val_mse: 0.0069\n",
      "\n",
      "Epoch 00012: val_mae improved from 0.06015 to 0.05891, saving model to data/models/clean_w_dups_jcw.h5\n",
      "Epoch 13/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.0033 - mae: 0.0431 - mse: 0.0033 - val_loss: 0.0073 - val_mae: 0.0618 - val_mse: 0.0073\n",
      "\n",
      "Epoch 00013: val_mae did not improve from 0.05891\n",
      "Epoch 14/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.0034 - mae: 0.0434 - mse: 0.0034 - val_loss: 0.0076 - val_mae: 0.0639 - val_mse: 0.0076\n",
      "\n",
      "Epoch 00014: val_mae did not improve from 0.05891\n",
      "Epoch 15/300\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.0033 - mae: 0.0431 - mse: 0.0033 - val_loss: 0.0067 - val_mae: 0.0579 - val_mse: 0.0067\n",
      "\n",
      "Epoch 00015: val_mae improved from 0.05891 to 0.05789, saving model to data/models/clean_w_dups_jcw.h5\n",
      "Epoch 16/300\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.0030 - mae: 0.0410 - mse: 0.0030 - val_loss: 0.0064 - val_mae: 0.0562 - val_mse: 0.0064\n",
      "\n",
      "Epoch 00016: val_mae improved from 0.05789 to 0.05615, saving model to data/models/clean_w_dups_jcw.h5\n",
      "Epoch 17/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.0030 - mae: 0.0411 - mse: 0.0030 - val_loss: 0.0071 - val_mae: 0.0595 - val_mse: 0.0071\n",
      "\n",
      "Epoch 00017: val_mae did not improve from 0.05615\n",
      "Epoch 18/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0028 - mae: 0.0386 - mse: 0.0028 - val_loss: 0.0065 - val_mae: 0.0568 - val_mse: 0.0065\n",
      "\n",
      "Epoch 00018: val_mae did not improve from 0.05615\n",
      "Epoch 19/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.0026 - mae: 0.0380 - mse: 0.0026 - val_loss: 0.0065 - val_mae: 0.0559 - val_mse: 0.0065\n",
      "\n",
      "Epoch 00019: val_mae improved from 0.05615 to 0.05587, saving model to data/models/clean_w_dups_jcw.h5\n",
      "Epoch 20/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.0023 - mae: 0.0359 - mse: 0.0023 - val_loss: 0.0067 - val_mae: 0.0576 - val_mse: 0.0067\n",
      "\n",
      "Epoch 00020: val_mae did not improve from 0.05587\n",
      "Epoch 21/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0025 - mae: 0.0374 - mse: 0.0025 - val_loss: 0.0064 - val_mae: 0.0553 - val_mse: 0.0064\n",
      "\n",
      "Epoch 00021: val_mae improved from 0.05587 to 0.05528, saving model to data/models/clean_w_dups_jcw.h5\n",
      "Epoch 22/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0024 - mae: 0.0367 - mse: 0.0024 - val_loss: 0.0067 - val_mae: 0.0572 - val_mse: 0.0067\n",
      "\n",
      "Epoch 00022: val_mae did not improve from 0.05528\n",
      "Epoch 23/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0035 - mae: 0.0435 - mse: 0.0035 - val_loss: 0.0063 - val_mae: 0.0548 - val_mse: 0.0063\n",
      "\n",
      "Epoch 00023: val_mae improved from 0.05528 to 0.05475, saving model to data/models/clean_w_dups_jcw.h5\n",
      "Epoch 24/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.0023 - mae: 0.0364 - mse: 0.0023 - val_loss: 0.0065 - val_mae: 0.0558 - val_mse: 0.0065\n",
      "\n",
      "Epoch 00024: val_mae did not improve from 0.05475\n",
      "Epoch 25/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0025 - mae: 0.0371 - mse: 0.0025 - val_loss: 0.0064 - val_mae: 0.0566 - val_mse: 0.0064\n",
      "\n",
      "Epoch 00025: val_mae did not improve from 0.05475\n",
      "Epoch 26/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0035 - mae: 0.0434 - mse: 0.0035 - val_loss: 0.0060 - val_mae: 0.0546 - val_mse: 0.0060\n",
      "\n",
      "Epoch 00026: val_mae improved from 0.05475 to 0.05455, saving model to data/models/clean_w_dups_jcw.h5\n",
      "Epoch 27/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.0027 - mae: 0.0389 - mse: 0.0027 - val_loss: 0.0058 - val_mae: 0.0523 - val_mse: 0.0058\n",
      "\n",
      "Epoch 00027: val_mae improved from 0.05455 to 0.05232, saving model to data/models/clean_w_dups_jcw.h5\n",
      "Epoch 28/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.0024 - mae: 0.0353 - mse: 0.0024 - val_loss: 0.0061 - val_mae: 0.0534 - val_mse: 0.0061\n",
      "\n",
      "Epoch 00028: val_mae did not improve from 0.05232\n",
      "Epoch 29/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.0021 - mae: 0.0338 - mse: 0.0021 - val_loss: 0.0059 - val_mae: 0.0526 - val_mse: 0.0059\n",
      "\n",
      "Epoch 00029: val_mae did not improve from 0.05232\n",
      "Epoch 30/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.0023 - mae: 0.0351 - mse: 0.0023 - val_loss: 0.0065 - val_mae: 0.0564 - val_mse: 0.0065\n",
      "\n",
      "Epoch 00030: val_mae did not improve from 0.05232\n",
      "Epoch 31/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.0022 - mae: 0.0353 - mse: 0.0022 - val_loss: 0.0069 - val_mae: 0.0576 - val_mse: 0.0069\n",
      "\n",
      "Epoch 00031: val_mae did not improve from 0.05232\n",
      "Epoch 32/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.0021 - mae: 0.0343 - mse: 0.0021 - val_loss: 0.0059 - val_mae: 0.0532 - val_mse: 0.0059\n",
      "\n",
      "Epoch 00032: val_mae did not improve from 0.05232\n",
      "Epoch 33/300\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.0022 - mae: 0.0341 - mse: 0.0022 - val_loss: 0.0057 - val_mae: 0.0514 - val_mse: 0.0057\n",
      "\n",
      "Epoch 00033: val_mae improved from 0.05232 to 0.05140, saving model to data/models/clean_w_dups_jcw.h5\n",
      "Epoch 34/300\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.0017 - mae: 0.0305 - mse: 0.0017 - val_loss: 0.0072 - val_mae: 0.0592 - val_mse: 0.0072\n",
      "\n",
      "Epoch 00034: val_mae did not improve from 0.05140\n",
      "Epoch 35/300\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.0019 - mae: 0.0327 - mse: 0.0019 - val_loss: 0.0060 - val_mae: 0.0530 - val_mse: 0.0060\n",
      "\n",
      "Epoch 00035: val_mae did not improve from 0.05140\n",
      "Epoch 36/300\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.0017 - mae: 0.0306 - mse: 0.0017 - val_loss: 0.0062 - val_mae: 0.0540 - val_mse: 0.0062\n",
      "\n",
      "Epoch 00036: val_mae did not improve from 0.05140\n",
      "Epoch 37/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.0016 - mae: 0.0302 - mse: 0.0016 - val_loss: 0.0059 - val_mae: 0.0520 - val_mse: 0.0059\n",
      "\n",
      "Epoch 00037: val_mae did not improve from 0.05140\n",
      "Epoch 38/300\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.0016 - mae: 0.0293 - mse: 0.0016 - val_loss: 0.0060 - val_mae: 0.0528 - val_mse: 0.0060\n",
      "\n",
      "Epoch 00038: val_mae did not improve from 0.05140\n",
      "Epoch 39/300\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.0018 - mae: 0.0319 - mse: 0.0018 - val_loss: 0.0060 - val_mae: 0.0538 - val_mse: 0.0060\n",
      "\n",
      "Epoch 00039: val_mae did not improve from 0.05140\n",
      "Epoch 40/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0032 - mae: 0.0407 - mse: 0.0032 - val_loss: 0.0057 - val_mae: 0.0512 - val_mse: 0.0057\n",
      "\n",
      "Epoch 00040: val_mae improved from 0.05140 to 0.05121, saving model to data/models/clean_w_dups_jcw.h5\n",
      "Epoch 41/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0019 - mae: 0.0320 - mse: 0.0019 - val_loss: 0.0058 - val_mae: 0.0520 - val_mse: 0.0058\n",
      "\n",
      "Epoch 00041: val_mae did not improve from 0.05121\n",
      "Epoch 42/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0017 - mae: 0.0302 - mse: 0.0017 - val_loss: 0.0064 - val_mae: 0.0550 - val_mse: 0.0064\n",
      "\n",
      "Epoch 00042: val_mae did not improve from 0.05121\n",
      "Epoch 43/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0021 - mae: 0.0327 - mse: 0.0021 - val_loss: 0.0055 - val_mae: 0.0502 - val_mse: 0.0055\n",
      "\n",
      "Epoch 00043: val_mae improved from 0.05121 to 0.05021, saving model to data/models/clean_w_dups_jcw.h5\n",
      "Epoch 44/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0021 - mae: 0.0329 - mse: 0.0021 - val_loss: 0.0059 - val_mae: 0.0521 - val_mse: 0.0059\n",
      "\n",
      "Epoch 00044: val_mae did not improve from 0.05021\n",
      "Epoch 45/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0014 - mae: 0.0281 - mse: 0.0014 - val_loss: 0.0054 - val_mae: 0.0495 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00045: val_mae improved from 0.05021 to 0.04947, saving model to data/models/clean_w_dups_jcw.h5\n",
      "Epoch 46/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0016 - mae: 0.0297 - mse: 0.0016 - val_loss: 0.0052 - val_mae: 0.0491 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00046: val_mae improved from 0.04947 to 0.04912, saving model to data/models/clean_w_dups_jcw.h5\n",
      "Epoch 47/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0016 - mae: 0.0289 - mse: 0.0016 - val_loss: 0.0059 - val_mae: 0.0522 - val_mse: 0.0059\n",
      "\n",
      "Epoch 00047: val_mae did not improve from 0.04912\n",
      "Epoch 48/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0013 - mae: 0.0275 - mse: 0.0013 - val_loss: 0.0059 - val_mae: 0.0529 - val_mse: 0.0059\n",
      "\n",
      "Epoch 00048: val_mae did not improve from 0.04912\n",
      "Epoch 49/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0019 - mae: 0.0300 - mse: 0.0019 - val_loss: 0.0061 - val_mae: 0.0531 - val_mse: 0.0061\n",
      "\n",
      "Epoch 00049: val_mae did not improve from 0.04912\n",
      "Epoch 50/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0016 - mae: 0.0284 - mse: 0.0016 - val_loss: 0.0053 - val_mae: 0.0496 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00050: val_mae did not improve from 0.04912\n",
      "Epoch 51/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0013 - mae: 0.0265 - mse: 0.0013 - val_loss: 0.0054 - val_mae: 0.0498 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00051: val_mae did not improve from 0.04912\n",
      "Epoch 52/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.0013 - mae: 0.0264 - mse: 0.0013 - val_loss: 0.0055 - val_mae: 0.0502 - val_mse: 0.0055\n",
      "\n",
      "Epoch 00052: val_mae did not improve from 0.04912\n",
      "Epoch 53/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0011 - mae: 0.0253 - mse: 0.0011 - val_loss: 0.0055 - val_mae: 0.0504 - val_mse: 0.0055\n",
      "\n",
      "Epoch 00053: val_mae did not improve from 0.04912\n",
      "Epoch 54/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0017 - mae: 0.0294 - mse: 0.0017 - val_loss: 0.0053 - val_mae: 0.0491 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00054: val_mae improved from 0.04912 to 0.04906, saving model to data/models/clean_w_dups_jcw.h5\n",
      "Epoch 55/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0014 - mae: 0.0274 - mse: 0.0014 - val_loss: 0.0054 - val_mae: 0.0494 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00055: val_mae did not improve from 0.04906\n",
      "Epoch 56/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0012 - mae: 0.0254 - mse: 0.0012 - val_loss: 0.0053 - val_mae: 0.0493 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00056: val_mae did not improve from 0.04906\n",
      "Epoch 57/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0013 - mae: 0.0261 - mse: 0.0013 - val_loss: 0.0053 - val_mae: 0.0495 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00057: val_mae did not improve from 0.04906\n",
      "Epoch 58/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0011 - mae: 0.0247 - mse: 0.0011 - val_loss: 0.0052 - val_mae: 0.0482 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00058: val_mae improved from 0.04906 to 0.04819, saving model to data/models/clean_w_dups_jcw.h5\n",
      "Epoch 59/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0015 - mae: 0.0263 - mse: 0.0015 - val_loss: 0.0054 - val_mae: 0.0489 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00059: val_mae did not improve from 0.04819\n",
      "Epoch 60/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0011 - mae: 0.0241 - mse: 0.0011 - val_loss: 0.0052 - val_mae: 0.0486 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00060: val_mae did not improve from 0.04819\n",
      "Epoch 61/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0011 - mae: 0.0246 - mse: 0.0011 - val_loss: 0.0053 - val_mae: 0.0485 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00061: val_mae did not improve from 0.04819\n",
      "Epoch 62/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 9.9369e-04 - mae: 0.0237 - mse: 9.9369e-04 - val_loss: 0.0053 - val_mae: 0.0488 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00062: val_mae did not improve from 0.04819\n",
      "Epoch 63/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 9.3038e-04 - mae: 0.0230 - mse: 9.3038e-04 - val_loss: 0.0057 - val_mae: 0.0507 - val_mse: 0.0057\n",
      "\n",
      "Epoch 00063: val_mae did not improve from 0.04819\n",
      "Epoch 64/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.0013 - mae: 0.0251 - mse: 0.0013 - val_loss: 0.0056 - val_mae: 0.0504 - val_mse: 0.0056\n",
      "\n",
      "Epoch 00064: val_mae did not improve from 0.04819\n",
      "Epoch 65/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.0014 - mae: 0.0273 - mse: 0.0014 - val_loss: 0.0054 - val_mae: 0.0491 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00065: val_mae did not improve from 0.04819\n",
      "Epoch 66/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.0012 - mae: 0.0247 - mse: 0.0012 - val_loss: 0.0052 - val_mae: 0.0489 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00066: val_mae did not improve from 0.04819\n",
      "Epoch 67/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.0011 - mae: 0.0243 - mse: 0.0011 - val_loss: 0.0054 - val_mae: 0.0490 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00067: val_mae did not improve from 0.04819\n",
      "Epoch 68/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.0011 - mae: 0.0238 - mse: 0.0011 - val_loss: 0.0049 - val_mae: 0.0469 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00068: val_mae improved from 0.04819 to 0.04690, saving model to data/models/clean_w_dups_jcw.h5\n",
      "Epoch 69/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0013 - mae: 0.0261 - mse: 0.0013 - val_loss: 0.0053 - val_mae: 0.0492 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00069: val_mae did not improve from 0.04690\n",
      "Epoch 70/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 9.8669e-04 - mae: 0.0236 - mse: 9.8669e-04 - val_loss: 0.0051 - val_mae: 0.0479 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00070: val_mae did not improve from 0.04690\n",
      "Epoch 71/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0012 - mae: 0.0248 - mse: 0.0012 - val_loss: 0.0053 - val_mae: 0.0494 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00071: val_mae did not improve from 0.04690\n",
      "Epoch 72/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0014 - mae: 0.0268 - mse: 0.0014 - val_loss: 0.0052 - val_mae: 0.0478 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00072: val_mae did not improve from 0.04690\n",
      "Epoch 73/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0010 - mae: 0.0236 - mse: 0.0010 - val_loss: 0.0051 - val_mae: 0.0476 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00073: val_mae did not improve from 0.04690\n",
      "Epoch 74/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0011 - mae: 0.0247 - mse: 0.0011 - val_loss: 0.0053 - val_mae: 0.0496 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00074: val_mae did not improve from 0.04690\n",
      "Epoch 75/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0010 - mae: 0.0236 - mse: 0.0010 - val_loss: 0.0052 - val_mae: 0.0489 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00075: val_mae did not improve from 0.04690\n",
      "Epoch 76/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0010 - mae: 0.0230 - mse: 0.0010 - val_loss: 0.0051 - val_mae: 0.0483 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00076: val_mae did not improve from 0.04690\n",
      "Epoch 77/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 9.5254e-04 - mae: 0.0221 - mse: 9.5254e-04 - val_loss: 0.0063 - val_mae: 0.0549 - val_mse: 0.0063\n",
      "\n",
      "Epoch 00077: val_mae did not improve from 0.04690\n",
      "Epoch 78/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0017 - mae: 0.0309 - mse: 0.0017 - val_loss: 0.0051 - val_mae: 0.0482 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00078: val_mae did not improve from 0.04690\n",
      "Epoch 79/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0012 - mae: 0.0250 - mse: 0.0012 - val_loss: 0.0051 - val_mae: 0.0479 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00079: val_mae did not improve from 0.04690\n",
      "Epoch 80/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0010 - mae: 0.0229 - mse: 0.0010 - val_loss: 0.0052 - val_mae: 0.0481 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00080: val_mae did not improve from 0.04690\n",
      "Epoch 81/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 9.4403e-04 - mae: 0.0222 - mse: 9.4403e-04 - val_loss: 0.0053 - val_mae: 0.0487 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00081: val_mae did not improve from 0.04690\n",
      "Epoch 82/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0013 - mae: 0.0255 - mse: 0.0013 - val_loss: 0.0051 - val_mae: 0.0478 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00082: val_mae did not improve from 0.04690\n",
      "Epoch 83/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 8.6757e-04 - mae: 0.0220 - mse: 8.6757e-04 - val_loss: 0.0052 - val_mae: 0.0479 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00083: val_mae did not improve from 0.04690\n",
      "Epoch 84/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 8.6209e-04 - mae: 0.0218 - mse: 8.6209e-04 - val_loss: 0.0052 - val_mae: 0.0482 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00084: val_mae did not improve from 0.04690\n",
      "Epoch 85/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 7.0934e-04 - mae: 0.0200 - mse: 7.0934e-04 - val_loss: 0.0051 - val_mae: 0.0479 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00085: val_mae did not improve from 0.04690\n",
      "Epoch 86/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 8.1987e-04 - mae: 0.0216 - mse: 8.1987e-04 - val_loss: 0.0051 - val_mae: 0.0479 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00086: val_mae did not improve from 0.04690\n",
      "Epoch 87/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 9.0488e-04 - mae: 0.0225 - mse: 9.0488e-04 - val_loss: 0.0052 - val_mae: 0.0481 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00087: val_mae did not improve from 0.04690\n",
      "Epoch 88/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 9.8106e-04 - mae: 0.0221 - mse: 9.8106e-04 - val_loss: 0.0054 - val_mae: 0.0488 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00088: val_mae did not improve from 0.04690\n",
      "Epoch 89/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 6.9812e-04 - mae: 0.0197 - mse: 6.9812e-04 - val_loss: 0.0050 - val_mae: 0.0474 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00089: val_mae did not improve from 0.04690\n",
      "Epoch 90/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 7.4116e-04 - mae: 0.0201 - mse: 7.4116e-04 - val_loss: 0.0054 - val_mae: 0.0490 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00090: val_mae did not improve from 0.04690\n",
      "Epoch 91/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.0012 - mae: 0.0262 - mse: 0.0012 - val_loss: 0.0054 - val_mae: 0.0494 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00091: val_mae did not improve from 0.04690\n",
      "Epoch 92/300\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 8.2725e-04 - mae: 0.0217 - mse: 8.2725e-04 - val_loss: 0.0053 - val_mae: 0.0485 - val_mse: 0.0053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00092: val_mae did not improve from 0.04690\n",
      "Epoch 93/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.0010 - mae: 0.0210 - mse: 0.0010 - val_loss: 0.0049 - val_mae: 0.0466 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00093: val_mae improved from 0.04690 to 0.04664, saving model to data/models/clean_w_dups_jcw.h5\n",
      "Epoch 94/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 8.1042e-04 - mae: 0.0203 - mse: 8.1042e-04 - val_loss: 0.0049 - val_mae: 0.0469 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00094: val_mae did not improve from 0.04664\n",
      "Epoch 95/300\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 7.9823e-04 - mae: 0.0205 - mse: 7.9823e-04 - val_loss: 0.0051 - val_mae: 0.0472 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00095: val_mae did not improve from 0.04664\n",
      "Epoch 96/300\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 8.8404e-04 - mae: 0.0198 - mse: 8.8404e-04 - val_loss: 0.0052 - val_mae: 0.0478 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00096: val_mae did not improve from 0.04664\n",
      "Epoch 97/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 6.7306e-04 - mae: 0.0190 - mse: 6.7306e-04 - val_loss: 0.0051 - val_mae: 0.0478 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00097: val_mae did not improve from 0.04664\n",
      "Epoch 98/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 7.2662e-04 - mae: 0.0192 - mse: 7.2662e-04 - val_loss: 0.0050 - val_mae: 0.0470 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00098: val_mae did not improve from 0.04664\n",
      "Epoch 99/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 7.9495e-04 - mae: 0.0204 - mse: 7.9495e-04 - val_loss: 0.0049 - val_mae: 0.0467 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00099: val_mae did not improve from 0.04664\n",
      "Epoch 100/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 7.6983e-04 - mae: 0.0208 - mse: 7.6983e-04 - val_loss: 0.0049 - val_mae: 0.0464 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00100: val_mae improved from 0.04664 to 0.04639, saving model to data/models/clean_w_dups_jcw.h5\n",
      "Epoch 101/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 5.7012e-04 - mae: 0.0181 - mse: 5.7012e-04 - val_loss: 0.0051 - val_mae: 0.0475 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00101: val_mae did not improve from 0.04639\n",
      "Epoch 102/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 6.1985e-04 - mae: 0.0186 - mse: 6.1985e-04 - val_loss: 0.0050 - val_mae: 0.0467 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00102: val_mae did not improve from 0.04639\n",
      "Epoch 103/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 6.3171e-04 - mae: 0.0184 - mse: 6.3171e-04 - val_loss: 0.0051 - val_mae: 0.0480 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00103: val_mae did not improve from 0.04639\n",
      "Epoch 104/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 7.4911e-04 - mae: 0.0198 - mse: 7.4911e-04 - val_loss: 0.0049 - val_mae: 0.0464 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00104: val_mae improved from 0.04639 to 0.04638, saving model to data/models/clean_w_dups_jcw.h5\n",
      "Epoch 105/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 5.9835e-04 - mae: 0.0182 - mse: 5.9835e-04 - val_loss: 0.0048 - val_mae: 0.0460 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00105: val_mae improved from 0.04638 to 0.04604, saving model to data/models/clean_w_dups_jcw.h5\n",
      "Epoch 106/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 6.5650e-04 - mae: 0.0192 - mse: 6.5650e-04 - val_loss: 0.0050 - val_mae: 0.0472 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00106: val_mae did not improve from 0.04604\n",
      "Epoch 107/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0011 - mae: 0.0253 - mse: 0.0011 - val_loss: 0.0052 - val_mae: 0.0487 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00107: val_mae did not improve from 0.04604\n",
      "Epoch 108/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 7.9780e-04 - mae: 0.0213 - mse: 7.9780e-04 - val_loss: 0.0050 - val_mae: 0.0467 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00108: val_mae did not improve from 0.04604\n",
      "Epoch 109/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 6.7377e-04 - mae: 0.0192 - mse: 6.7377e-04 - val_loss: 0.0049 - val_mae: 0.0465 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00109: val_mae did not improve from 0.04604\n",
      "Epoch 110/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 5.9893e-04 - mae: 0.0179 - mse: 5.9893e-04 - val_loss: 0.0051 - val_mae: 0.0481 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00110: val_mae did not improve from 0.04604\n",
      "Epoch 111/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.0013 - mae: 0.0270 - mse: 0.0013 - val_loss: 0.0052 - val_mae: 0.0479 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00111: val_mae did not improve from 0.04604\n",
      "Epoch 112/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 8.9107e-04 - mae: 0.0222 - mse: 8.9107e-04 - val_loss: 0.0049 - val_mae: 0.0466 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00112: val_mae did not improve from 0.04604\n",
      "Epoch 113/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 6.7525e-04 - mae: 0.0195 - mse: 6.7525e-04 - val_loss: 0.0049 - val_mae: 0.0467 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00113: val_mae did not improve from 0.04604\n",
      "Epoch 114/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 5.8597e-04 - mae: 0.0180 - mse: 5.8597e-04 - val_loss: 0.0048 - val_mae: 0.0458 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00114: val_mae improved from 0.04604 to 0.04578, saving model to data/models/clean_w_dups_jcw.h5\n",
      "Epoch 115/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 5.5098e-04 - mae: 0.0170 - mse: 5.5098e-04 - val_loss: 0.0048 - val_mae: 0.0461 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00115: val_mae did not improve from 0.04578\n",
      "Epoch 116/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 5.1272e-04 - mae: 0.0167 - mse: 5.1272e-04 - val_loss: 0.0049 - val_mae: 0.0467 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00116: val_mae did not improve from 0.04578\n",
      "Epoch 117/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 5.5938e-04 - mae: 0.0176 - mse: 5.5938e-04 - val_loss: 0.0049 - val_mae: 0.0469 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00117: val_mae did not improve from 0.04578\n",
      "Epoch 118/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 6.0904e-04 - mae: 0.0184 - mse: 6.0904e-04 - val_loss: 0.0049 - val_mae: 0.0466 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00118: val_mae did not improve from 0.04578\n",
      "Epoch 119/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 5.8555e-04 - mae: 0.0173 - mse: 5.8555e-04 - val_loss: 0.0049 - val_mae: 0.0464 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00119: val_mae did not improve from 0.04578\n",
      "Epoch 120/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 5.1243e-04 - mae: 0.0170 - mse: 5.1243e-04 - val_loss: 0.0047 - val_mae: 0.0458 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00120: val_mae improved from 0.04578 to 0.04577, saving model to data/models/clean_w_dups_jcw.h5\n",
      "Epoch 121/300\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 5.9228e-04 - mae: 0.0173 - mse: 5.9228e-04 - val_loss: 0.0049 - val_mae: 0.0466 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00121: val_mae did not improve from 0.04577\n",
      "Epoch 122/300\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 5.2824e-04 - mae: 0.0171 - mse: 5.2824e-04 - val_loss: 0.0049 - val_mae: 0.0464 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00122: val_mae did not improve from 0.04577\n",
      "Epoch 123/300\n",
      "162/162 [==============================] - 5s 28ms/step - loss: 7.1082e-04 - mae: 0.0186 - mse: 7.1082e-04 - val_loss: 0.0049 - val_mae: 0.0462 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00123: val_mae did not improve from 0.04577\n",
      "Epoch 124/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 5.2153e-04 - mae: 0.0172 - mse: 5.2153e-04 - val_loss: 0.0048 - val_mae: 0.0461 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00124: val_mae did not improve from 0.04577\n",
      "Epoch 125/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 5.6616e-04 - mae: 0.0174 - mse: 5.6616e-04 - val_loss: 0.0049 - val_mae: 0.0467 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00125: val_mae did not improve from 0.04577\n",
      "Epoch 126/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 4.7402e-04 - mae: 0.0165 - mse: 4.7402e-04 - val_loss: 0.0049 - val_mae: 0.0467 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00126: val_mae did not improve from 0.04577\n",
      "Epoch 127/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 4.6930e-04 - mae: 0.0163 - mse: 4.6930e-04 - val_loss: 0.0051 - val_mae: 0.0476 - val_mse: 0.0051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00127: val_mae did not improve from 0.04577\n",
      "Epoch 128/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 5.6021e-04 - mae: 0.0178 - mse: 5.6021e-04 - val_loss: 0.0049 - val_mae: 0.0467 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00128: val_mae did not improve from 0.04577\n",
      "Epoch 129/300\n",
      "162/162 [==============================] - 3s 18ms/step - loss: 4.8948e-04 - mae: 0.0165 - mse: 4.8948e-04 - val_loss: 0.0048 - val_mae: 0.0459 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00129: val_mae did not improve from 0.04577\n",
      "Epoch 130/300\n",
      "162/162 [==============================] - 3s 18ms/step - loss: 5.6389e-04 - mae: 0.0177 - mse: 5.6389e-04 - val_loss: 0.0048 - val_mae: 0.0460 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00130: val_mae did not improve from 0.04577\n",
      "Epoch 131/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 7.8692e-04 - mae: 0.0201 - mse: 7.8692e-04 - val_loss: 0.0051 - val_mae: 0.0475 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00131: val_mae did not improve from 0.04577\n",
      "Epoch 132/300\n",
      "162/162 [==============================] - 3s 18ms/step - loss: 6.0017e-04 - mae: 0.0182 - mse: 6.0017e-04 - val_loss: 0.0050 - val_mae: 0.0471 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00132: val_mae did not improve from 0.04577\n",
      "Epoch 133/300\n",
      "162/162 [==============================] - 3s 18ms/step - loss: 5.1028e-04 - mae: 0.0170 - mse: 5.1028e-04 - val_loss: 0.0048 - val_mae: 0.0461 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00133: val_mae did not improve from 0.04577\n",
      "Epoch 134/300\n",
      "162/162 [==============================] - 3s 18ms/step - loss: 6.2319e-04 - mae: 0.0188 - mse: 6.2319e-04 - val_loss: 0.0049 - val_mae: 0.0461 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00134: val_mae did not improve from 0.04577\n",
      "Epoch 135/300\n",
      "162/162 [==============================] - 3s 18ms/step - loss: 5.3882e-04 - mae: 0.0174 - mse: 5.3882e-04 - val_loss: 0.0050 - val_mae: 0.0467 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00135: val_mae did not improve from 0.04577\n",
      "Epoch 136/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 4.9825e-04 - mae: 0.0165 - mse: 4.9825e-04 - val_loss: 0.0050 - val_mae: 0.0469 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00136: val_mae did not improve from 0.04577\n",
      "Epoch 137/300\n",
      "162/162 [==============================] - 3s 18ms/step - loss: 5.2421e-04 - mae: 0.0162 - mse: 5.2421e-04 - val_loss: 0.0048 - val_mae: 0.0460 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00137: val_mae did not improve from 0.04577\n",
      "Epoch 138/300\n",
      "162/162 [==============================] - 3s 18ms/step - loss: 4.4786e-04 - mae: 0.0157 - mse: 4.4786e-04 - val_loss: 0.0048 - val_mae: 0.0460 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00138: val_mae did not improve from 0.04577\n",
      "Epoch 139/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 4.6039e-04 - mae: 0.0159 - mse: 4.6039e-04 - val_loss: 0.0048 - val_mae: 0.0458 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00139: val_mae did not improve from 0.04577\n",
      "Epoch 140/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 4.0704e-04 - mae: 0.0151 - mse: 4.0704e-04 - val_loss: 0.0050 - val_mae: 0.0470 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00140: val_mae did not improve from 0.04577\n",
      "Epoch 141/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 4.6994e-04 - mae: 0.0161 - mse: 4.6994e-04 - val_loss: 0.0050 - val_mae: 0.0473 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00141: val_mae did not improve from 0.04577\n",
      "Epoch 142/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 4.8899e-04 - mae: 0.0163 - mse: 4.8899e-04 - val_loss: 0.0047 - val_mae: 0.0452 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00142: val_mae improved from 0.04577 to 0.04521, saving model to data/models/clean_w_dups_jcw.h5\n",
      "Epoch 143/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 4.3729e-04 - mae: 0.0156 - mse: 4.3729e-04 - val_loss: 0.0050 - val_mae: 0.0468 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00143: val_mae did not improve from 0.04521\n",
      "Epoch 144/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 4.4519e-04 - mae: 0.0157 - mse: 4.4519e-04 - val_loss: 0.0048 - val_mae: 0.0457 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00144: val_mae did not improve from 0.04521\n",
      "Epoch 145/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 7.5734e-04 - mae: 0.0194 - mse: 7.5734e-04 - val_loss: 0.0052 - val_mae: 0.0492 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00145: val_mae did not improve from 0.04521\n",
      "Epoch 146/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 5.4553e-04 - mae: 0.0172 - mse: 5.4553e-04 - val_loss: 0.0048 - val_mae: 0.0463 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00146: val_mae did not improve from 0.04521\n",
      "Epoch 147/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 9.4539e-04 - mae: 0.0227 - mse: 9.4539e-04 - val_loss: 0.0049 - val_mae: 0.0471 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00147: val_mae did not improve from 0.04521\n",
      "Epoch 148/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 7.1037e-04 - mae: 0.0198 - mse: 7.1037e-04 - val_loss: 0.0049 - val_mae: 0.0466 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00148: val_mae did not improve from 0.04521\n",
      "Epoch 149/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 4.7103e-04 - mae: 0.0159 - mse: 4.7103e-04 - val_loss: 0.0051 - val_mae: 0.0472 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00149: val_mae did not improve from 0.04521\n",
      "Epoch 150/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 7.2538e-04 - mae: 0.0205 - mse: 7.2538e-04 - val_loss: 0.0050 - val_mae: 0.0475 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00150: val_mae did not improve from 0.04521\n",
      "Epoch 151/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 6.8404e-04 - mae: 0.0190 - mse: 6.8404e-04 - val_loss: 0.0048 - val_mae: 0.0456 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00151: val_mae did not improve from 0.04521\n",
      "Epoch 152/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 4.4267e-04 - mae: 0.0159 - mse: 4.4267e-04 - val_loss: 0.0049 - val_mae: 0.0459 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00152: val_mae did not improve from 0.04521\n",
      "Epoch 153/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 4.0736e-04 - mae: 0.0152 - mse: 4.0736e-04 - val_loss: 0.0048 - val_mae: 0.0458 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00153: val_mae did not improve from 0.04521\n",
      "Epoch 154/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 8.9471e-04 - mae: 0.0220 - mse: 8.9471e-04 - val_loss: 0.0049 - val_mae: 0.0465 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00154: val_mae did not improve from 0.04521\n",
      "Epoch 155/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 5.4245e-04 - mae: 0.0173 - mse: 5.4245e-04 - val_loss: 0.0048 - val_mae: 0.0457 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00155: val_mae did not improve from 0.04521\n",
      "Epoch 156/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 5.2259e-04 - mae: 0.0165 - mse: 5.2259e-04 - val_loss: 0.0049 - val_mae: 0.0461 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00156: val_mae did not improve from 0.04521\n",
      "Epoch 157/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 4.5910e-04 - mae: 0.0160 - mse: 4.5910e-04 - val_loss: 0.0049 - val_mae: 0.0459 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00157: val_mae did not improve from 0.04521\n",
      "Epoch 158/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 4.3579e-04 - mae: 0.0152 - mse: 4.3579e-04 - val_loss: 0.0049 - val_mae: 0.0460 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00158: val_mae did not improve from 0.04521\n",
      "Epoch 159/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 3.9395e-04 - mae: 0.0150 - mse: 3.9395e-04 - val_loss: 0.0049 - val_mae: 0.0464 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00159: val_mae did not improve from 0.04521\n",
      "Epoch 160/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 5.2324e-04 - mae: 0.0171 - mse: 5.2324e-04 - val_loss: 0.0048 - val_mae: 0.0460 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00160: val_mae did not improve from 0.04521\n",
      "Epoch 161/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 6.1583e-04 - mae: 0.0186 - mse: 6.1583e-04 - val_loss: 0.0048 - val_mae: 0.0458 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00161: val_mae did not improve from 0.04521\n",
      "Epoch 162/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 5.4268e-04 - mae: 0.0173 - mse: 5.4268e-04 - val_loss: 0.0048 - val_mae: 0.0457 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00162: val_mae did not improve from 0.04521\n",
      "Epoch 163/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 4.2195e-04 - mae: 0.0150 - mse: 4.2195e-04 - val_loss: 0.0046 - val_mae: 0.0449 - val_mse: 0.0046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00163: val_mae improved from 0.04521 to 0.04490, saving model to data/models/clean_w_dups_jcw.h5\n",
      "Epoch 164/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 4.0012e-04 - mae: 0.0142 - mse: 4.0012e-04 - val_loss: 0.0047 - val_mae: 0.0449 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00164: val_mae improved from 0.04490 to 0.04489, saving model to data/models/clean_w_dups_jcw.h5\n",
      "Epoch 165/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 3.6266e-04 - mae: 0.0143 - mse: 3.6266e-04 - val_loss: 0.0047 - val_mae: 0.0452 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00165: val_mae did not improve from 0.04489\n",
      "Epoch 166/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 5.2093e-04 - mae: 0.0170 - mse: 5.2093e-04 - val_loss: 0.0048 - val_mae: 0.0456 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00166: val_mae did not improve from 0.04489\n",
      "Epoch 167/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 4.1067e-04 - mae: 0.0153 - mse: 4.1067e-04 - val_loss: 0.0047 - val_mae: 0.0450 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00167: val_mae did not improve from 0.04489\n",
      "Epoch 168/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 3.7520e-04 - mae: 0.0144 - mse: 3.7520e-04 - val_loss: 0.0047 - val_mae: 0.0447 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00168: val_mae improved from 0.04489 to 0.04474, saving model to data/models/clean_w_dups_jcw.h5\n",
      "Epoch 169/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 5.7295e-04 - mae: 0.0179 - mse: 5.7295e-04 - val_loss: 0.0048 - val_mae: 0.0455 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00169: val_mae did not improve from 0.04474\n",
      "Epoch 170/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 4.0009e-04 - mae: 0.0148 - mse: 4.0009e-04 - val_loss: 0.0047 - val_mae: 0.0453 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00170: val_mae did not improve from 0.04474\n",
      "Epoch 171/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 3.7742e-04 - mae: 0.0145 - mse: 3.7742e-04 - val_loss: 0.0047 - val_mae: 0.0451 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00171: val_mae did not improve from 0.04474\n",
      "Epoch 172/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 3.9597e-04 - mae: 0.0147 - mse: 3.9597e-04 - val_loss: 0.0047 - val_mae: 0.0454 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00172: val_mae did not improve from 0.04474\n",
      "Epoch 173/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 3.9078e-04 - mae: 0.0146 - mse: 3.9078e-04 - val_loss: 0.0047 - val_mae: 0.0449 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00173: val_mae did not improve from 0.04474\n",
      "Epoch 174/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 4.0012e-04 - mae: 0.0150 - mse: 4.0012e-04 - val_loss: 0.0048 - val_mae: 0.0461 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00174: val_mae did not improve from 0.04474\n",
      "Epoch 175/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0013 - mae: 0.0265 - mse: 0.0013 - val_loss: 0.0050 - val_mae: 0.0467 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00175: val_mae did not improve from 0.04474\n",
      "Epoch 176/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 6.7008e-04 - mae: 0.0192 - mse: 6.7008e-04 - val_loss: 0.0049 - val_mae: 0.0459 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00176: val_mae did not improve from 0.04474\n",
      "Epoch 177/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 7.0547e-04 - mae: 0.0196 - mse: 7.0547e-04 - val_loss: 0.0048 - val_mae: 0.0458 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00177: val_mae did not improve from 0.04474\n",
      "Epoch 178/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 5.9255e-04 - mae: 0.0167 - mse: 5.9255e-04 - val_loss: 0.0047 - val_mae: 0.0454 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00178: val_mae did not improve from 0.04474\n",
      "Epoch 179/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 4.5429e-04 - mae: 0.0157 - mse: 4.5429e-04 - val_loss: 0.0048 - val_mae: 0.0454 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00179: val_mae did not improve from 0.04474\n",
      "Epoch 180/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 3.9082e-04 - mae: 0.0151 - mse: 3.9082e-04 - val_loss: 0.0047 - val_mae: 0.0446 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00180: val_mae improved from 0.04474 to 0.04461, saving model to data/models/clean_w_dups_jcw.h5\n",
      "Epoch 181/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 3.0293e-04 - mae: 0.0132 - mse: 3.0293e-04 - val_loss: 0.0046 - val_mae: 0.0445 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00181: val_mae improved from 0.04461 to 0.04446, saving model to data/models/clean_w_dups_jcw.h5\n",
      "Epoch 182/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 3.5791e-04 - mae: 0.0143 - mse: 3.5791e-04 - val_loss: 0.0048 - val_mae: 0.0455 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00182: val_mae did not improve from 0.04446\n",
      "Epoch 183/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 3.3573e-04 - mae: 0.0133 - mse: 3.3573e-04 - val_loss: 0.0048 - val_mae: 0.0457 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00183: val_mae did not improve from 0.04446\n",
      "Epoch 184/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 3.2420e-04 - mae: 0.0135 - mse: 3.2420e-04 - val_loss: 0.0047 - val_mae: 0.0447 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00184: val_mae did not improve from 0.04446\n",
      "Epoch 185/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 3.3429e-04 - mae: 0.0137 - mse: 3.3429e-04 - val_loss: 0.0048 - val_mae: 0.0453 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00185: val_mae did not improve from 0.04446\n",
      "Epoch 186/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 3.0727e-04 - mae: 0.0131 - mse: 3.0727e-04 - val_loss: 0.0049 - val_mae: 0.0466 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00186: val_mae did not improve from 0.04446\n",
      "Epoch 187/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.0018 - mae: 0.0316 - mse: 0.0018 - val_loss: 0.0050 - val_mae: 0.0472 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00187: val_mae did not improve from 0.04446\n",
      "Epoch 188/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 8.5843e-04 - mae: 0.0222 - mse: 8.5843e-04 - val_loss: 0.0049 - val_mae: 0.0461 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00188: val_mae did not improve from 0.04446\n",
      "Epoch 189/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 6.6071e-04 - mae: 0.0182 - mse: 6.6071e-04 - val_loss: 0.0048 - val_mae: 0.0456 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00189: val_mae did not improve from 0.04446\n",
      "Epoch 190/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 6.1323e-04 - mae: 0.0163 - mse: 6.1323e-04 - val_loss: 0.0048 - val_mae: 0.0456 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00190: val_mae did not improve from 0.04446\n",
      "Epoch 191/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 3.7132e-04 - mae: 0.0144 - mse: 3.7132e-04 - val_loss: 0.0047 - val_mae: 0.0450 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00191: val_mae did not improve from 0.04446\n",
      "Epoch 192/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 3.2559e-04 - mae: 0.0137 - mse: 3.2559e-04 - val_loss: 0.0047 - val_mae: 0.0455 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00192: val_mae did not improve from 0.04446\n",
      "Epoch 193/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 3.3006e-04 - mae: 0.0135 - mse: 3.3006e-04 - val_loss: 0.0047 - val_mae: 0.0451 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00193: val_mae did not improve from 0.04446\n",
      "Epoch 194/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 3.0632e-04 - mae: 0.0131 - mse: 3.0632e-04 - val_loss: 0.0047 - val_mae: 0.0449 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00194: val_mae did not improve from 0.04446\n",
      "Epoch 195/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 3.2092e-04 - mae: 0.0136 - mse: 3.2092e-04 - val_loss: 0.0047 - val_mae: 0.0452 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00195: val_mae did not improve from 0.04446\n",
      "Epoch 196/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 3.2565e-04 - mae: 0.0133 - mse: 3.2565e-04 - val_loss: 0.0048 - val_mae: 0.0453 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00196: val_mae did not improve from 0.04446\n",
      "Epoch 197/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 2.9844e-04 - mae: 0.0130 - mse: 2.9844e-04 - val_loss: 0.0048 - val_mae: 0.0453 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00197: val_mae did not improve from 0.04446\n",
      "Epoch 198/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 3.2623e-04 - mae: 0.0134 - mse: 3.2623e-04 - val_loss: 0.0047 - val_mae: 0.0450 - val_mse: 0.0047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00198: val_mae did not improve from 0.04446\n",
      "Epoch 199/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 3.8742e-04 - mae: 0.0143 - mse: 3.8742e-04 - val_loss: 0.0047 - val_mae: 0.0451 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00199: val_mae did not improve from 0.04446\n",
      "Epoch 200/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 3.6491e-04 - mae: 0.0141 - mse: 3.6491e-04 - val_loss: 0.0047 - val_mae: 0.0454 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00200: val_mae did not improve from 0.04446\n",
      "Epoch 201/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 4.0974e-04 - mae: 0.0154 - mse: 4.0974e-04 - val_loss: 0.0046 - val_mae: 0.0447 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00201: val_mae did not improve from 0.04446\n",
      "Epoch 202/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 3.8314e-04 - mae: 0.0143 - mse: 3.8314e-04 - val_loss: 0.0047 - val_mae: 0.0451 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00202: val_mae did not improve from 0.04446\n",
      "Epoch 203/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 2.8027e-04 - mae: 0.0125 - mse: 2.8027e-04 - val_loss: 0.0046 - val_mae: 0.0447 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00203: val_mae did not improve from 0.04446\n",
      "Epoch 204/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 3.8220e-04 - mae: 0.0144 - mse: 3.8220e-04 - val_loss: 0.0048 - val_mae: 0.0457 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00204: val_mae did not improve from 0.04446\n",
      "Epoch 205/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 3.8345e-04 - mae: 0.0148 - mse: 3.8345e-04 - val_loss: 0.0047 - val_mae: 0.0451 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00205: val_mae did not improve from 0.04446\n",
      "Epoch 206/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 3.3237e-04 - mae: 0.0135 - mse: 3.3237e-04 - val_loss: 0.0047 - val_mae: 0.0450 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00206: val_mae did not improve from 0.04446\n",
      "Epoch 207/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 3.0862e-04 - mae: 0.0128 - mse: 3.0862e-04 - val_loss: 0.0048 - val_mae: 0.0452 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00207: val_mae did not improve from 0.04446\n",
      "Epoch 208/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 3.6475e-04 - mae: 0.0137 - mse: 3.6475e-04 - val_loss: 0.0048 - val_mae: 0.0458 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00208: val_mae did not improve from 0.04446\n",
      "Epoch 209/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 6.1149e-04 - mae: 0.0182 - mse: 6.1149e-04 - val_loss: 0.0047 - val_mae: 0.0451 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00209: val_mae did not improve from 0.04446\n",
      "Epoch 210/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 6.7271e-04 - mae: 0.0191 - mse: 6.7271e-04 - val_loss: 0.0051 - val_mae: 0.0475 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00210: val_mae did not improve from 0.04446\n",
      "Epoch 211/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 5.2188e-04 - mae: 0.0167 - mse: 5.2188e-04 - val_loss: 0.0048 - val_mae: 0.0457 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00211: val_mae did not improve from 0.04446\n",
      "Epoch 00211: early stopping\n",
      "Done fitting\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_w_dups_jcw model created and file saved for future use.\n",
      "End model and train\n",
      "\n",
      "Opening file:  clean_w_outliers.p\n",
      "cleantrain/clean_w_outliers.p\n",
      "Train Shape: (7041, 31)\n",
      "Begin model and train:\n",
      "Model name: clean_w_outliers_jcw\n",
      "Scaling 7041 images...\n",
      "Scaling of 7041 observations complete.\n",
      "Index(['left_eye_center_x', 'left_eye_center_y', 'right_eye_center_x',\n",
      "       'right_eye_center_y', 'nose_tip_x', 'nose_tip_y',\n",
      "       'mouth_center_bottom_lip_x', 'mouth_center_bottom_lip_y', 'image'],\n",
      "      dtype='object')\n",
      "Begining the split of Train with all features\n",
      "Looking for model JW\n",
      "JW model file not found. Model creation beginning\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 32, 32, 32)        288       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 8, 8, 64)          8192      \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 2, 2, 128)         32768     \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 2, 2, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 8)                 4104      \n",
      "=================================================================\n",
      "Total params: 374,952\n",
      "Trainable params: 374,504\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "None\n",
      "Done compiling\n",
      "Epoch 1/300\n",
      "175/175 [==============================] - 4s 19ms/step - loss: 0.0993 - mae: 0.1911 - mse: 0.0993 - val_loss: 0.0118 - val_mae: 0.0811 - val_mse: 0.0118\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 0.08110, saving model to data/models/clean_w_outliers_jcw.h5\n",
      "Epoch 2/300\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0090 - mae: 0.0708 - mse: 0.0090 - val_loss: 0.0099 - val_mae: 0.0743 - val_mse: 0.0099\n",
      "\n",
      "Epoch 00002: val_mae improved from 0.08110 to 0.07427, saving model to data/models/clean_w_outliers_jcw.h5\n",
      "Epoch 3/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0077 - mae: 0.0638 - mse: 0.0077 - val_loss: 0.0083 - val_mae: 0.0662 - val_mse: 0.0083\n",
      "\n",
      "Epoch 00003: val_mae improved from 0.07427 to 0.06619, saving model to data/models/clean_w_outliers_jcw.h5\n",
      "Epoch 4/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0063 - mae: 0.0583 - mse: 0.0063 - val_loss: 0.0074 - val_mae: 0.0624 - val_mse: 0.0074\n",
      "\n",
      "Epoch 00004: val_mae improved from 0.06619 to 0.06242, saving model to data/models/clean_w_outliers_jcw.h5\n",
      "Epoch 5/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0061 - mae: 0.0566 - mse: 0.0061 - val_loss: 0.0070 - val_mae: 0.0605 - val_mse: 0.0070\n",
      "\n",
      "Epoch 00005: val_mae improved from 0.06242 to 0.06050, saving model to data/models/clean_w_outliers_jcw.h5\n",
      "Epoch 6/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0052 - mae: 0.0529 - mse: 0.0052 - val_loss: 0.0070 - val_mae: 0.0601 - val_mse: 0.0070\n",
      "\n",
      "Epoch 00006: val_mae improved from 0.06050 to 0.06006, saving model to data/models/clean_w_outliers_jcw.h5\n",
      "Epoch 7/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0054 - mae: 0.0529 - mse: 0.0054 - val_loss: 0.0071 - val_mae: 0.0616 - val_mse: 0.0071\n",
      "\n",
      "Epoch 00007: val_mae did not improve from 0.06006\n",
      "Epoch 8/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0048 - mae: 0.0507 - mse: 0.0048 - val_loss: 0.0071 - val_mae: 0.0603 - val_mse: 0.0071\n",
      "\n",
      "Epoch 00008: val_mae did not improve from 0.06006\n",
      "Epoch 9/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0044 - mae: 0.0490 - mse: 0.0044 - val_loss: 0.0076 - val_mae: 0.0628 - val_mse: 0.0076\n",
      "\n",
      "Epoch 00009: val_mae did not improve from 0.06006\n",
      "Epoch 10/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0043 - mae: 0.0484 - mse: 0.0043 - val_loss: 0.0068 - val_mae: 0.0587 - val_mse: 0.0068\n",
      "\n",
      "Epoch 00010: val_mae improved from 0.06006 to 0.05866, saving model to data/models/clean_w_outliers_jcw.h5\n",
      "Epoch 11/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0040 - mae: 0.0468 - mse: 0.0040 - val_loss: 0.0066 - val_mae: 0.0579 - val_mse: 0.0066\n",
      "\n",
      "Epoch 00011: val_mae improved from 0.05866 to 0.05795, saving model to data/models/clean_w_outliers_jcw.h5\n",
      "Epoch 12/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0039 - mae: 0.0455 - mse: 0.0039 - val_loss: 0.0065 - val_mae: 0.0574 - val_mse: 0.0065\n",
      "\n",
      "Epoch 00012: val_mae improved from 0.05795 to 0.05737, saving model to data/models/clean_w_outliers_jcw.h5\n",
      "Epoch 13/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.0035 - mae: 0.0441 - mse: 0.0035 - val_loss: 0.0068 - val_mae: 0.0582 - val_mse: 0.0068\n",
      "\n",
      "Epoch 00013: val_mae did not improve from 0.05737\n",
      "Epoch 14/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0033 - mae: 0.0429 - mse: 0.0033 - val_loss: 0.0069 - val_mae: 0.0585 - val_mse: 0.0069\n",
      "\n",
      "Epoch 00014: val_mae did not improve from 0.05737\n",
      "Epoch 15/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0033 - mae: 0.0425 - mse: 0.0033 - val_loss: 0.0062 - val_mae: 0.0556 - val_mse: 0.0062\n",
      "\n",
      "Epoch 00015: val_mae improved from 0.05737 to 0.05563, saving model to data/models/clean_w_outliers_jcw.h5\n",
      "Epoch 16/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0031 - mae: 0.0418 - mse: 0.0031 - val_loss: 0.0061 - val_mae: 0.0547 - val_mse: 0.0061\n",
      "\n",
      "Epoch 00016: val_mae improved from 0.05563 to 0.05470, saving model to data/models/clean_w_outliers_jcw.h5\n",
      "Epoch 17/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0031 - mae: 0.0412 - mse: 0.0031 - val_loss: 0.0074 - val_mae: 0.0627 - val_mse: 0.0074\n",
      "\n",
      "Epoch 00017: val_mae did not improve from 0.05470\n",
      "Epoch 18/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0030 - mae: 0.0410 - mse: 0.0030 - val_loss: 0.0062 - val_mae: 0.0553 - val_mse: 0.0062\n",
      "\n",
      "Epoch 00018: val_mae did not improve from 0.05470\n",
      "Epoch 19/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0027 - mae: 0.0393 - mse: 0.0027 - val_loss: 0.0061 - val_mae: 0.0549 - val_mse: 0.0061\n",
      "\n",
      "Epoch 00019: val_mae did not improve from 0.05470\n",
      "Epoch 20/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0026 - mae: 0.0381 - mse: 0.0026 - val_loss: 0.0059 - val_mae: 0.0534 - val_mse: 0.0059\n",
      "\n",
      "Epoch 00020: val_mae improved from 0.05470 to 0.05339, saving model to data/models/clean_w_outliers_jcw.h5\n",
      "Epoch 21/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0025 - mae: 0.0377 - mse: 0.0025 - val_loss: 0.0060 - val_mae: 0.0543 - val_mse: 0.0060\n",
      "\n",
      "Epoch 00021: val_mae did not improve from 0.05339\n",
      "Epoch 22/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0023 - mae: 0.0363 - mse: 0.0023 - val_loss: 0.0060 - val_mae: 0.0540 - val_mse: 0.0060\n",
      "\n",
      "Epoch 00022: val_mae did not improve from 0.05339\n",
      "Epoch 23/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0026 - mae: 0.0380 - mse: 0.0026 - val_loss: 0.0060 - val_mae: 0.0534 - val_mse: 0.0060\n",
      "\n",
      "Epoch 00023: val_mae did not improve from 0.05339\n",
      "Epoch 24/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.0025 - mae: 0.0374 - mse: 0.0025 - val_loss: 0.0062 - val_mae: 0.0543 - val_mse: 0.0062\n",
      "\n",
      "Epoch 00024: val_mae did not improve from 0.05339\n",
      "Epoch 25/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0024 - mae: 0.0368 - mse: 0.0024 - val_loss: 0.0060 - val_mae: 0.0537 - val_mse: 0.0060\n",
      "\n",
      "Epoch 00025: val_mae did not improve from 0.05339\n",
      "Epoch 26/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0022 - mae: 0.0352 - mse: 0.0022 - val_loss: 0.0063 - val_mae: 0.0548 - val_mse: 0.0063\n",
      "\n",
      "Epoch 00026: val_mae did not improve from 0.05339\n",
      "Epoch 27/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0025 - mae: 0.0368 - mse: 0.0025 - val_loss: 0.0061 - val_mae: 0.0550 - val_mse: 0.0061\n",
      "\n",
      "Epoch 00027: val_mae did not improve from 0.05339\n",
      "Epoch 28/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0021 - mae: 0.0343 - mse: 0.0021 - val_loss: 0.0060 - val_mae: 0.0538 - val_mse: 0.0060\n",
      "\n",
      "Epoch 00028: val_mae did not improve from 0.05339\n",
      "Epoch 29/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.0021 - mae: 0.0339 - mse: 0.0021 - val_loss: 0.0057 - val_mae: 0.0518 - val_mse: 0.0057\n",
      "\n",
      "Epoch 00029: val_mae improved from 0.05339 to 0.05184, saving model to data/models/clean_w_outliers_jcw.h5\n",
      "Epoch 30/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.0020 - mae: 0.0329 - mse: 0.0020 - val_loss: 0.0063 - val_mae: 0.0558 - val_mse: 0.0063\n",
      "\n",
      "Epoch 00030: val_mae did not improve from 0.05184\n",
      "Epoch 31/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0018 - mae: 0.0319 - mse: 0.0018 - val_loss: 0.0059 - val_mae: 0.0529 - val_mse: 0.0059\n",
      "\n",
      "Epoch 00031: val_mae did not improve from 0.05184\n",
      "Epoch 32/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0019 - mae: 0.0317 - mse: 0.0019 - val_loss: 0.0059 - val_mae: 0.0517 - val_mse: 0.0059\n",
      "\n",
      "Epoch 00032: val_mae improved from 0.05184 to 0.05168, saving model to data/models/clean_w_outliers_jcw.h5\n",
      "Epoch 33/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0016 - mae: 0.0306 - mse: 0.0016 - val_loss: 0.0057 - val_mae: 0.0522 - val_mse: 0.0057\n",
      "\n",
      "Epoch 00033: val_mae did not improve from 0.05168\n",
      "Epoch 34/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0016 - mae: 0.0305 - mse: 0.0016 - val_loss: 0.0054 - val_mae: 0.0497 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00034: val_mae improved from 0.05168 to 0.04975, saving model to data/models/clean_w_outliers_jcw.h5\n",
      "Epoch 35/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0017 - mae: 0.0311 - mse: 0.0017 - val_loss: 0.0062 - val_mae: 0.0539 - val_mse: 0.0062\n",
      "\n",
      "Epoch 00035: val_mae did not improve from 0.04975\n",
      "Epoch 36/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0019 - mae: 0.0320 - mse: 0.0019 - val_loss: 0.0059 - val_mae: 0.0526 - val_mse: 0.0059\n",
      "\n",
      "Epoch 00036: val_mae did not improve from 0.04975\n",
      "Epoch 37/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0019 - mae: 0.0323 - mse: 0.0019 - val_loss: 0.0056 - val_mae: 0.0517 - val_mse: 0.0056\n",
      "\n",
      "Epoch 00037: val_mae did not improve from 0.04975\n",
      "Epoch 38/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.0020 - mae: 0.0328 - mse: 0.0020 - val_loss: 0.0056 - val_mae: 0.0521 - val_mse: 0.0056\n",
      "\n",
      "Epoch 00038: val_mae did not improve from 0.04975\n",
      "Epoch 39/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.0019 - mae: 0.0320 - mse: 0.0019 - val_loss: 0.0052 - val_mae: 0.0496 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00039: val_mae improved from 0.04975 to 0.04959, saving model to data/models/clean_w_outliers_jcw.h5\n",
      "Epoch 40/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.0016 - mae: 0.0300 - mse: 0.0016 - val_loss: 0.0053 - val_mae: 0.0499 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00040: val_mae did not improve from 0.04959\n",
      "Epoch 41/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.0014 - mae: 0.0285 - mse: 0.0014 - val_loss: 0.0055 - val_mae: 0.0510 - val_mse: 0.0055\n",
      "\n",
      "Epoch 00041: val_mae did not improve from 0.04959\n",
      "Epoch 42/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.0015 - mae: 0.0288 - mse: 0.0015 - val_loss: 0.0052 - val_mae: 0.0493 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00042: val_mae improved from 0.04959 to 0.04931, saving model to data/models/clean_w_outliers_jcw.h5\n",
      "Epoch 43/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0015 - mae: 0.0285 - mse: 0.0015 - val_loss: 0.0053 - val_mae: 0.0498 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00043: val_mae did not improve from 0.04931\n",
      "Epoch 44/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0017 - mae: 0.0298 - mse: 0.0017 - val_loss: 0.0053 - val_mae: 0.0495 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00044: val_mae did not improve from 0.04931\n",
      "Epoch 45/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0018 - mae: 0.0309 - mse: 0.0018 - val_loss: 0.0054 - val_mae: 0.0498 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00045: val_mae did not improve from 0.04931\n",
      "Epoch 46/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.0018 - mae: 0.0296 - mse: 0.0018 - val_loss: 0.0053 - val_mae: 0.0494 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00046: val_mae did not improve from 0.04931\n",
      "Epoch 47/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0016 - mae: 0.0297 - mse: 0.0016 - val_loss: 0.0051 - val_mae: 0.0482 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00047: val_mae improved from 0.04931 to 0.04820, saving model to data/models/clean_w_outliers_jcw.h5\n",
      "Epoch 48/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.0014 - mae: 0.0276 - mse: 0.0014 - val_loss: 0.0050 - val_mae: 0.0475 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00048: val_mae improved from 0.04820 to 0.04755, saving model to data/models/clean_w_outliers_jcw.h5\n",
      "Epoch 49/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0018 - mae: 0.0292 - mse: 0.0018 - val_loss: 0.0050 - val_mae: 0.0471 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00049: val_mae improved from 0.04755 to 0.04713, saving model to data/models/clean_w_outliers_jcw.h5\n",
      "Epoch 50/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0013 - mae: 0.0267 - mse: 0.0013 - val_loss: 0.0050 - val_mae: 0.0474 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00050: val_mae did not improve from 0.04713\n",
      "Epoch 51/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0013 - mae: 0.0264 - mse: 0.0013 - val_loss: 0.0052 - val_mae: 0.0484 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00051: val_mae did not improve from 0.04713\n",
      "Epoch 52/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0012 - mae: 0.0259 - mse: 0.0012 - val_loss: 0.0052 - val_mae: 0.0491 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00052: val_mae did not improve from 0.04713\n",
      "Epoch 53/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0012 - mae: 0.0257 - mse: 0.0012 - val_loss: 0.0051 - val_mae: 0.0485 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00053: val_mae did not improve from 0.04713\n",
      "Epoch 54/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.0017 - mae: 0.0284 - mse: 0.0017 - val_loss: 0.0051 - val_mae: 0.0481 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00054: val_mae did not improve from 0.04713\n",
      "Epoch 55/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0012 - mae: 0.0257 - mse: 0.0012 - val_loss: 0.0052 - val_mae: 0.0482 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00055: val_mae did not improve from 0.04713\n",
      "Epoch 56/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.0012 - mae: 0.0252 - mse: 0.0012 - val_loss: 0.0050 - val_mae: 0.0473 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00056: val_mae did not improve from 0.04713\n",
      "Epoch 57/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0011 - mae: 0.0246 - mse: 0.0011 - val_loss: 0.0050 - val_mae: 0.0476 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00057: val_mae did not improve from 0.04713\n",
      "Epoch 58/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.0010 - mae: 0.0241 - mse: 0.0010 - val_loss: 0.0049 - val_mae: 0.0468 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00058: val_mae improved from 0.04713 to 0.04681, saving model to data/models/clean_w_outliers_jcw.h5\n",
      "Epoch 59/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0015 - mae: 0.0272 - mse: 0.0015 - val_loss: 0.0053 - val_mae: 0.0493 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00059: val_mae did not improve from 0.04681\n",
      "Epoch 60/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0014 - mae: 0.0264 - mse: 0.0014 - val_loss: 0.0050 - val_mae: 0.0477 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00060: val_mae did not improve from 0.04681\n",
      "Epoch 61/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0011 - mae: 0.0246 - mse: 0.0011 - val_loss: 0.0052 - val_mae: 0.0482 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00061: val_mae did not improve from 0.04681\n",
      "Epoch 62/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.0011 - mae: 0.0241 - mse: 0.0011 - val_loss: 0.0050 - val_mae: 0.0473 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00062: val_mae did not improve from 0.04681\n",
      "Epoch 63/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0010 - mae: 0.0239 - mse: 0.0010 - val_loss: 0.0051 - val_mae: 0.0485 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00063: val_mae did not improve from 0.04681\n",
      "Epoch 64/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0011 - mae: 0.0239 - mse: 0.0011 - val_loss: 0.0050 - val_mae: 0.0476 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00064: val_mae did not improve from 0.04681\n",
      "Epoch 65/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 9.1997e-04 - mae: 0.0227 - mse: 9.1997e-04 - val_loss: 0.0048 - val_mae: 0.0464 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00065: val_mae improved from 0.04681 to 0.04644, saving model to data/models/clean_w_outliers_jcw.h5\n",
      "Epoch 66/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 9.9386e-04 - mae: 0.0231 - mse: 9.9386e-04 - val_loss: 0.0052 - val_mae: 0.0486 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00066: val_mae did not improve from 0.04644\n",
      "Epoch 67/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0011 - mae: 0.0242 - mse: 0.0011 - val_loss: 0.0050 - val_mae: 0.0477 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00067: val_mae did not improve from 0.04644\n",
      "Epoch 68/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0011 - mae: 0.0242 - mse: 0.0011 - val_loss: 0.0051 - val_mae: 0.0478 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00068: val_mae did not improve from 0.04644\n",
      "Epoch 69/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0011 - mae: 0.0227 - mse: 0.0011 - val_loss: 0.0048 - val_mae: 0.0460 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00069: val_mae improved from 0.04644 to 0.04596, saving model to data/models/clean_w_outliers_jcw.h5\n",
      "Epoch 70/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0011 - mae: 0.0230 - mse: 0.0011 - val_loss: 0.0051 - val_mae: 0.0482 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00070: val_mae did not improve from 0.04596\n",
      "Epoch 71/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 9.0927e-04 - mae: 0.0221 - mse: 9.0927e-04 - val_loss: 0.0052 - val_mae: 0.0475 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00071: val_mae did not improve from 0.04596\n",
      "Epoch 72/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 8.9508e-04 - mae: 0.0222 - mse: 8.9508e-04 - val_loss: 0.0049 - val_mae: 0.0467 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00072: val_mae did not improve from 0.04596\n",
      "Epoch 73/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0012 - mae: 0.0234 - mse: 0.0012 - val_loss: 0.0047 - val_mae: 0.0450 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00073: val_mae improved from 0.04596 to 0.04499, saving model to data/models/clean_w_outliers_jcw.h5\n",
      "Epoch 74/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 9.9205e-04 - mae: 0.0221 - mse: 9.9205e-04 - val_loss: 0.0050 - val_mae: 0.0469 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00074: val_mae did not improve from 0.04499\n",
      "Epoch 75/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 7.8669e-04 - mae: 0.0212 - mse: 7.8669e-04 - val_loss: 0.0050 - val_mae: 0.0473 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00075: val_mae did not improve from 0.04499\n",
      "Epoch 76/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 8.3736e-04 - mae: 0.0216 - mse: 8.3736e-04 - val_loss: 0.0049 - val_mae: 0.0462 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00076: val_mae did not improve from 0.04499\n",
      "Epoch 77/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 8.6583e-04 - mae: 0.0216 - mse: 8.6583e-04 - val_loss: 0.0048 - val_mae: 0.0460 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00077: val_mae did not improve from 0.04499\n",
      "Epoch 78/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 8.7671e-04 - mae: 0.0210 - mse: 8.7671e-04 - val_loss: 0.0051 - val_mae: 0.0472 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00078: val_mae did not improve from 0.04499\n",
      "Epoch 79/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 9.6211e-04 - mae: 0.0215 - mse: 9.6211e-04 - val_loss: 0.0048 - val_mae: 0.0459 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00079: val_mae did not improve from 0.04499\n",
      "Epoch 80/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 8.3969e-04 - mae: 0.0214 - mse: 8.3969e-04 - val_loss: 0.0048 - val_mae: 0.0459 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00080: val_mae did not improve from 0.04499\n",
      "Epoch 81/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 7.2265e-04 - mae: 0.0202 - mse: 7.2265e-04 - val_loss: 0.0052 - val_mae: 0.0489 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00081: val_mae did not improve from 0.04499\n",
      "Epoch 82/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0014 - mae: 0.0253 - mse: 0.0014 - val_loss: 0.0048 - val_mae: 0.0458 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00082: val_mae did not improve from 0.04499\n",
      "Epoch 83/300\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 0.0011 - mae: 0.0224 - mse: 0.0011 - val_loss: 0.0047 - val_mae: 0.0453 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00083: val_mae did not improve from 0.04499\n",
      "Epoch 84/300\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 0.0010 - mae: 0.0222 - mse: 0.0010 - val_loss: 0.0047 - val_mae: 0.0456 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00084: val_mae did not improve from 0.04499\n",
      "Epoch 85/300\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 7.9185e-04 - mae: 0.0209 - mse: 7.9185e-04 - val_loss: 0.0047 - val_mae: 0.0455 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00085: val_mae did not improve from 0.04499\n",
      "Epoch 86/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 7.2188e-04 - mae: 0.0198 - mse: 7.2188e-04 - val_loss: 0.0049 - val_mae: 0.0469 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00086: val_mae did not improve from 0.04499\n",
      "Epoch 87/300\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 7.3720e-04 - mae: 0.0201 - mse: 7.3720e-04 - val_loss: 0.0048 - val_mae: 0.0462 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00087: val_mae did not improve from 0.04499\n",
      "Epoch 88/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 8.3501e-04 - mae: 0.0201 - mse: 8.3501e-04 - val_loss: 0.0047 - val_mae: 0.0449 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00088: val_mae improved from 0.04499 to 0.04493, saving model to data/models/clean_w_outliers_jcw.h5\n",
      "Epoch 89/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 7.1118e-04 - mae: 0.0195 - mse: 7.1118e-04 - val_loss: 0.0050 - val_mae: 0.0468 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00089: val_mae did not improve from 0.04493\n",
      "Epoch 90/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 6.8872e-04 - mae: 0.0192 - mse: 6.8872e-04 - val_loss: 0.0049 - val_mae: 0.0462 - val_mse: 0.0049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00090: val_mae did not improve from 0.04493\n",
      "Epoch 91/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 7.5407e-04 - mae: 0.0200 - mse: 7.5407e-04 - val_loss: 0.0048 - val_mae: 0.0460 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00091: val_mae did not improve from 0.04493\n",
      "Epoch 92/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 7.1805e-04 - mae: 0.0193 - mse: 7.1805e-04 - val_loss: 0.0047 - val_mae: 0.0455 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00092: val_mae did not improve from 0.04493\n",
      "Epoch 93/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 7.8198e-04 - mae: 0.0202 - mse: 7.8198e-04 - val_loss: 0.0046 - val_mae: 0.0449 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00093: val_mae improved from 0.04493 to 0.04491, saving model to data/models/clean_w_outliers_jcw.h5\n",
      "Epoch 94/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 6.5671e-04 - mae: 0.0190 - mse: 6.5671e-04 - val_loss: 0.0048 - val_mae: 0.0457 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00094: val_mae did not improve from 0.04491\n",
      "Epoch 95/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 5.8657e-04 - mae: 0.0182 - mse: 5.8657e-04 - val_loss: 0.0046 - val_mae: 0.0446 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00095: val_mae improved from 0.04491 to 0.04464, saving model to data/models/clean_w_outliers_jcw.h5\n",
      "Epoch 96/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 7.3666e-04 - mae: 0.0194 - mse: 7.3666e-04 - val_loss: 0.0046 - val_mae: 0.0447 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00096: val_mae did not improve from 0.04464\n",
      "Epoch 97/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 7.1727e-04 - mae: 0.0189 - mse: 7.1727e-04 - val_loss: 0.0047 - val_mae: 0.0456 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00097: val_mae did not improve from 0.04464\n",
      "Epoch 98/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 5.7993e-04 - mae: 0.0181 - mse: 5.7993e-04 - val_loss: 0.0046 - val_mae: 0.0446 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00098: val_mae improved from 0.04464 to 0.04464, saving model to data/models/clean_w_outliers_jcw.h5\n",
      "Epoch 99/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 7.7033e-04 - mae: 0.0189 - mse: 7.7033e-04 - val_loss: 0.0046 - val_mae: 0.0447 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00099: val_mae did not improve from 0.04464\n",
      "Epoch 100/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 7.2325e-04 - mae: 0.0190 - mse: 7.2325e-04 - val_loss: 0.0047 - val_mae: 0.0449 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00100: val_mae did not improve from 0.04464\n",
      "Epoch 101/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 6.1840e-04 - mae: 0.0184 - mse: 6.1840e-04 - val_loss: 0.0047 - val_mae: 0.0449 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00101: val_mae did not improve from 0.04464\n",
      "Epoch 102/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 5.8093e-04 - mae: 0.0178 - mse: 5.8093e-04 - val_loss: 0.0046 - val_mae: 0.0447 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00102: val_mae did not improve from 0.04464\n",
      "Epoch 103/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 5.6423e-04 - mae: 0.0176 - mse: 5.6423e-04 - val_loss: 0.0046 - val_mae: 0.0442 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00103: val_mae improved from 0.04464 to 0.04421, saving model to data/models/clean_w_outliers_jcw.h5\n",
      "Epoch 104/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 5.6747e-04 - mae: 0.0177 - mse: 5.6747e-04 - val_loss: 0.0046 - val_mae: 0.0443 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00104: val_mae did not improve from 0.04421\n",
      "Epoch 105/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 6.3362e-04 - mae: 0.0182 - mse: 6.3362e-04 - val_loss: 0.0047 - val_mae: 0.0450 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00105: val_mae did not improve from 0.04421\n",
      "Epoch 106/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 6.9990e-04 - mae: 0.0189 - mse: 6.9990e-04 - val_loss: 0.0046 - val_mae: 0.0446 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00106: val_mae did not improve from 0.04421\n",
      "Epoch 107/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 6.8249e-04 - mae: 0.0189 - mse: 6.8249e-04 - val_loss: 0.0047 - val_mae: 0.0452 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00107: val_mae did not improve from 0.04421\n",
      "Epoch 108/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 6.5503e-04 - mae: 0.0187 - mse: 6.5503e-04 - val_loss: 0.0046 - val_mae: 0.0446 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00108: val_mae did not improve from 0.04421\n",
      "Epoch 109/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 6.0381e-04 - mae: 0.0179 - mse: 6.0381e-04 - val_loss: 0.0046 - val_mae: 0.0448 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00109: val_mae did not improve from 0.04421\n",
      "Epoch 110/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 6.6024e-04 - mae: 0.0182 - mse: 6.6024e-04 - val_loss: 0.0049 - val_mae: 0.0460 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00110: val_mae did not improve from 0.04421\n",
      "Epoch 111/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 6.8407e-04 - mae: 0.0181 - mse: 6.8407e-04 - val_loss: 0.0046 - val_mae: 0.0447 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00111: val_mae did not improve from 0.04421\n",
      "Epoch 112/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 5.1706e-04 - mae: 0.0170 - mse: 5.1706e-04 - val_loss: 0.0046 - val_mae: 0.0445 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00112: val_mae did not improve from 0.04421\n",
      "Epoch 113/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 5.1278e-04 - mae: 0.0167 - mse: 5.1278e-04 - val_loss: 0.0047 - val_mae: 0.0448 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00113: val_mae did not improve from 0.04421\n",
      "Epoch 114/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 5.1480e-04 - mae: 0.0168 - mse: 5.1480e-04 - val_loss: 0.0045 - val_mae: 0.0439 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00114: val_mae improved from 0.04421 to 0.04386, saving model to data/models/clean_w_outliers_jcw.h5\n",
      "Epoch 115/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 5.0729e-04 - mae: 0.0168 - mse: 5.0729e-04 - val_loss: 0.0046 - val_mae: 0.0446 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00115: val_mae did not improve from 0.04386\n",
      "Epoch 116/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 5.8235e-04 - mae: 0.0169 - mse: 5.8235e-04 - val_loss: 0.0048 - val_mae: 0.0456 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00116: val_mae did not improve from 0.04386\n",
      "Epoch 117/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 5.2806e-04 - mae: 0.0169 - mse: 5.2806e-04 - val_loss: 0.0046 - val_mae: 0.0447 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00117: val_mae did not improve from 0.04386\n",
      "Epoch 118/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 5.3966e-04 - mae: 0.0171 - mse: 5.3966e-04 - val_loss: 0.0046 - val_mae: 0.0446 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00118: val_mae did not improve from 0.04386\n",
      "Epoch 119/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 5.7615e-04 - mae: 0.0171 - mse: 5.7615e-04 - val_loss: 0.0047 - val_mae: 0.0449 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00119: val_mae did not improve from 0.04386\n",
      "Epoch 120/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 5.6988e-04 - mae: 0.0171 - mse: 5.6988e-04 - val_loss: 0.0047 - val_mae: 0.0448 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00120: val_mae did not improve from 0.04386\n",
      "Epoch 121/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 4.5145e-04 - mae: 0.0160 - mse: 4.5145e-04 - val_loss: 0.0048 - val_mae: 0.0451 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00121: val_mae did not improve from 0.04386\n",
      "Epoch 122/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 5.9972e-04 - mae: 0.0177 - mse: 5.9972e-04 - val_loss: 0.0046 - val_mae: 0.0443 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00122: val_mae did not improve from 0.04386\n",
      "Epoch 123/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 5.2930e-04 - mae: 0.0169 - mse: 5.2930e-04 - val_loss: 0.0045 - val_mae: 0.0440 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00123: val_mae did not improve from 0.04386\n",
      "Epoch 124/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 5.3475e-04 - mae: 0.0164 - mse: 5.3475e-04 - val_loss: 0.0046 - val_mae: 0.0446 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00124: val_mae did not improve from 0.04386\n",
      "Epoch 125/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 4.9883e-04 - mae: 0.0165 - mse: 4.9883e-04 - val_loss: 0.0046 - val_mae: 0.0444 - val_mse: 0.0046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00125: val_mae did not improve from 0.04386\n",
      "Epoch 126/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 4.7154e-04 - mae: 0.0161 - mse: 4.7154e-04 - val_loss: 0.0047 - val_mae: 0.0453 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00126: val_mae did not improve from 0.04386\n",
      "Epoch 127/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 4.5992e-04 - mae: 0.0160 - mse: 4.5992e-04 - val_loss: 0.0046 - val_mae: 0.0444 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00127: val_mae did not improve from 0.04386\n",
      "Epoch 128/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 5.7764e-04 - mae: 0.0169 - mse: 5.7764e-04 - val_loss: 0.0046 - val_mae: 0.0440 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00128: val_mae did not improve from 0.04386\n",
      "Epoch 129/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 5.3597e-04 - mae: 0.0163 - mse: 5.3597e-04 - val_loss: 0.0046 - val_mae: 0.0441 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00129: val_mae did not improve from 0.04386\n",
      "Epoch 130/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 4.4968e-04 - mae: 0.0156 - mse: 4.4968e-04 - val_loss: 0.0047 - val_mae: 0.0448 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00130: val_mae did not improve from 0.04386\n",
      "Epoch 131/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 4.2240e-04 - mae: 0.0154 - mse: 4.2240e-04 - val_loss: 0.0047 - val_mae: 0.0446 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00131: val_mae did not improve from 0.04386\n",
      "Epoch 132/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 4.3168e-04 - mae: 0.0154 - mse: 4.3168e-04 - val_loss: 0.0046 - val_mae: 0.0444 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00132: val_mae did not improve from 0.04386\n",
      "Epoch 133/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 4.5832e-04 - mae: 0.0159 - mse: 4.5832e-04 - val_loss: 0.0046 - val_mae: 0.0444 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00133: val_mae did not improve from 0.04386\n",
      "Epoch 134/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 5.0514e-04 - mae: 0.0162 - mse: 5.0514e-04 - val_loss: 0.0045 - val_mae: 0.0440 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00134: val_mae did not improve from 0.04386\n",
      "Epoch 135/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 4.8445e-04 - mae: 0.0159 - mse: 4.8445e-04 - val_loss: 0.0046 - val_mae: 0.0439 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00135: val_mae improved from 0.04386 to 0.04385, saving model to data/models/clean_w_outliers_jcw.h5\n",
      "Epoch 136/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 4.9463e-04 - mae: 0.0158 - mse: 4.9463e-04 - val_loss: 0.0048 - val_mae: 0.0452 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00136: val_mae did not improve from 0.04385\n",
      "Epoch 137/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 4.0942e-04 - mae: 0.0151 - mse: 4.0942e-04 - val_loss: 0.0048 - val_mae: 0.0455 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00137: val_mae did not improve from 0.04385\n",
      "Epoch 138/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 3.9899e-04 - mae: 0.0149 - mse: 3.9899e-04 - val_loss: 0.0046 - val_mae: 0.0446 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00138: val_mae did not improve from 0.04385\n",
      "Epoch 139/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 4.2586e-04 - mae: 0.0154 - mse: 4.2586e-04 - val_loss: 0.0047 - val_mae: 0.0445 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00139: val_mae did not improve from 0.04385\n",
      "Epoch 140/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 4.3024e-04 - mae: 0.0154 - mse: 4.3024e-04 - val_loss: 0.0046 - val_mae: 0.0445 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00140: val_mae did not improve from 0.04385\n",
      "Epoch 141/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 4.5395e-04 - mae: 0.0157 - mse: 4.5395e-04 - val_loss: 0.0045 - val_mae: 0.0438 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00141: val_mae improved from 0.04385 to 0.04378, saving model to data/models/clean_w_outliers_jcw.h5\n",
      "Epoch 142/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 4.4311e-04 - mae: 0.0156 - mse: 4.4311e-04 - val_loss: 0.0046 - val_mae: 0.0444 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00142: val_mae did not improve from 0.04378\n",
      "Epoch 143/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 4.4848e-04 - mae: 0.0158 - mse: 4.4848e-04 - val_loss: 0.0046 - val_mae: 0.0442 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00143: val_mae did not improve from 0.04378\n",
      "Epoch 144/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 4.0823e-04 - mae: 0.0149 - mse: 4.0823e-04 - val_loss: 0.0047 - val_mae: 0.0449 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00144: val_mae did not improve from 0.04378\n",
      "Epoch 00144: early stopping\n",
      "Done fitting\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_w_outliers_jcw model created and file saved for future use.\n",
      "End model and train\n",
      "\n",
      "Opening file:  clean_o_dups.p\n",
      "cleantrain/clean_o_dups.p\n",
      "Train Shape: (6483, 31)\n",
      "Begin model and train:\n",
      "Model name: clean_o_dups_jcw\n",
      "Scaling 6483 images...\n",
      "Scaling of 6483 observations complete.\n",
      "Index(['left_eye_center_x', 'left_eye_center_y', 'right_eye_center_x',\n",
      "       'right_eye_center_y', 'nose_tip_x', 'nose_tip_y',\n",
      "       'mouth_center_bottom_lip_x', 'mouth_center_bottom_lip_y', 'image'],\n",
      "      dtype='object')\n",
      "Begining the split of Train with all features\n",
      "Looking for model JW\n",
      "JW model file not found. Model creation beginning\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 32, 32, 32)        288       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 8, 8, 64)          8192      \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 2, 2, 128)         32768     \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 2, 2, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 8)                 4104      \n",
      "=================================================================\n",
      "Total params: 374,952\n",
      "Trainable params: 374,504\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "None\n",
      "Done compiling\n",
      "Epoch 1/300\n",
      "161/161 [==============================] - 4s 22ms/step - loss: 0.0931 - mae: 0.1849 - mse: 0.0931 - val_loss: 0.0112 - val_mae: 0.0793 - val_mse: 0.0112\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 0.07929, saving model to data/models/clean_o_dups_jcw.h5\n",
      "Epoch 2/300\n",
      "161/161 [==============================] - 3s 17ms/step - loss: 0.0094 - mae: 0.0713 - mse: 0.0094 - val_loss: 0.0098 - val_mae: 0.0754 - val_mse: 0.0098\n",
      "\n",
      "Epoch 00002: val_mae improved from 0.07929 to 0.07541, saving model to data/models/clean_o_dups_jcw.h5\n",
      "Epoch 3/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 0.0073 - mae: 0.0629 - mse: 0.0073 - val_loss: 0.0078 - val_mae: 0.0650 - val_mse: 0.0078\n",
      "\n",
      "Epoch 00003: val_mae improved from 0.07541 to 0.06501, saving model to data/models/clean_o_dups_jcw.h5\n",
      "Epoch 4/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 0.0063 - mae: 0.0575 - mse: 0.0063 - val_loss: 0.0076 - val_mae: 0.0634 - val_mse: 0.0076\n",
      "\n",
      "Epoch 00004: val_mae improved from 0.06501 to 0.06338, saving model to data/models/clean_o_dups_jcw.h5\n",
      "Epoch 5/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 0.0058 - mae: 0.0555 - mse: 0.0058 - val_loss: 0.0074 - val_mae: 0.0623 - val_mse: 0.0074\n",
      "\n",
      "Epoch 00005: val_mae improved from 0.06338 to 0.06234, saving model to data/models/clean_o_dups_jcw.h5\n",
      "Epoch 6/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 0.0055 - mae: 0.0534 - mse: 0.0055 - val_loss: 0.0074 - val_mae: 0.0624 - val_mse: 0.0074\n",
      "\n",
      "Epoch 00006: val_mae did not improve from 0.06234\n",
      "Epoch 7/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0051 - mae: 0.0517 - mse: 0.0051 - val_loss: 0.0072 - val_mae: 0.0612 - val_mse: 0.0072\n",
      "\n",
      "Epoch 00007: val_mae improved from 0.06234 to 0.06119, saving model to data/models/clean_o_dups_jcw.h5\n",
      "Epoch 8/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0048 - mae: 0.0503 - mse: 0.0048 - val_loss: 0.0073 - val_mae: 0.0613 - val_mse: 0.0073\n",
      "\n",
      "Epoch 00008: val_mae did not improve from 0.06119\n",
      "Epoch 9/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0045 - mae: 0.0494 - mse: 0.0045 - val_loss: 0.0074 - val_mae: 0.0615 - val_mse: 0.0074\n",
      "\n",
      "Epoch 00009: val_mae did not improve from 0.06119\n",
      "Epoch 10/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0041 - mae: 0.0471 - mse: 0.0041 - val_loss: 0.0068 - val_mae: 0.0590 - val_mse: 0.0068\n",
      "\n",
      "Epoch 00010: val_mae improved from 0.06119 to 0.05899, saving model to data/models/clean_o_dups_jcw.h5\n",
      "Epoch 11/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0039 - mae: 0.0462 - mse: 0.0039 - val_loss: 0.0093 - val_mae: 0.0703 - val_mse: 0.0093\n",
      "\n",
      "Epoch 00011: val_mae did not improve from 0.05899\n",
      "Epoch 12/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0037 - mae: 0.0452 - mse: 0.0037 - val_loss: 0.0067 - val_mae: 0.0587 - val_mse: 0.0067\n",
      "\n",
      "Epoch 00012: val_mae improved from 0.05899 to 0.05868, saving model to data/models/clean_o_dups_jcw.h5\n",
      "Epoch 13/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0034 - mae: 0.0434 - mse: 0.0034 - val_loss: 0.0071 - val_mae: 0.0598 - val_mse: 0.0071\n",
      "\n",
      "Epoch 00013: val_mae did not improve from 0.05868\n",
      "Epoch 14/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 0.0033 - mae: 0.0430 - mse: 0.0033 - val_loss: 0.0070 - val_mae: 0.0599 - val_mse: 0.0070\n",
      "\n",
      "Epoch 00014: val_mae did not improve from 0.05868\n",
      "Epoch 15/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 0.0034 - mae: 0.0427 - mse: 0.0034 - val_loss: 0.0081 - val_mae: 0.0651 - val_mse: 0.0081\n",
      "\n",
      "Epoch 00015: val_mae did not improve from 0.05868\n",
      "Epoch 16/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 0.0029 - mae: 0.0401 - mse: 0.0029 - val_loss: 0.0069 - val_mae: 0.0586 - val_mse: 0.0069\n",
      "\n",
      "Epoch 00016: val_mae improved from 0.05868 to 0.05856, saving model to data/models/clean_o_dups_jcw.h5\n",
      "Epoch 17/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 0.0029 - mae: 0.0405 - mse: 0.0029 - val_loss: 0.0066 - val_mae: 0.0580 - val_mse: 0.0066\n",
      "\n",
      "Epoch 00017: val_mae improved from 0.05856 to 0.05796, saving model to data/models/clean_o_dups_jcw.h5\n",
      "Epoch 18/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 0.0027 - mae: 0.0390 - mse: 0.0027 - val_loss: 0.0064 - val_mae: 0.0567 - val_mse: 0.0064\n",
      "\n",
      "Epoch 00018: val_mae improved from 0.05796 to 0.05667, saving model to data/models/clean_o_dups_jcw.h5\n",
      "Epoch 19/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0027 - mae: 0.0388 - mse: 0.0027 - val_loss: 0.0066 - val_mae: 0.0576 - val_mse: 0.0066\n",
      "\n",
      "Epoch 00019: val_mae did not improve from 0.05667\n",
      "Epoch 20/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 3s 19ms/step - loss: 0.0025 - mae: 0.0376 - mse: 0.0025 - val_loss: 0.0065 - val_mae: 0.0571 - val_mse: 0.0065\n",
      "\n",
      "Epoch 00020: val_mae did not improve from 0.05667\n",
      "Epoch 21/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0025 - mae: 0.0378 - mse: 0.0025 - val_loss: 0.0070 - val_mae: 0.0605 - val_mse: 0.0070\n",
      "\n",
      "Epoch 00021: val_mae did not improve from 0.05667\n",
      "Epoch 22/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 0.0024 - mae: 0.0366 - mse: 0.0024 - val_loss: 0.0068 - val_mae: 0.0582 - val_mse: 0.0068\n",
      "\n",
      "Epoch 00022: val_mae did not improve from 0.05667\n",
      "Epoch 23/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 0.0022 - mae: 0.0351 - mse: 0.0022 - val_loss: 0.0067 - val_mae: 0.0587 - val_mse: 0.0067\n",
      "\n",
      "Epoch 00023: val_mae did not improve from 0.05667\n",
      "Epoch 24/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 0.0022 - mae: 0.0357 - mse: 0.0022 - val_loss: 0.0070 - val_mae: 0.0600 - val_mse: 0.0070\n",
      "\n",
      "Epoch 00024: val_mae did not improve from 0.05667\n",
      "Epoch 25/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0025 - mae: 0.0371 - mse: 0.0025 - val_loss: 0.0066 - val_mae: 0.0586 - val_mse: 0.0066\n",
      "\n",
      "Epoch 00025: val_mae did not improve from 0.05667\n",
      "Epoch 26/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0022 - mae: 0.0350 - mse: 0.0022 - val_loss: 0.0065 - val_mae: 0.0567 - val_mse: 0.0065\n",
      "\n",
      "Epoch 00026: val_mae did not improve from 0.05667\n",
      "Epoch 27/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0021 - mae: 0.0343 - mse: 0.0021 - val_loss: 0.0063 - val_mae: 0.0562 - val_mse: 0.0063\n",
      "\n",
      "Epoch 00027: val_mae improved from 0.05667 to 0.05616, saving model to data/models/clean_o_dups_jcw.h5\n",
      "Epoch 28/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0021 - mae: 0.0343 - mse: 0.0021 - val_loss: 0.0065 - val_mae: 0.0571 - val_mse: 0.0065\n",
      "\n",
      "Epoch 00028: val_mae did not improve from 0.05616\n",
      "Epoch 29/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0020 - mae: 0.0338 - mse: 0.0020 - val_loss: 0.0063 - val_mae: 0.0564 - val_mse: 0.0063\n",
      "\n",
      "Epoch 00029: val_mae did not improve from 0.05616\n",
      "Epoch 30/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0025 - mae: 0.0364 - mse: 0.0025 - val_loss: 0.0064 - val_mae: 0.0565 - val_mse: 0.0064\n",
      "\n",
      "Epoch 00030: val_mae did not improve from 0.05616\n",
      "Epoch 31/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0020 - mae: 0.0333 - mse: 0.0020 - val_loss: 0.0065 - val_mae: 0.0569 - val_mse: 0.0065\n",
      "\n",
      "Epoch 00031: val_mae did not improve from 0.05616\n",
      "Epoch 32/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 0.0020 - mae: 0.0334 - mse: 0.0020 - val_loss: 0.0059 - val_mae: 0.0542 - val_mse: 0.0059\n",
      "\n",
      "Epoch 00032: val_mae improved from 0.05616 to 0.05425, saving model to data/models/clean_o_dups_jcw.h5\n",
      "Epoch 33/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0019 - mae: 0.0325 - mse: 0.0019 - val_loss: 0.0068 - val_mae: 0.0577 - val_mse: 0.0068\n",
      "\n",
      "Epoch 00033: val_mae did not improve from 0.05425\n",
      "Epoch 34/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0018 - mae: 0.0311 - mse: 0.0018 - val_loss: 0.0061 - val_mae: 0.0545 - val_mse: 0.0061\n",
      "\n",
      "Epoch 00034: val_mae did not improve from 0.05425\n",
      "Epoch 35/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0018 - mae: 0.0315 - mse: 0.0018 - val_loss: 0.0059 - val_mae: 0.0537 - val_mse: 0.0059\n",
      "\n",
      "Epoch 00035: val_mae improved from 0.05425 to 0.05371, saving model to data/models/clean_o_dups_jcw.h5\n",
      "Epoch 36/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 0.0017 - mae: 0.0308 - mse: 0.0017 - val_loss: 0.0058 - val_mae: 0.0532 - val_mse: 0.0058\n",
      "\n",
      "Epoch 00036: val_mae improved from 0.05371 to 0.05316, saving model to data/models/clean_o_dups_jcw.h5\n",
      "Epoch 37/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 0.0017 - mae: 0.0306 - mse: 0.0017 - val_loss: 0.0056 - val_mae: 0.0521 - val_mse: 0.0056\n",
      "\n",
      "Epoch 00037: val_mae improved from 0.05316 to 0.05212, saving model to data/models/clean_o_dups_jcw.h5\n",
      "Epoch 38/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 0.0016 - mae: 0.0293 - mse: 0.0016 - val_loss: 0.0059 - val_mae: 0.0541 - val_mse: 0.0059\n",
      "\n",
      "Epoch 00038: val_mae did not improve from 0.05212\n",
      "Epoch 39/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0016 - mae: 0.0298 - mse: 0.0016 - val_loss: 0.0061 - val_mae: 0.0541 - val_mse: 0.0061\n",
      "\n",
      "Epoch 00039: val_mae did not improve from 0.05212\n",
      "Epoch 40/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 0.0014 - mae: 0.0287 - mse: 0.0014 - val_loss: 0.0061 - val_mae: 0.0548 - val_mse: 0.0061\n",
      "\n",
      "Epoch 00040: val_mae did not improve from 0.05212\n",
      "Epoch 41/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 0.0016 - mae: 0.0300 - mse: 0.0016 - val_loss: 0.0059 - val_mae: 0.0534 - val_mse: 0.0059\n",
      "\n",
      "Epoch 00041: val_mae did not improve from 0.05212\n",
      "Epoch 42/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 0.0017 - mae: 0.0310 - mse: 0.0017 - val_loss: 0.0064 - val_mae: 0.0565 - val_mse: 0.0064\n",
      "\n",
      "Epoch 00042: val_mae did not improve from 0.05212\n",
      "Epoch 43/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0017 - mae: 0.0301 - mse: 0.0017 - val_loss: 0.0067 - val_mae: 0.0578 - val_mse: 0.0067\n",
      "\n",
      "Epoch 00043: val_mae did not improve from 0.05212\n",
      "Epoch 44/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0017 - mae: 0.0301 - mse: 0.0017 - val_loss: 0.0057 - val_mae: 0.0521 - val_mse: 0.0057\n",
      "\n",
      "Epoch 00044: val_mae improved from 0.05212 to 0.05206, saving model to data/models/clean_o_dups_jcw.h5\n",
      "Epoch 45/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0016 - mae: 0.0292 - mse: 0.0016 - val_loss: 0.0060 - val_mae: 0.0540 - val_mse: 0.0060\n",
      "\n",
      "Epoch 00045: val_mae did not improve from 0.05206\n",
      "Epoch 46/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0016 - mae: 0.0289 - mse: 0.0016 - val_loss: 0.0064 - val_mae: 0.0567 - val_mse: 0.0064\n",
      "\n",
      "Epoch 00046: val_mae did not improve from 0.05206\n",
      "Epoch 47/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0018 - mae: 0.0312 - mse: 0.0018 - val_loss: 0.0063 - val_mae: 0.0556 - val_mse: 0.0063\n",
      "\n",
      "Epoch 00047: val_mae did not improve from 0.05206\n",
      "Epoch 48/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0016 - mae: 0.0287 - mse: 0.0016 - val_loss: 0.0057 - val_mae: 0.0524 - val_mse: 0.0057\n",
      "\n",
      "Epoch 00048: val_mae did not improve from 0.05206\n",
      "Epoch 49/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0014 - mae: 0.0276 - mse: 0.0014 - val_loss: 0.0059 - val_mae: 0.0542 - val_mse: 0.0059\n",
      "\n",
      "Epoch 00049: val_mae did not improve from 0.05206\n",
      "Epoch 50/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0014 - mae: 0.0278 - mse: 0.0014 - val_loss: 0.0057 - val_mae: 0.0523 - val_mse: 0.0057\n",
      "\n",
      "Epoch 00050: val_mae did not improve from 0.05206\n",
      "Epoch 51/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 0.0012 - mae: 0.0259 - mse: 0.0012 - val_loss: 0.0057 - val_mae: 0.0525 - val_mse: 0.0057\n",
      "\n",
      "Epoch 00051: val_mae did not improve from 0.05206\n",
      "Epoch 52/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 0.0011 - mae: 0.0252 - mse: 0.0011 - val_loss: 0.0060 - val_mae: 0.0537 - val_mse: 0.0060\n",
      "\n",
      "Epoch 00052: val_mae did not improve from 0.05206\n",
      "Epoch 53/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0012 - mae: 0.0258 - mse: 0.0012 - val_loss: 0.0061 - val_mae: 0.0543 - val_mse: 0.0061\n",
      "\n",
      "Epoch 00053: val_mae did not improve from 0.05206\n",
      "Epoch 54/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 0.0013 - mae: 0.0267 - mse: 0.0013 - val_loss: 0.0054 - val_mae: 0.0512 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00054: val_mae improved from 0.05206 to 0.05121, saving model to data/models/clean_o_dups_jcw.h5\n",
      "Epoch 55/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 0.0011 - mae: 0.0247 - mse: 0.0011 - val_loss: 0.0056 - val_mae: 0.0524 - val_mse: 0.0056\n",
      "\n",
      "Epoch 00055: val_mae did not improve from 0.05121\n",
      "Epoch 56/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 3s 19ms/step - loss: 0.0013 - mae: 0.0262 - mse: 0.0013 - val_loss: 0.0054 - val_mae: 0.0510 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00056: val_mae improved from 0.05121 to 0.05101, saving model to data/models/clean_o_dups_jcw.h5\n",
      "Epoch 57/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0015 - mae: 0.0273 - mse: 0.0015 - val_loss: 0.0054 - val_mae: 0.0508 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00057: val_mae improved from 0.05101 to 0.05084, saving model to data/models/clean_o_dups_jcw.h5\n",
      "Epoch 58/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0011 - mae: 0.0251 - mse: 0.0011 - val_loss: 0.0053 - val_mae: 0.0501 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00058: val_mae improved from 0.05084 to 0.05009, saving model to data/models/clean_o_dups_jcw.h5\n",
      "Epoch 59/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 0.0011 - mae: 0.0250 - mse: 0.0011 - val_loss: 0.0052 - val_mae: 0.0500 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00059: val_mae improved from 0.05009 to 0.04999, saving model to data/models/clean_o_dups_jcw.h5\n",
      "Epoch 60/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 0.0011 - mae: 0.0248 - mse: 0.0011 - val_loss: 0.0056 - val_mae: 0.0515 - val_mse: 0.0056\n",
      "\n",
      "Epoch 00060: val_mae did not improve from 0.04999\n",
      "Epoch 61/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 0.0010 - mae: 0.0237 - mse: 0.0010 - val_loss: 0.0055 - val_mae: 0.0512 - val_mse: 0.0055\n",
      "\n",
      "Epoch 00061: val_mae did not improve from 0.04999\n",
      "Epoch 62/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 9.2575e-04 - mae: 0.0228 - mse: 9.2575e-04 - val_loss: 0.0054 - val_mae: 0.0508 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00062: val_mae did not improve from 0.04999\n",
      "Epoch 63/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 9.7188e-04 - mae: 0.0234 - mse: 9.7188e-04 - val_loss: 0.0050 - val_mae: 0.0485 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00063: val_mae improved from 0.04999 to 0.04852, saving model to data/models/clean_o_dups_jcw.h5\n",
      "Epoch 64/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0010 - mae: 0.0233 - mse: 0.0010 - val_loss: 0.0056 - val_mae: 0.0513 - val_mse: 0.0056\n",
      "\n",
      "Epoch 00064: val_mae did not improve from 0.04852\n",
      "Epoch 65/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0013 - mae: 0.0258 - mse: 0.0013 - val_loss: 0.0050 - val_mae: 0.0481 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00065: val_mae improved from 0.04852 to 0.04812, saving model to data/models/clean_o_dups_jcw.h5\n",
      "Epoch 66/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0011 - mae: 0.0236 - mse: 0.0011 - val_loss: 0.0053 - val_mae: 0.0504 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00066: val_mae did not improve from 0.04812\n",
      "Epoch 67/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0010 - mae: 0.0235 - mse: 0.0010 - val_loss: 0.0051 - val_mae: 0.0488 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00067: val_mae did not improve from 0.04812\n",
      "Epoch 68/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 9.5280e-04 - mae: 0.0229 - mse: 9.5280e-04 - val_loss: 0.0055 - val_mae: 0.0514 - val_mse: 0.0055\n",
      "\n",
      "Epoch 00068: val_mae did not improve from 0.04812\n",
      "Epoch 69/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 0.0011 - mae: 0.0235 - mse: 0.0011 - val_loss: 0.0049 - val_mae: 0.0479 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00069: val_mae improved from 0.04812 to 0.04793, saving model to data/models/clean_o_dups_jcw.h5\n",
      "Epoch 70/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 9.8678e-04 - mae: 0.0230 - mse: 9.8678e-04 - val_loss: 0.0051 - val_mae: 0.0487 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00070: val_mae did not improve from 0.04793\n",
      "Epoch 71/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 9.3068e-04 - mae: 0.0220 - mse: 9.3068e-04 - val_loss: 0.0054 - val_mae: 0.0509 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00071: val_mae did not improve from 0.04793\n",
      "Epoch 72/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 9.2645e-04 - mae: 0.0217 - mse: 9.2645e-04 - val_loss: 0.0052 - val_mae: 0.0494 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00072: val_mae did not improve from 0.04793\n",
      "Epoch 73/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 9.5702e-04 - mae: 0.0222 - mse: 9.5702e-04 - val_loss: 0.0051 - val_mae: 0.0489 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00073: val_mae did not improve from 0.04793\n",
      "Epoch 74/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 7.6536e-04 - mae: 0.0209 - mse: 7.6536e-04 - val_loss: 0.0050 - val_mae: 0.0486 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00074: val_mae did not improve from 0.04793\n",
      "Epoch 75/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 7.7302e-04 - mae: 0.0208 - mse: 7.7302e-04 - val_loss: 0.0049 - val_mae: 0.0478 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00075: val_mae improved from 0.04793 to 0.04784, saving model to data/models/clean_o_dups_jcw.h5\n",
      "Epoch 76/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 6.8772e-04 - mae: 0.0198 - mse: 6.8772e-04 - val_loss: 0.0054 - val_mae: 0.0511 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00076: val_mae did not improve from 0.04784\n",
      "Epoch 77/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 7.5221e-04 - mae: 0.0205 - mse: 7.5221e-04 - val_loss: 0.0051 - val_mae: 0.0490 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00077: val_mae did not improve from 0.04784\n",
      "Epoch 78/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 6.8877e-04 - mae: 0.0199 - mse: 6.8877e-04 - val_loss: 0.0057 - val_mae: 0.0524 - val_mse: 0.0057\n",
      "\n",
      "Epoch 00078: val_mae did not improve from 0.04784\n",
      "Epoch 79/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 8.0674e-04 - mae: 0.0210 - mse: 8.0674e-04 - val_loss: 0.0052 - val_mae: 0.0503 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00079: val_mae did not improve from 0.04784\n",
      "Epoch 80/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 8.1856e-04 - mae: 0.0209 - mse: 8.1856e-04 - val_loss: 0.0053 - val_mae: 0.0497 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00080: val_mae did not improve from 0.04784\n",
      "Epoch 81/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 8.1425e-04 - mae: 0.0209 - mse: 8.1425e-04 - val_loss: 0.0052 - val_mae: 0.0500 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00081: val_mae did not improve from 0.04784\n",
      "Epoch 82/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 9.1194e-04 - mae: 0.0216 - mse: 9.1194e-04 - val_loss: 0.0050 - val_mae: 0.0489 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00082: val_mae did not improve from 0.04784\n",
      "Epoch 83/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 6.8915e-04 - mae: 0.0197 - mse: 6.8915e-04 - val_loss: 0.0057 - val_mae: 0.0517 - val_mse: 0.0057\n",
      "\n",
      "Epoch 00083: val_mae did not improve from 0.04784\n",
      "Epoch 84/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 7.0171e-04 - mae: 0.0195 - mse: 7.0171e-04 - val_loss: 0.0050 - val_mae: 0.0485 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00084: val_mae did not improve from 0.04784\n",
      "Epoch 85/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 7.7889e-04 - mae: 0.0204 - mse: 7.7889e-04 - val_loss: 0.0051 - val_mae: 0.0491 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00085: val_mae did not improve from 0.04784\n",
      "Epoch 86/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 7.7226e-04 - mae: 0.0202 - mse: 7.7226e-04 - val_loss: 0.0049 - val_mae: 0.0481 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00086: val_mae did not improve from 0.04784\n",
      "Epoch 87/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 8.1205e-04 - mae: 0.0206 - mse: 8.1205e-04 - val_loss: 0.0056 - val_mae: 0.0512 - val_mse: 0.0056\n",
      "\n",
      "Epoch 00087: val_mae did not improve from 0.04784\n",
      "Epoch 88/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 7.1808e-04 - mae: 0.0200 - mse: 7.1808e-04 - val_loss: 0.0055 - val_mae: 0.0510 - val_mse: 0.0055\n",
      "\n",
      "Epoch 00088: val_mae did not improve from 0.04784\n",
      "Epoch 89/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 7.5996e-04 - mae: 0.0205 - mse: 7.5996e-04 - val_loss: 0.0051 - val_mae: 0.0492 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00089: val_mae did not improve from 0.04784\n",
      "Epoch 90/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 6.6600e-04 - mae: 0.0192 - mse: 6.6600e-04 - val_loss: 0.0053 - val_mae: 0.0501 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00090: val_mae did not improve from 0.04784\n",
      "Epoch 91/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 3s 19ms/step - loss: 6.4032e-04 - mae: 0.0189 - mse: 6.4032e-04 - val_loss: 0.0048 - val_mae: 0.0475 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00091: val_mae improved from 0.04784 to 0.04748, saving model to data/models/clean_o_dups_jcw.h5\n",
      "Epoch 92/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 6.8009e-04 - mae: 0.0193 - mse: 6.8009e-04 - val_loss: 0.0055 - val_mae: 0.0513 - val_mse: 0.0055\n",
      "\n",
      "Epoch 00092: val_mae did not improve from 0.04748\n",
      "Epoch 93/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 0.0010 - mae: 0.0202 - mse: 0.0010 - val_loss: 0.0051 - val_mae: 0.0487 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00093: val_mae did not improve from 0.04748\n",
      "Epoch 94/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 6.3903e-04 - mae: 0.0189 - mse: 6.3903e-04 - val_loss: 0.0052 - val_mae: 0.0494 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00094: val_mae did not improve from 0.04748\n",
      "Epoch 95/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 7.5211e-04 - mae: 0.0194 - mse: 7.5211e-04 - val_loss: 0.0049 - val_mae: 0.0482 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00095: val_mae did not improve from 0.04748\n",
      "Epoch 96/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 7.6268e-04 - mae: 0.0198 - mse: 7.6268e-04 - val_loss: 0.0049 - val_mae: 0.0477 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00096: val_mae did not improve from 0.04748\n",
      "Epoch 97/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 7.6197e-04 - mae: 0.0199 - mse: 7.6197e-04 - val_loss: 0.0049 - val_mae: 0.0482 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00097: val_mae did not improve from 0.04748\n",
      "Epoch 98/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 5.6795e-04 - mae: 0.0179 - mse: 5.6795e-04 - val_loss: 0.0051 - val_mae: 0.0491 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00098: val_mae did not improve from 0.04748\n",
      "Epoch 99/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 6.7633e-04 - mae: 0.0189 - mse: 6.7633e-04 - val_loss: 0.0047 - val_mae: 0.0467 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00099: val_mae improved from 0.04748 to 0.04673, saving model to data/models/clean_o_dups_jcw.h5\n",
      "Epoch 100/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 6.7063e-04 - mae: 0.0183 - mse: 6.7063e-04 - val_loss: 0.0050 - val_mae: 0.0485 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00100: val_mae did not improve from 0.04673\n",
      "Epoch 101/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 7.1646e-04 - mae: 0.0193 - mse: 7.1646e-04 - val_loss: 0.0047 - val_mae: 0.0468 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00101: val_mae did not improve from 0.04673\n",
      "Epoch 102/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 7.0276e-04 - mae: 0.0185 - mse: 7.0276e-04 - val_loss: 0.0047 - val_mae: 0.0469 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00102: val_mae did not improve from 0.04673\n",
      "Epoch 103/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 5.9974e-04 - mae: 0.0177 - mse: 5.9974e-04 - val_loss: 0.0049 - val_mae: 0.0479 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00103: val_mae did not improve from 0.04673\n",
      "Epoch 104/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 5.8699e-04 - mae: 0.0178 - mse: 5.8699e-04 - val_loss: 0.0052 - val_mae: 0.0492 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00104: val_mae did not improve from 0.04673\n",
      "Epoch 105/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 5.4673e-04 - mae: 0.0174 - mse: 5.4673e-04 - val_loss: 0.0047 - val_mae: 0.0467 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00105: val_mae improved from 0.04673 to 0.04670, saving model to data/models/clean_o_dups_jcw.h5\n",
      "Epoch 106/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 5.2685e-04 - mae: 0.0172 - mse: 5.2685e-04 - val_loss: 0.0049 - val_mae: 0.0478 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00106: val_mae did not improve from 0.04670\n",
      "Epoch 107/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 4.9351e-04 - mae: 0.0164 - mse: 4.9351e-04 - val_loss: 0.0048 - val_mae: 0.0473 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00107: val_mae did not improve from 0.04670\n",
      "Epoch 108/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 5.8452e-04 - mae: 0.0178 - mse: 5.8452e-04 - val_loss: 0.0048 - val_mae: 0.0471 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00108: val_mae did not improve from 0.04670\n",
      "Epoch 109/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 5.9219e-04 - mae: 0.0173 - mse: 5.9219e-04 - val_loss: 0.0050 - val_mae: 0.0483 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00109: val_mae did not improve from 0.04670\n",
      "Epoch 110/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 5.5910e-04 - mae: 0.0174 - mse: 5.5910e-04 - val_loss: 0.0048 - val_mae: 0.0477 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00110: val_mae did not improve from 0.04670\n",
      "Epoch 111/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 5.2206e-04 - mae: 0.0170 - mse: 5.2206e-04 - val_loss: 0.0049 - val_mae: 0.0479 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00111: val_mae did not improve from 0.04670\n",
      "Epoch 112/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 5.3584e-04 - mae: 0.0171 - mse: 5.3584e-04 - val_loss: 0.0051 - val_mae: 0.0487 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00112: val_mae did not improve from 0.04670\n",
      "Epoch 113/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 6.5571e-04 - mae: 0.0178 - mse: 6.5571e-04 - val_loss: 0.0048 - val_mae: 0.0473 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00113: val_mae did not improve from 0.04670\n",
      "Epoch 114/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 5.6378e-04 - mae: 0.0176 - mse: 5.6378e-04 - val_loss: 0.0051 - val_mae: 0.0488 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00114: val_mae did not improve from 0.04670\n",
      "Epoch 115/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 5.3537e-04 - mae: 0.0168 - mse: 5.3537e-04 - val_loss: 0.0047 - val_mae: 0.0468 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00115: val_mae did not improve from 0.04670\n",
      "Epoch 116/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 5.5056e-04 - mae: 0.0172 - mse: 5.5056e-04 - val_loss: 0.0046 - val_mae: 0.0462 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00116: val_mae improved from 0.04670 to 0.04618, saving model to data/models/clean_o_dups_jcw.h5\n",
      "Epoch 117/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 5.8380e-04 - mae: 0.0169 - mse: 5.8380e-04 - val_loss: 0.0047 - val_mae: 0.0469 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00117: val_mae did not improve from 0.04618\n",
      "Epoch 118/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 5.5748e-04 - mae: 0.0171 - mse: 5.5748e-04 - val_loss: 0.0048 - val_mae: 0.0468 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00118: val_mae did not improve from 0.04618\n",
      "Epoch 119/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 5.6308e-04 - mae: 0.0170 - mse: 5.6308e-04 - val_loss: 0.0048 - val_mae: 0.0471 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00119: val_mae did not improve from 0.04618\n",
      "Epoch 120/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 5.8805e-04 - mae: 0.0169 - mse: 5.8805e-04 - val_loss: 0.0048 - val_mae: 0.0474 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00120: val_mae did not improve from 0.04618\n",
      "Epoch 121/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 5.2211e-04 - mae: 0.0169 - mse: 5.2211e-04 - val_loss: 0.0049 - val_mae: 0.0476 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00121: val_mae did not improve from 0.04618\n",
      "Epoch 122/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 6.0096e-04 - mae: 0.0170 - mse: 6.0096e-04 - val_loss: 0.0046 - val_mae: 0.0467 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00122: val_mae did not improve from 0.04618\n",
      "Epoch 123/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 4.9347e-04 - mae: 0.0163 - mse: 4.9347e-04 - val_loss: 0.0050 - val_mae: 0.0482 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00123: val_mae did not improve from 0.04618\n",
      "Epoch 124/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 4.8648e-04 - mae: 0.0161 - mse: 4.8648e-04 - val_loss: 0.0048 - val_mae: 0.0472 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00124: val_mae did not improve from 0.04618\n",
      "Epoch 125/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 4.4512e-04 - mae: 0.0152 - mse: 4.4512e-04 - val_loss: 0.0048 - val_mae: 0.0473 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00125: val_mae did not improve from 0.04618\n",
      "Epoch 126/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 3s 20ms/step - loss: 4.4666e-04 - mae: 0.0157 - mse: 4.4666e-04 - val_loss: 0.0049 - val_mae: 0.0480 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00126: val_mae did not improve from 0.04618\n",
      "Epoch 127/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 3.9607e-04 - mae: 0.0150 - mse: 3.9607e-04 - val_loss: 0.0047 - val_mae: 0.0465 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00127: val_mae did not improve from 0.04618\n",
      "Epoch 128/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 4.3863e-04 - mae: 0.0156 - mse: 4.3863e-04 - val_loss: 0.0046 - val_mae: 0.0460 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00128: val_mae improved from 0.04618 to 0.04598, saving model to data/models/clean_o_dups_jcw.h5\n",
      "Epoch 129/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 4.2603e-04 - mae: 0.0152 - mse: 4.2603e-04 - val_loss: 0.0052 - val_mae: 0.0502 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00129: val_mae did not improve from 0.04598\n",
      "Epoch 130/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 4.8814e-04 - mae: 0.0162 - mse: 4.8814e-04 - val_loss: 0.0050 - val_mae: 0.0482 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00130: val_mae did not improve from 0.04598\n",
      "Epoch 131/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 4.3441e-04 - mae: 0.0156 - mse: 4.3441e-04 - val_loss: 0.0047 - val_mae: 0.0465 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00131: val_mae did not improve from 0.04598\n",
      "Epoch 132/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 4.7575e-04 - mae: 0.0160 - mse: 4.7575e-04 - val_loss: 0.0048 - val_mae: 0.0475 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00132: val_mae did not improve from 0.04598\n",
      "Epoch 133/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 5.0049e-04 - mae: 0.0163 - mse: 5.0049e-04 - val_loss: 0.0048 - val_mae: 0.0472 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00133: val_mae did not improve from 0.04598\n",
      "Epoch 134/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 4.9186e-04 - mae: 0.0160 - mse: 4.9186e-04 - val_loss: 0.0048 - val_mae: 0.0471 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00134: val_mae did not improve from 0.04598\n",
      "Epoch 135/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 4.7046e-04 - mae: 0.0160 - mse: 4.7046e-04 - val_loss: 0.0048 - val_mae: 0.0470 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00135: val_mae did not improve from 0.04598\n",
      "Epoch 136/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 4.6978e-04 - mae: 0.0154 - mse: 4.6978e-04 - val_loss: 0.0049 - val_mae: 0.0477 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00136: val_mae did not improve from 0.04598\n",
      "Epoch 137/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 4.5069e-04 - mae: 0.0158 - mse: 4.5069e-04 - val_loss: 0.0047 - val_mae: 0.0466 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00137: val_mae did not improve from 0.04598\n",
      "Epoch 138/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 4.2326e-04 - mae: 0.0152 - mse: 4.2326e-04 - val_loss: 0.0048 - val_mae: 0.0471 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00138: val_mae did not improve from 0.04598\n",
      "Epoch 139/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 4.1041e-04 - mae: 0.0150 - mse: 4.1041e-04 - val_loss: 0.0048 - val_mae: 0.0469 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00139: val_mae did not improve from 0.04598\n",
      "Epoch 140/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 3.6441e-04 - mae: 0.0143 - mse: 3.6441e-04 - val_loss: 0.0049 - val_mae: 0.0478 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00140: val_mae did not improve from 0.04598\n",
      "Epoch 141/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 4.1429e-04 - mae: 0.0150 - mse: 4.1429e-04 - val_loss: 0.0049 - val_mae: 0.0473 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00141: val_mae did not improve from 0.04598\n",
      "Epoch 142/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 4.8708e-04 - mae: 0.0156 - mse: 4.8708e-04 - val_loss: 0.0050 - val_mae: 0.0482 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00142: val_mae did not improve from 0.04598\n",
      "Epoch 143/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 3.7765e-04 - mae: 0.0145 - mse: 3.7765e-04 - val_loss: 0.0047 - val_mae: 0.0467 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00143: val_mae did not improve from 0.04598\n",
      "Epoch 144/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 3.9468e-04 - mae: 0.0148 - mse: 3.9468e-04 - val_loss: 0.0047 - val_mae: 0.0467 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00144: val_mae did not improve from 0.04598\n",
      "Epoch 145/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 3.8961e-04 - mae: 0.0144 - mse: 3.8961e-04 - val_loss: 0.0049 - val_mae: 0.0479 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00145: val_mae did not improve from 0.04598\n",
      "Epoch 146/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 3.8865e-04 - mae: 0.0145 - mse: 3.8865e-04 - val_loss: 0.0046 - val_mae: 0.0461 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00146: val_mae did not improve from 0.04598\n",
      "Epoch 147/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 4.5597e-04 - mae: 0.0154 - mse: 4.5597e-04 - val_loss: 0.0048 - val_mae: 0.0474 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00147: val_mae did not improve from 0.04598\n",
      "Epoch 148/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 3.9117e-04 - mae: 0.0144 - mse: 3.9117e-04 - val_loss: 0.0046 - val_mae: 0.0458 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00148: val_mae improved from 0.04598 to 0.04582, saving model to data/models/clean_o_dups_jcw.h5\n",
      "Epoch 149/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 3.6632e-04 - mae: 0.0142 - mse: 3.6632e-04 - val_loss: 0.0046 - val_mae: 0.0458 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00149: val_mae did not improve from 0.04582\n",
      "Epoch 150/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 3.9927e-04 - mae: 0.0147 - mse: 3.9927e-04 - val_loss: 0.0051 - val_mae: 0.0486 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00150: val_mae did not improve from 0.04582\n",
      "Epoch 151/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 4.2461e-04 - mae: 0.0150 - mse: 4.2461e-04 - val_loss: 0.0048 - val_mae: 0.0470 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00151: val_mae did not improve from 0.04582\n",
      "Epoch 152/300\n",
      "161/161 [==============================] - 25s 157ms/step - loss: 3.9395e-04 - mae: 0.0144 - mse: 3.9395e-04 - val_loss: 0.0047 - val_mae: 0.0467 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00152: val_mae did not improve from 0.04582\n",
      "Epoch 153/300\n",
      "161/161 [==============================] - 9s 57ms/step - loss: 3.7581e-04 - mae: 0.0144 - mse: 3.7581e-04 - val_loss: 0.0046 - val_mae: 0.0459 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00153: val_mae did not improve from 0.04582\n",
      "Epoch 154/300\n",
      "161/161 [==============================] - 206s 1s/step - loss: 3.9017e-04 - mae: 0.0146 - mse: 3.9017e-04 - val_loss: 0.0046 - val_mae: 0.0460 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00154: val_mae did not improve from 0.04582\n",
      "Epoch 155/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 3.6724e-04 - mae: 0.0140 - mse: 3.6724e-04 - val_loss: 0.0049 - val_mae: 0.0481 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00155: val_mae did not improve from 0.04582\n",
      "Epoch 156/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 3.7173e-04 - mae: 0.0141 - mse: 3.7173e-04 - val_loss: 0.0047 - val_mae: 0.0465 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00156: val_mae did not improve from 0.04582\n",
      "Epoch 157/300\n",
      "161/161 [==============================] - 3s 18ms/step - loss: 3.2300e-04 - mae: 0.0135 - mse: 3.2300e-04 - val_loss: 0.0048 - val_mae: 0.0470 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00157: val_mae did not improve from 0.04582\n",
      "Epoch 158/300\n",
      "161/161 [==============================] - 3s 18ms/step - loss: 3.8224e-04 - mae: 0.0142 - mse: 3.8224e-04 - val_loss: 0.0048 - val_mae: 0.0470 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00158: val_mae did not improve from 0.04582\n",
      "Epoch 159/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 4.0510e-04 - mae: 0.0145 - mse: 4.0510e-04 - val_loss: 0.0045 - val_mae: 0.0454 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00159: val_mae improved from 0.04582 to 0.04539, saving model to data/models/clean_o_dups_jcw.h5\n",
      "Epoch 160/300\n",
      "161/161 [==============================] - 3s 18ms/step - loss: 3.6797e-04 - mae: 0.0137 - mse: 3.6797e-04 - val_loss: 0.0048 - val_mae: 0.0471 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00160: val_mae did not improve from 0.04539\n",
      "Epoch 161/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 3s 19ms/step - loss: 3.4995e-04 - mae: 0.0138 - mse: 3.4995e-04 - val_loss: 0.0047 - val_mae: 0.0468 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00161: val_mae did not improve from 0.04539\n",
      "Epoch 162/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 4.0059e-04 - mae: 0.0146 - mse: 4.0059e-04 - val_loss: 0.0047 - val_mae: 0.0461 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00162: val_mae did not improve from 0.04539\n",
      "Epoch 163/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 4.3457e-04 - mae: 0.0146 - mse: 4.3457e-04 - val_loss: 0.0046 - val_mae: 0.0461 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00163: val_mae did not improve from 0.04539\n",
      "Epoch 164/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 3.8572e-04 - mae: 0.0146 - mse: 3.8572e-04 - val_loss: 0.0046 - val_mae: 0.0460 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00164: val_mae did not improve from 0.04539\n",
      "Epoch 165/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 4.0025e-04 - mae: 0.0148 - mse: 4.0025e-04 - val_loss: 0.0048 - val_mae: 0.0469 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00165: val_mae did not improve from 0.04539\n",
      "Epoch 166/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 3.4891e-04 - mae: 0.0138 - mse: 3.4891e-04 - val_loss: 0.0047 - val_mae: 0.0463 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00166: val_mae did not improve from 0.04539\n",
      "Epoch 167/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 3.7351e-04 - mae: 0.0140 - mse: 3.7351e-04 - val_loss: 0.0046 - val_mae: 0.0458 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00167: val_mae did not improve from 0.04539\n",
      "Epoch 168/300\n",
      "161/161 [==============================] - 4s 22ms/step - loss: 3.7982e-04 - mae: 0.0138 - mse: 3.7982e-04 - val_loss: 0.0047 - val_mae: 0.0463 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00168: val_mae did not improve from 0.04539\n",
      "Epoch 169/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 3.6202e-04 - mae: 0.0137 - mse: 3.6202e-04 - val_loss: 0.0047 - val_mae: 0.0462 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00169: val_mae did not improve from 0.04539\n",
      "Epoch 170/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 3.6640e-04 - mae: 0.0138 - mse: 3.6640e-04 - val_loss: 0.0047 - val_mae: 0.0465 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00170: val_mae did not improve from 0.04539\n",
      "Epoch 171/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 3.3936e-04 - mae: 0.0136 - mse: 3.3936e-04 - val_loss: 0.0046 - val_mae: 0.0459 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00171: val_mae did not improve from 0.04539\n",
      "Epoch 172/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 3.2318e-04 - mae: 0.0131 - mse: 3.2318e-04 - val_loss: 0.0046 - val_mae: 0.0454 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00172: val_mae did not improve from 0.04539\n",
      "Epoch 173/300\n",
      "161/161 [==============================] - 3s 22ms/step - loss: 3.2395e-04 - mae: 0.0131 - mse: 3.2395e-04 - val_loss: 0.0047 - val_mae: 0.0462 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00173: val_mae did not improve from 0.04539\n",
      "Epoch 174/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 3.0299e-04 - mae: 0.0127 - mse: 3.0299e-04 - val_loss: 0.0046 - val_mae: 0.0455 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00174: val_mae did not improve from 0.04539\n",
      "Epoch 175/300\n",
      "161/161 [==============================] - 3s 22ms/step - loss: 2.8484e-04 - mae: 0.0125 - mse: 2.8484e-04 - val_loss: 0.0048 - val_mae: 0.0468 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00175: val_mae did not improve from 0.04539\n",
      "Epoch 176/300\n",
      "161/161 [==============================] - 4s 22ms/step - loss: 2.9740e-04 - mae: 0.0128 - mse: 2.9740e-04 - val_loss: 0.0047 - val_mae: 0.0463 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00176: val_mae did not improve from 0.04539\n",
      "Epoch 177/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 3.2652e-04 - mae: 0.0133 - mse: 3.2652e-04 - val_loss: 0.0046 - val_mae: 0.0460 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00177: val_mae did not improve from 0.04539\n",
      "Epoch 178/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 3.2712e-04 - mae: 0.0131 - mse: 3.2712e-04 - val_loss: 0.0047 - val_mae: 0.0466 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00178: val_mae did not improve from 0.04539\n",
      "Epoch 179/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 2.9213e-04 - mae: 0.0126 - mse: 2.9213e-04 - val_loss: 0.0048 - val_mae: 0.0468 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00179: val_mae did not improve from 0.04539\n",
      "Epoch 180/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 3.0899e-04 - mae: 0.0130 - mse: 3.0899e-04 - val_loss: 0.0047 - val_mae: 0.0464 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00180: val_mae did not improve from 0.04539\n",
      "Epoch 181/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 3.3960e-04 - mae: 0.0134 - mse: 3.3960e-04 - val_loss: 0.0048 - val_mae: 0.0467 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00181: val_mae did not improve from 0.04539\n",
      "Epoch 182/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 3.1416e-04 - mae: 0.0129 - mse: 3.1416e-04 - val_loss: 0.0047 - val_mae: 0.0459 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00182: val_mae did not improve from 0.04539\n",
      "Epoch 183/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 3.4121e-04 - mae: 0.0134 - mse: 3.4121e-04 - val_loss: 0.0046 - val_mae: 0.0457 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00183: val_mae did not improve from 0.04539\n",
      "Epoch 184/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 4.3903e-04 - mae: 0.0141 - mse: 4.3903e-04 - val_loss: 0.0047 - val_mae: 0.0468 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00184: val_mae did not improve from 0.04539\n",
      "Epoch 185/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 3.4284e-04 - mae: 0.0135 - mse: 3.4284e-04 - val_loss: 0.0046 - val_mae: 0.0456 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00185: val_mae did not improve from 0.04539\n",
      "Epoch 186/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 3.6400e-04 - mae: 0.0139 - mse: 3.6400e-04 - val_loss: 0.0046 - val_mae: 0.0456 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00186: val_mae did not improve from 0.04539\n",
      "Epoch 187/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 3.5257e-04 - mae: 0.0136 - mse: 3.5257e-04 - val_loss: 0.0047 - val_mae: 0.0462 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00187: val_mae did not improve from 0.04539\n",
      "Epoch 188/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 4.0017e-04 - mae: 0.0138 - mse: 4.0017e-04 - val_loss: 0.0046 - val_mae: 0.0455 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00188: val_mae did not improve from 0.04539\n",
      "Epoch 189/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 2.9581e-04 - mae: 0.0128 - mse: 2.9581e-04 - val_loss: 0.0047 - val_mae: 0.0463 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00189: val_mae did not improve from 0.04539\n",
      "Epoch 00189: early stopping\n",
      "Done fitting\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXxU9bn48c8zk32HACGEVUDEBRAQcKmNrQvigq173WtLvdVWe+2i3v5ae+vtta221Wqlbq22VWu1rVhRXGouKqAsIrLKLoGwBRKyLzPP74/vSTLJzCQTzJBBn/frNS9mzvl+zzxnovPMdznfI6qKMcYYEytfbwdgjDHm8GKJwxhjTLdY4jDGGNMtljiMMcZ0iyUOY4wx3WKJwxhjTLdY4jDmMCAid4rIn3s7jkhEREVkVG/HYQ4dSxymV4jIFhE5vbfjMMZ0nyUOY0xCEJGk3o7BxMYSh0koIpIqIr8RkR3e4zcikurt6yci/xKRChHZJyJviYjP2/cDEdkuIlUisk5Evhjh2NNEZKeI+EO2fUlEVnjPp4jIEhE5ICK7RORXncR5rogs92JZICLjQvZtEZHbRWS1iOwXkT+ISFrI/q+LyAbvHOaIyKCQfceIyGvevl0ickfI26aIyJPeOa4SkcmdxKcicoOIrPdieFBExNvXrttLRIZ75ZO81yUicpd3XtUi8qKI5IvIX7zPZrGIDO/wljNEZJOI7BWRX7b8XbzjfVVE1nhxzBORYR3ivFFE1gPro52PSTCqag97HPIHsAU4PcL2/wYWAQOA/sAC4Kfevv8FZgPJ3uNzgABjgG3AIK/ccGBklPfdCJwR8vpvwG3e84XAVd7zLGBalGNMBHYDUwE/cI13Pqkh57YSGAL0Bd4B7vL2fQHY6x0jFfgtMN/blw2UAbcCad7rqd6+O4F6YIb3nv8LLOrk81XgX0AeMBTYA0wPOdafQ8oO98onea9LgA3ASCAXWA18BJwOJAFPAn/o8F5veuc61Cv7NW/fBd6xxnp1fwgs6FD3Na9uem//d2mP2B7W4jCJ5grgv1V1t6ruAX4CXOXtawIKgWGq2qSqb6n79gngvoSPFpFkVd2iqhujHP9p4HIAEcnGfRE/HXL8USLST1WrVXVRlGN8Hfi9qr6rqgFVfQJoAKaFlHlAVbep6j7gf1re0zu/x1V1mao2ALcDJ3q/4M8Fdqrqvapar6pVqvpuyDHfVtW5qhoA/gSM7+RzBLhbVStU9WPcF/uELsqH+oOqblTVSuBlYKOqvq6qzbhke3yH8j9X1X3ee/0m5Hy/Afyvqq7x6v4MmBDa6vD271PVum7EZ3qRJQ6TaAYBW0Neb/W2AfwS9+v1Va9b5DYAVd0A3IL7Jb1bRJ4J7f7p4Cngy17315eBZara8n7XA0cCa73umHOjHGMYcKvXTVUhIhW41kXoe26Lcg7tzk9Vq4FyoMg7RrSEB7Az5HktkNbFuEDH8lmdlO1oV8jzugivOx4r2vkOA+4L+Zz24VqJRVHqmsOAJQ6TaHbgvmxaDPW24f0Cv1VVjwDOA/6zZSxDVZ9S1VO8ugr8PNLBVXU17ovtbOAruETSsm+9ql6O6yb7OfCciGRGOMw24H9UNS/kkaGqT4eUGRLpHDqen3f8fGC7d9yR0T+aHlMDZIS8HtgDx4x2vtuAb3T4rNJVdUFIeVui+zBjicP0pmQRSQt5JOG6jX4oIv1FpB/wI+DP0DogPcob5D2A66IKiMgYEfmC14qox/0iDnTyvk8B3wZOxXW74B3/ShHpr6pBoMLbHOk4jwA3iMhUcTJF5Byv66vFjSIyWET6AncAfw157+tEZIIX78+Ad1V1C25MYqCI3CJukkC2iEyN7aPsluXAqSIyVERycd1ln9T3RKSPiAwBbqbtfGcDt4vIMQAikisiF/fA+5leZInD9Ka5uC/5lsedwF3AEmAF8CGwzNsGMBp4HajGDWT/TlVLcOMbd+MGnXfiWgyhs5E6ehooBv6tqntDtk8HVolINXAfcJmq1nesrKpLcOMcDwD7cd1n13Yo9hTwKrDJe9zl1X0D+H/A87iB8JHAZd6+KuAMXGtqJ26W0WmdnMdBUdXXcF/sK4CluIT1Sb3gHWs58BLwmPde/8C13p4RkQO4SQNn98D7mV4kbmzRGNNTRGQLblbR670dizHxYC0OY4wx3WKJwxhjTLfENXGIyHRxV/FuaJk62WG/iMj93v4VIjLR254mIu+JyAfeFbI/Calzp7grhJd7jxnxPAdjuktVh1s3lfk0i9vaMOKWdXgQN9hXCiwWkTnedMgWZ+MGPEfjrsJ9yPu3AfiCqlaLSDLwtoi8HHJB1q9V9Z54xW6MMSa6eC4qNgXYoKqbAETkGWAmbvmCFjOBJ72rfxeJSJ6IFKpqGW7mDLQtL3HQo/j9+vXT4cOHH1TdmpoaMjMjTeVPHIkeY6LHB4kfY6LHB4kfo8XXfUuXLt2rqv07bo9n4iii/RWhpbjWRFdlioAyr8WyFBgFPNhh6YWbRORq3LTNW1V1f8c3F5FZwCyAgoIC7rnn4Boo1dXVZGV154LbQy/RY0z0+CDxY0z0+CDxY7T4uu+0007bGnFHvBbBAi4GHg15fRXw2w5lXgJOCXn9BjCpQ5k83Do7x3qvC3CLvPlwawA93lUskyZN0oP15ptvHnTdQyXRY0z0+FQTP8ZEj0818WO0+LoPWKKHeJHDUtovQzCYtmUIYi6jqhW41Tqne693qVtYLoi7gndKz4ZtjDGmM/FMHIuB0SIyQkRScFfHzulQZg5wtTe7ahpQqapl3nITeQAiko5bznmt97owpP6XcFeiGmOMOUTiNsahqs0ichMwD9e19LiqrhKRG7z9s3FLTszALdlQC1znVS8EnvDGOXzAs6rasizCL0RkAm6wfAtu2WZjjOlRTU1NlJaWUl8ftupMXOTm5rJmzZpD8l4dpaWlMXjwYJKTk2MqH9dbNarqXFxyCN02O+S5AjdGqLeC8PX+W/ZdFWm7Mcb0pNLSUrKzsxk+fDhuXc34qqqqIjs7u+uCPUxVKS8vp7S0lBEjRsRUx64cN8aYCOrr68nPzz8kSaM3iQj5+fndallZ4ohib3UDCzbuZdXeAGvKDvR2OMaYXvBpTxotunuece2qOpwt2FjOt59+H4DVjRt48CsTezkiY4xJDNbiiMIfkoGDQVt63hhzaFVUVPC73/2u2/VmzJhBRUVF1wU/AUscUfhDPpmAJQ5jzCEWLXEEAp3d3BLmzp1LXl5evMICrKsqKl9oi8NudmWMOcRuu+02Nm7cyIQJE0hOTiYrK4vCwkKWL1/O6tWrueCCC9i2bRv19fXcfPPNzJo1C4Dhw4ezZMkSqqurOfvssznllFNYsGABRUVFvPDCC6Snp3/i2CxxRNE+cfRiIMaYXjf8tpfiduwtd58Tcfvdd9/NypUrWb58OSUlJZxzzjmsXLmydcrs448/Tt++famrq+OEE07gwgsvJD8/v90x1q9fz9NPP80jjzzCJZdcwvPPP8+VV175iWO2xBGF39eWOKyryhjT26ZMmdLuOov777+ff/zjHwBs27aN9evXhyWOESNGMGHCBAAmTZrEli1beiQWSxxR+HzWVWWMSRyhS66XlJTw+uuvs3DhQjIyMiguLo54HUZqamrrc7/fT11dXY/EYokjitBZVdbiMOazLVp3UjxlZ2dTVVUVcV9lZSV9+vQhIyODtWvXsmjRoojl4sUSRxQ+m1VljOlF+fn5nHzyyRx77LGkp6dTUFDQum/69OnMnj2bcePGMWbMGKZNm3ZIY7PEEUVoi8N6qowxveGpp56KuD01NZWXX3454r6WcYx+/fqxcmXb4uHf/e53eywuu44jitAxjoBlDmOMaWWJIwqfjXEYY0xEljii8NusKmOMicgSRxQ2q8oYYyKzxBFF6KwqyxvGGNPGEkcUPlsd1xhjIrLEEYXfZlUZYw4jWVlZAOzYsYOLLrooYpni4mKWLFnyid/LEkcU1uIwxhyOBg0axHPPPRfX97ALAKOwFocxpjf94Ac/YNiwYXzzm98E4M4770REmD9/Pvv376epqYm77rqLmTNntqu3ZcsWzj33XFauXEldXR3XXXcdq1evZuzYsYfHWlUiMh24D/ADj6rq3R32i7d/BlALXKuqy0QkDZgPpHoxPqeqP/bq9AX+CgwHtgCXqOr+no7dZlUZY1rdmRvHY1dG3HzZZZdxyy23tCaOZ599lldeeYXvfOc75OTksHfvXqZNm8b5558f9Z7hDz30EBkZGaxYsYIVK1YwcWLP3AI7bl1VIuIHHgTOBo4GLheRozsUOxsY7T1mAQ952xuAL6jqeGACMF1EWhZjuQ14Q1VHA294r3tc6Kwqa3AYYw61448/nt27d7Njxw4++OAD+vTpQ2FhIXfccQfjxo3j9NNPZ/v27ezatSvqMebPn996/41x48Yxbty4Hoktni2OKcAGVd0EICLPADOB1SFlZgJPqqoCi0QkT0QKVbUMqPbKJHsPDalT7D1/AigBftDTwduV48aY3nbRRRfx3HPPsXPnTi677DL+8pe/sGfPHpYuXUpycjLDhw+PuJx6qGitkU8inomjCNgW8roUmBpDmSKgzGuxLAVGAQ+q6rtemQIvsaCqZSIyINKbi8gsXCuGgoICSkpKuhX8/vpg6/O6hoZu1z+UqqurLb5PKNFjTPT4IPFj7G58ubm5bcua31oan6AAvPcIBAJhy6ifd955fOtb36K8vJyXX36Zv//97+Tl5VFfX8+rr77K1q1bqa6ubq1XVVVFdXU1wWCQqqoqpk6dyh//+EcmT57M6tWrWbFiBTU1NRGXa6+vr4/584ln4oiU5jr+dI9aRlUDwAQRyQP+ISLHqurKCOUjUtWHgYcBJk+erMXFxbFWBWBPVQOUvA5AUlIy3a1/KJWUlFh8n1Cix5jo8UHix9jd+NasWUN2dnb8Auqgqqoq7P2mTJlCbW0tQ4YMYfTo0Vx//fWcd955nHbaaUyYMIGjjjqKrKys1nrZ2dlkZWXh8/nIzs7mlltu4brrruPkk09mwoQJTJkyhczMzIjnlZaWxvHHHx9TrPFMHKXAkJDXg4Ed3S2jqhUiUgJMB1YCu1q6s0SkENjd04GDzaoyxiSGDz/8sPV5v379WLhwYcRy1dWud3/48OGty6mnp6fzzDPP9HhM8byOYzEwWkRGiEgKcBkwp0OZOcDV4kwDKr2E0N9raSAi6cDpwNqQOtd4z68BXohH8H67jsMYYyKKW4tDVZtF5CZgHm467uOqukpEbvD2zwbm4qbibsBNx73Oq14IPOGNc/iAZ1X1X96+u4FnReR64GPg4njEL7ZWlTHGRBTX6zhUdS4uOYRumx3yXIEbI9RbAUTsbFPVcuCLPRtpOLuOwxijqnGZlZRotJvd8bbkSBQ2xmHMZ1taWhrl5eXd/lI93Kgq5eXlpKWlxVzHlhyJwtaqMuazbfDgwZSWlrJnz55D8n719fXd+vLuSWlpaQwePDjm8pY4orA7ABrz2ZacnMyIESMO2fuVlJTEPB22t1lXVRQheYOgdr8P0BhjPq0scUQhIkiH5GGMMcYSR6dsZpUxxoSzxNEJn41zGGNMGEscnbAWhzHGhLPE0QmbWWWMMeEscXSi3eB4MHo5Y4z5LLHE0Qm7etwYY8JZ4uiEjXEYY0w4SxydsFlVxhgTzhJHJ9rdk8MShzHGAJY4OtVujMO6qowxBrDE0SmbVWWMMeEscXTCZlUZY0w4SxydsFlVxhgTzhJHJ0JnVdmy6sYY41ji6ES7FoclDmOMASxxdCp0cNy6qowxxolr4hCR6SKyTkQ2iMhtEfaLiNzv7V8hIhO97UNE5E0RWSMiq0Tk5pA6d4rIdhFZ7j1mxCv+dosc2qwqY4wB4njPcRHxAw8CZwClwGIRmaOqq0OKnQ2M9h5TgYe8f5uBW1V1mYhkA0tF5LWQur9W1XviFXsLm1VljDHh4tnimAJsUNVNqtoIPAPM7FBmJvCkOouAPBEpVNUyVV0GoKpVwBqgKI6xRuSzWVXGGBMmbi0O3Bf9tpDXpbjWRFdlioCylg0iMhw4Hng3pNxNInI1sATXMtnf8c1FZBYwC6CgoICSkpJun0B1VV3r82XLllG12d/tYxwK1dXVB3V+h0qixweJH2OixweJH6PF13PimTgkwraOP9s7LSMiWcDzwC2qesDb/BDwU6/cT4F7ga+GHUT1YeBhgMmTJ2txcXE3w4ffrV0IFfsAGDd+AlOPyO/2MQ6FkpISDub8DpVEjw8SP8ZEjw8SP0aLr+fEs6uqFBgS8nowsCPWMiKSjEsaf1HVv7cUUNVdqhpQ1SDwCK5LLC7azaqyMQ5jjAHimzgWA6NFZISIpACXAXM6lJkDXO3NrpoGVKpqmYgI8BiwRlV/FVpBRApDXn4JWBmvE7BZVcYYEy5uXVWq2iwiNwHzAD/wuKquEpEbvP2zgbnADGADUAtc51U/GbgK+FBElnvb7lDVucAvRGQCrqtqC/CNeJ2Dzaoyxphw8RzjwPuin9th2+yQ5wrcGKHe20Qe/0BVr+rhMKPy2f04jDEmjF053on2XVWWOIwxBixxdMpnS44YY0wYSxydsK4qY4wJZ4mjE+1vHduLgRhjTAKxxNEJn82qMsaYMJY4OhF6Pw67kZMxxjiWODrRvqvKEocxxoAljk7ZjZyMMSacJY5O+G1WlTHGhLHE0QmbVWWMMeEscXQidFaVtTiMMcaxxNEJ66oyxphwljg6YUuOGGNMOEscnfDZdFxjjAljiaMT1lVljDHhLHF0ot2y6pY3jDEGsMTRKeuqMsaYcJY4OhE6OG43cjLGGMcSRydCxzhsdVxjjHEscXTCZ7eONcaYMHFNHCIyXUTWicgGEbktwn4Rkfu9/StEZKK3fYiIvCkia0RklYjcHFKnr4i8JiLrvX/7xCt+a3EYY0y4uCUOEfEDDwJnA0cDl4vI0R2KnQ2M9h6zgIe87c3Arao6FpgG3BhS9zbgDVUdDbzhvY4Ln82qMsaYMPFscUwBNqjqJlVtBJ4BZnYoMxN4Up1FQJ6IFKpqmaouA1DVKmANUBRS5wnv+RPABfE6Ab91VRljTJikOB67CNgW8roUmBpDmSKgrGWDiAwHjgfe9TYVqGoZgKqWiciASG8uIrNwrRgKCgooKSnp9gls3tzU+nzLxx9TUrKr28c4FKqrqw/q/A6VRI8PEj/GRI8PEj9Gi6/nxDNxSIRtHX+2d1pGRLKA54FbVPVAd95cVR8GHgaYPHmyFhcXd6c6ABv8m2DdGgAGFQ2muPiYbh/jUCgpKeFgzu9QSfT4IPFjTPT4IPFjtPh6Tjy7qkqBISGvBwM7Yi0jIsm4pPEXVf17SJldIlLolSkEdvdw3K2sq8oYY8LFM3EsBkaLyAgRSQEuA+Z0KDMHuNqbXTUNqPS6nwR4DFijqr+KUOca7/k1wAvxOgFbcsQYY8LFratKVZtF5CZgHuAHHlfVVSJyg7d/NjAXmAFsAGqB67zqJwNXAR+KyHJv2x2qOhe4G3hWRK4HPgYujtc5+Gw6rjHGhInnGAfeF/3cDttmhzxX4MYI9d4m8vgHqloOfLFnI40sNHFYV5Uxxjh25Xgn/CGfji1yaIwxjiWOTlhXlTHGhLPE0YnQwXHLG8YY41ji6ITf7sdhjDFhLHF0wrqqjDEmnCWOTtisKmOMCWeJoxM2q8oYY8LFlDhE5GYRyfGu8H5MRJaJyJnxDq63tWtxWFeVMcYAsbc4vuotMngm0B93hffdcYsqQdiSI8YYEy7WxNHyDToD+IOqfkCUK7s/TXw2q8oYY8LEmjiWisiruMQxT0SygWD8wkoM1lVljDHhYl2r6npgArBJVWtFpC9tCxJ+arW757i1OIwxBoi9xXEisE5VK0TkSuCHQGX8wkoMPptVZYwxYWJNHA8BtSIyHvg+sBV4Mm5RJYjQFof1VBljjBNr4mj2lkCfCdynqvcB2fELKzG0W3LEMocxxgCxj3FUicjtuJsrfU5E/EBy/MJKDDaryhhjwsXa4rgUaMBdz7ETKAJ+GbeoEoTNqjLGmHAxJQ4vWfwFyBWRc4F6Vf1MjXFYi8MYY5xYlxy5BHgPd3/vS4B3ReSieAaWCEJnVVneMMYYJ9Yxjv8CTlDV3QAi0h94HXguXoElgnZLjljmMMYYIPYxDl9L0vCUd6PuYctv9+MwxpgwsX75vyIi80TkWhG5FngJmNtVJRGZLiLrRGSDiNwWYb+IyP3e/hUiMjFk3+MisltEVnaoc6eIbBeR5d5jRozn0G1i9+MwxpgwsQ6Ofw94GBgHjAceVtUfdFbHm7L7IHA2cDRwuYgc3aHY2cBo7zELd6Fhiz8C06Mc/teqOsF7dJnADpZdx2GMMeFiHeNAVZ8Hnu/GsacAG1R1E4CIPIO7gHB1SJmZwJPexYWLRCRPRApVtUxV54vI8G68X4+zWVXGGBOu08QhIlVApG9MAVRVczqpXgRsC3ldCkyNoUwRUNZZXMBNInI1sAS4VVX3R4h9Fq4VQ0FBASUlJV0cMtzeurYFgOvq6g/qGIdCdXV1wsYGiR8fJH6MiR4fJH6MFl/P6TRxqOonWVYk0v06OiahWMp09BDwU6/cT4F7ga+GHUT1YVz3GpMnT9bi4uIuDhuurLIO/u/fACSnpHIwxzgUSkpKEjY2SPz4IPFjTPT4IPFjtPh6TjxnRpUCQ0JeDwZ2HESZdlR1l6oGVDUIPILrEosLm1VljDHh4pk4FgOjRWSEiKQAlwFzOpSZA1ztza6aBlSqaqfdVCJSGPLyS8DKaGU/KZtVZYwx4WIeHO8uVW0WkZuAeYAfeFxVV4nIDd7+2bgpvTOADUAtITeHEpGngWKgn4iUAj9W1ceAX4jIBFxX1RbgG/E6B5tVZYwx4eKWOAC8qbJzO2ybHfJcgRuj1L08yvarejLGzvitxWGMMWE+9Vd/fxK2VpUxxoSzxNEJv92Pwxhjwlji6ITPZlUZY0wYSxyd8NkYhzHGhLHE0Yl2y6pbi8MYYwBLHJ0KyRsEFdSShzHGWOLojIi0WxPFequMMcYSR5dCWx02s8oYYyxxdEnadVdZ4jDGGEscXbAWhzHGtGeJowuhH5C1OIwxxhJHl9rNrApGL2eMMZ8Vlji60K6rylocxhhjiaMrYmMcxhjTjiWOLrRbdsRaHMYYY4kjqsZa2LaYS3mNifIRYInDGGPAEkd0C+6Hx07nDnmcc/2LAOuqMsYYsMQRXeH41qfH+LYANqvKGGPAEkd0A8e1Pj1atiIEbVaVMcZgiSO6nEGQ0Q+AbKljqOy2ripjjMESR3QiUNjW6jhWttiy6sYYQ5wTh4hMF5F1IrJBRG6LsF9E5H5v/woRmRiy73ER2S0iKzvU6Ssir4nIeu/fPnE7gQ7jHNZVZYwxcUwcIuIHHgTOBo4GLheRozsUOxsY7T1mAQ+F7PsjMD3CoW8D3lDV0cAb3uv4CBnnOEa2WFeVMcYQ3xbHFGCDqm5S1UbgGWBmhzIzgSfVWQTkiUghgKrOB/ZFOO5M4Anv+RPABXGJHsJaHMGAJQ5jjEmK47GLgG0hr0uBqTGUKQLKOjlugaqWAahqmYgMiFRIRGbhWjEUFBRQUlLSreAB0CAnkEYm9fSTA7y+8FXKN0Z8u15VXV19cOd3iCR6fJD4MSZ6fJD4MVp8PSeeiUMibOv4kz2WMgdFVR8GHgaYPHmyFhcXH9RxVswfzjhdC8CkQUmMPuXgjhNPJSUlHOz5HQqJHh8kfoyJHh8kfowWX8+JZ1dVKTAk5PVgYMdBlOloV0t3lvfv7k8YZ6c+9hW1Pk89sLl7lVWhek8PR2SMMb0rnoljMTBaREaISApwGTCnQ5k5wNXe7KppQGVLN1Qn5gDXeM+vAV7oyaA7KpOBrc9TDmyNvaIq/PEcuGcUzL8nDpEZY0zviFviUNVm4CZgHrAGeFZVV4nIDSJyg1dsLrAJ2AA8Anyzpb6IPA0sBMaISKmIXO/tuhs4Q0TWA2d4r+OmzFfQ+jz1wJbYK+5ZC1vfcc+X/rFHYzLGmN4UzzEOVHUuLjmEbpsd8lyBG6PUvTzK9nLgiz0YZqd2+ttaHGlV3WhxVG5ve15V5ha68tn1lsaYw599k3VhZ8ikrdTqUgg0x1axKmSoJtgMNTbWYYz5dLDE0YWAP52d6i5O92kzVG7roobnQIcx/qquxvyNMebwYImjCwMzhK3aNs7Bvk2xVTywvf3rqp09F5QxxvQiSxxdGJztY0uwbZwj9sTRYXJYxxaIMcYcpixxdGFItq9DiyPGaznCuqpCEkn5RnjyAvjXdyAY+ORBGmPMIWSJowuDsnxspS1xBMo3xlax45hGaAvk3z+FTW/Cksdh7Us9EKUxxhw6lji6kOIXmnJHtL7WjxfBjuWdV2qqg7r97be1JJJgEDb9X9v2lms9jDHmMGGJIwbphUexR3MASGqogMfPgjUvRq8QaTyjpcWxZw3UhSz6+/GiHozUGGPiL64XAH5ajBzUn/9c800eTL6PHKmD5nr465VuZ2Z/OOO/of9RsOJZd73GnnXhB2lpcWx5u/32nR9CQzWkZsX3JIwxpodY4ojBmIHZ/Co4jpmNd/F05r0MbA5pUdTsgX/+B4gPNBj9IPWV0FgLW95qv10DsGMZjDg1PsEbY0wPs66qGIwd6LqpNmshlzT9hGDh8eGFOksaLX45KnIX18fvRi6/Zx28/pP2YyLLnoQ/XwSb58cQuTHG9DxrccRgSN90huVnsLW8lo8bMnl16hNMz1gHSSnw+p2w431XcPjnwlsUoZpqIm//eGH4tsZaN2W3age8/SsYMwOGnwLz7mir882FkDc09hOp2w++JEjNjr2OMcZ0YC2OGIgIF0xouy/H8yv2wJFnwhHFcO1cmHEPXPQ4XD0HLnsqtoMOCbkZ4sY3YOHv3HNVaKyBxY+2n9K7bm5b0gBorIYXbnSztGKxbTHccyT8cjSUfRBbnVCNNe79/nhu7BdBGmM+lazFEaMLji/ivjfWA1Cybjf7axrpk5kCKRkw5ettBY88G1Ky3Bc7wLCT20+5nXg1pObASd+G569va6HMux12rXKtlyI42U8AACAASURBVN2rYgtq83x44jwy+1/iBthXPAMZ+TB2JqDwwTPw/p9hyBTYtRICja7ey7fBV1+O/eRVYc63YOXz7vVrP4ZL/+SeBwNufEci3czRGPNpZIkjRiP6ZTJhSB7Lt1XQFFD+/v52rj9lRHhBnw+ueRFeuR0GT4Yjz3JdTuJzX7Zjzm4re+mf4KnLYJs3JXf5n8OPlzcUvvwovPpDKH0P0vvCyNPavsS3vs3krQtg7c+g2lsPa+A4l7haWgYfL2h/zI8XQNUuyC4gJot+1/Z+AGvmuISxZy38+UI38H/shXDq96DPsNiOaYw5bFni6IYLJw1m+bYKAB58cwMXTx5MTlpyeMGiiXD9vLbX317mEkfH8Yj0PnDVP+Af33BfxpF84UcwdCpc/6obLM8a4FosOYNc95YGEIJtSQNg54quT+b9P8Gp3w3f3lgLH73s3qNwvOuiev0n4eVKF8NL321bSuX9P8HGf8N/vOPOK5L9W2DvejcWlJzWdYzGmIRkiaMbLp40mNklG9leUce+mkZml2zk+9OP6rpin+HR96VkwCVPwsIHYMEDMGiC++W+cwVkDYSjZrhyIjAg5L3OvAsmXAFzv9fW3ZWaC021EGzqOqZFD7mWyegz2rqZKkvhqUtdt5Z7U0Aj1//zhW3dcS0ObIflT8GJ7e/NlV5b5spveN1tOPZCNyZkjDksWeLohrRkP987awy3/NUtOfLo25v50vFFjC74hLOUROCkb7lHi8GTu643YCxc8yIr/n4v4wpT4bhLoKEKPnrF7Rt6IvztGlj/anjd2r3w1MVQOMG9b8Gx8OTM9i2XjknjhK+5QXtonzSyC9taHvPucNOHM/Lh898DXxITlt8BjSFXy6/8O5x+Z/dmhBljEobNquqm88cPYtzgXAAam4Pc/MxyGpp7cYVbEfblT3Zf/tkF0G8UnHQTjPqiN3A/q61sel/4yt8gLbdtW9lyN0j/+1PbJ43M/u3fZ8IV8Llbw99/0PFw43uutdNi/Tz44Cl4cCr85jhSQ5MGAApLn3Bdb82NB33qPa52H7x0q9cFGKGlFQzCsj91vtyMMZ8Blji6yecTfnHROFKS3Ee3uuwAv3glwhIjiWLkF2H85ZCW57q3jjwTvrUMJl0L/tS2coEG929Klhvc/94Gl2QKJ8DIL7i6OYOg35i2OsmZcOmfIS0HJnwl/L0DIUnBnwKTv9r2+q174MEpcP8EWP2C+9IO/bJe9if4WZFLPgt+CzV73famOnj+a/Do6bB7bfv3qz8Aix+D3Wvab6+riO2zeuEm16Kad7vrcuvorXthzk1uuZmOyePNn8Fvxrm45v2XGysKtfNDd81Px5iNOQxZV9VBOGpgDreffRQ/eXE1AI+9vZkJQ/I4b/ygXo4sAp8PvjTbfSm3jGVk9oPz7oMv/hje/J+27qfkDLjibzDsJPf6yDPdI9TUb8BL/+laJFf9E3IHu+1Tvg5L/wjNddDvSHeR4falAAR8KfgvfNRNVV7zYvv7rx/YDs9e7Z4POBpO+y/XhfWv77ixmj1r3Yyy138C4y5xsX/4N1f+n/8Bn/+Bu8Zl0jWuTtkHrkV142I3SP/89W7iwYjPw5cfCZ9JtvwpKLmb43z9Yd+Stu1v/gxGn+nuF59V4JLguw+17V/0EIw9zz3fthj+7+fuecVWN3GgvgLOvQ8aDkByOvzpy1Cz2y2lf9MSN8nBmMNUXBOHiEwH7gP8wKOqeneH/eLtnwHUAteq6rLO6orIncDXgZZvnztUdW48zyOSa08azjsbynl9zS4Avv/cCsYW5jBqQIIuVhjpOouMvnDOve4LcMPrMO4yGHhs58eZ/FXXDZaR3/4K9PyR8LXXYNdqOOocSMl04x4a5J0lqzj16LNcueOvclfCR7J7Nfz1isj7gk2w/C/tt+1YBk9f6p4ve6Jte30lvPd7qN7VNltt8//B7FNg/GVw3MVQOA72b4UXb4ZAI/lsbX/sA6Vwzyj3PDnDTToItfUdWP86ZPSBhb8Nj/f9P7sHAkWTXNJoie2ByW4lgEET3biRr0PDPzTJR1JXAe/8xrUiT/p2eP1oDuyApDT3d68sdTPm+o/put7B2L0GNpW4GXRd/TdlDjtxSxwi4gceBM4ASoHFIjJHVVeHFDsbGO09pgIPAVNjqPtrVb0nXrHHQkT41aXjmfnAO2zeW0NdU4Bb//YBz99wIkn+w6wH8Ihi94iFSPRZYgOPc48WOa4FFvRvaNt26vfcwLr44fgr3JfrxjfdVN2W7rIWSenwhR+6rqzS92KLr8Vb94Zvq9kNC+53j6POhW3vte9Oi6Zj0mjxlwvDt+WPgvKQ80Vh+5L2Zeor4YOn3aN0MZz/Wzc9efN817qqLIXz7ncrLq9/FY75Ukgs9W7mW8u1PyJw8s3tj6/qJkgEmtx1Q/u3wms/gnUvudbYybe4FlJzvVv1IPQC1kiCQTeZImuAi335025sa+jUtv2V29q6Gqt2wmNnQUOle330THc+6XnR36Nmr0uE/ihfScGgu/nZjvfdrLy+3jVUtftg70cweErkBPz6ne7HwwlfBx0bftzGGihd4i6STU7v/HMwreLZ4pgCbFDVTQAi8gwwEwhNHDOBJ1VVgUUikicihcDwGOr2upy0ZH53xUTOf+BtmgLKB9sq+PXrH/HdM8cgdiV1ZCkZMOOXba/P9rp4avbC/Htcq6LhgNt21v/ACde7wf5X7oBFDx7ce2YPcgmidm/btrX/ily2aJK7uLFsOSDui7Y+xjGSI4rhoj/A707sMDutEx8+C+tedq2AipBWT2jLa+EDpBxzF5StgNd/3JY0wCWErQtd91/+KDdle9U/vfhx5169s20RzvpKeCPkupx5d7jlbwrHuS/Rim2upbZ9iftSzuzvWnP7NrkEsHe9axkCTPumu9bn7V/DnrUcn3MUTHsF3rmvLWmAS/wN1S6JbV3gkp34wed3/5Ytd1PAc4dC8W3uR0TNHpf4drzvWq4iUFvujrfgfvjKs26869lr3HtNuNKNsy3/i2vxHnWO6xZ95zfeed7O2AGfhynHue5OcDMQHzvLrdTQ70g462cueQeboc8IGH+p++/yg6eh70jXdZmZ3/7vV18JH73qWm6F42L7m4cKBmFzCSSlIaG3kQ4G3fk2Vrm/QV2FazEOOKr95JauWqfBoPt8ol1bdZBEI80e6YkDi1wETFfVr3mvrwKmqupNIWX+Bdytqm97r98AfoBLHBHrel1V1wIHgCXArara4XZ7ICKzgFkABQUFk5555pmDOo/q6mqysjrvfvrXxkaeW9927cSx+X5uGJ9KVsqhSR6xxNibuhOfBJvJrtpI0JdMdfYRIdsDjF1zLwP2vMPe/BOoSx/IkNIXCUoSG0dex+DSOYgq5fmTKNrRtpzK7v4ns2bsdxAN0mf/Cgp2/ZsBe9pfSV/edzIVyQPIa9rFhlFfozGlD5k1W6nNGERzcg75exczZt1vSWmqZOvQC+m/ZxEZddsBUHzuAkzgg3E/Zn/fiaTX7vDiCTCorG0qdFXWSFT8pNXvJqUpxmR0CNSlDWRP/xMp2j4Xf7Ch6wqdaEjpQ2pj2P+Oh9yOwrMYVDYvbHvAl8ruAaewv894Rmx+ivT66Am+Nr2Q5KZqkpurAPe3rsw9ioq8cdSlF5BWv5vBpf9q3V+ZM4by/CmkNuwl58A6gr4UAv40fMFmGlL7Up01guqsI0ht2Et21Qbq0gvJq/iQfuWLAWhMyqK83zREg/TfswB/sD5C/GmUFX6Rmszh9N/zNjkH1rGn/0lsHnElKkkM2D2ftPpdVGUfSXrdTgbufI2q7NGsPub7B/U5nnbaaUtVNezagHgmjouBszp8+U9R1W+FlHkJ+N8OieP7wBHR6opIAbAXd5HBT4FCVQ2ZrhNu8uTJumTJks6KRFVSUkJxcXGnZZoDQb7y6Lu8t7lt2ukpo/rx5Fen4PPFP3nEEmNv6rH4VN2v4Zapwutfdb8E+x/Z9surqR6euRxKl8Kpt7oxgI6/yHaudFe6r5vrxmou/TMl72/oPMamOteFlD8KKj52v6KHnQRJqfDeI+7X5glfC68393vw3sOAwDVz2u67ourqLXrQ/cIGt3Jx/7Gw68OuP4v+R7mJA51JSnPdUeBm140+w7VQAo1un/iid8P1hMIJbkXnhQ/E7z1M13zJcOvatpZWN4hIxMQRz66qUmBIyOvBQMd7qkYrkxKtrqruatkoIo8AUfocDp0kv48nvzqFe19dx6Nvb0YV3t6wl0ff3sSsU0f2dnifHiKQPbDtdei6Xy3JITnNLeMSDEYfNB54rOsia+kmA2BD5LItktOh32j3vM8wOPnbbfvOvz96vel3u0Hw7IL2N+sSgamz3PhC+QZobnDHT0p1XSx/nwV5w9zKAS3jNf5UGHuu6yIqmuQu7lz9gutmOe0Ot/7Y1rddd9OUWW6dtPWvuhUCWgaoC8e7rpcJV7ixiH/c4GbCtcgpcmNTA452zyu2uokPe9e7euAmOAw+wR070OS6adJy0X/fhYReNFp8u5tIsWO5iyspDU75jkv2GnBdgsFm140y8Dh3nh8vhKHTXNIRcefWb4wb/8oqcMl7zrddOQ24ffs3t41V+ZLDV064YDakZFI190dkV28O/xuNOsMdr7EaxpzjPqu37nWxgZuiPuBoNx4VaSWFrALXrRfLig3RZOS3dcW1SMt1S/9U73b//aXluB8t3ZWa5boXe/BmcfFMHIuB0SIyAtgOXAZ0nOw/B7jJG8OYClSqapmI7IlWV0QKVdW7TJkvAStJAGnJfv7rnKNJ8vt4qGQjAL94ZR1HDczh1CP7d1Hb9LhYZxrFm88PEy6Pvl+kLSG1GHse3L7dq++DUWew8r0Sjj3vRvfl0eKiP7ov9ryh7n0Apt3Q/lgdr68ZdlLbdGtwCeD/fu7GEo6/0pvl5Q+PMxh0rZamWpd0/EluCnSIpZV9mZy9x32RD50GY6a7HVe/4Aa2C45pnTAR0cwYWib5I+G6l1w8jdVuZl/Zcvjbte5L9qLH3WSLLfNdMh5xqptJJ8LSXdkUj8pyEwd2r3HnUjjeTcBorHat1ZxC9z4Dj3NJ1ZfkrlUa8Tn3Bb7x3+6anAPbIXOASzLHXeLG5da/5safUrJc686f6pKy+N0Y0c4VrrWblAbDToSPF7nkXXwbHPNllr34CBOzdrmEdfRM94MjtLWs6t5/83x3vL4jXPzv3OfOR4Nu0sKwk9yAf0omjLvUTQTp6bXhVDVuD9w024+AjcB/edtuAG7wngtu9tRG4ENgcmd1ve1/8squwCWewq7imDRpkh6sN998s1vlG5sDev4Db+uwH/xLh/3gX3rUD1/WBRv2HvT7x6K7MR5qiR6fauLHmOjxqSZ+jN2Or75KtaEmLrFEkoifH7BEI3ynxvU6DnXXV8ztsG12yHMFbuxYL1pdb/tVPRxmj0r2+5h95UQuemgh2yvqqGsK8JVHF3HtScP57pljyEy1ay6NOSykJu6Ek96WIO35T5fC3HSevH4K+ZkpgGth/uGdLZz1m/ks2LC3i9rGGJPYLHHEycj+Wcz51intxjdK99dxxWPv8sC/1xMIxmc2mzHGxJsljjgqykvnietO4N6Lx5Ob7m74pAr3vPoRxfe8ybOLt7WM2xhjzGHDEkeciQgXThrMa985lSkj+rZu37avju8/v4InF27tpLYxxiQeSxyHyICcNP7ytan85xlHkpfRdrvZH89ZxfTfzOdHL6xkX00C3ZvCGGOisCk+h1Cy38e3vzia608ZweWPLGJFqVvPZ+3OKtburOKF5Tv4ytShZKUmccnkIfTPTu3iiMYYc+hZ4ugFmalJzL5yEuc/8DZ7q9taGZV1Ta0XDz6xYAuzTj2CitomzjymgHGDO1lZ1BhjDiFLHL1kUF46/7zxZErW7eHD0kqeX1ZKc8hMq91VDdz1kruT3e/nb+Sei8czc0IRADUNzTy3tJRAULlsypCIxwd3caet0muM6WmWOHrR4D4ZXDltGAAXThrMg29uYNeBetburGpXrimg3PzMcv60cCtD+mbw1vo9rS2VPyzYzIzBQSbWN5GT5sZOVu84wA//+SH7ahr5xUXj2w3KG2PMJ2WJI0FMGdGXKSOmAPDe5n3c9vwKKuqa2g2YL9m6nyVb2y9ZvW1fHb/fB4+veo3pxxYyMCeVPy3aSn2TW+r7+icW85tLJ5CbnsyxRbmkJUdYh8gYY7rBEkcCmjKiL//+bjEAlbVN3PGPD3ll1c52Fw0W5qZR09DMgXq3gmdTQHnxg46LD0NVfTPXP+GWlM/PTOErU4dy5bRhFOT03KJnqsq6XVWM6JdJapIlJmM+7SxxJLjcjGQevGIi5dUNvLV+L02BIANy0pg6oi9V9c089e7H/P29DWw9EOzyWOU1jfz23xt4qGQjxWMGcNYxBZw3flCnrZDmQJB5q3bxxtpdVNU30y8rletPGc6oAe5+42WVddz01Pss3bqfQblpPPHVKYwuyI56PGPM4c8Sx2EiPyuVC44varctLdnPzaePZnzSdgYcOZGXPtxBUGHCkDyKx/Rn3qpd/PiFlaQl+wmqsuuAu7tbc1B5fc0uXl+zi1+/9hEnjuzH/tpGBuamMTw/g2H5mYzol8nK7ZXc++pHbK+oa/e+zy8t5YxjCqhvDLBoUzk1je6Wlzsq67nk9wu5//Lj+dxoW0remE8rSxyfEkcPyuHoQTnttp0/fhDnj3f3P2gOBHl19S7+8M5mFm9pGyfZUVnP88tKu/VejYEgL60oi7hvf20TVz32HmcfO5D/Omcsg/tkdHm8fTWNvLZ6J0P7ZnLiyPwuyxtjepcljs+IJL+PGccVMuO4QjbvreGVlTt59K1NlMdwtXrfzBSumDqUIwuyefStTXzgXbjY4oh+mVz/uRHcM28d+2vdXdBeXrmTN9ft5ssTB5NV10zpoq34fUJ6sp+0ZB9pyX4amoO8tnoXL36wg4Zm19V2x4yjYrprYnVDM2+v38sR/TM50rrGjDmkLHF8Bo3ol8l/FI/kqhOHMW/lTuqaAuRnprCjsp6t5TVsKa9la3kNgaBywYQibigeSZZ3H5EZxxXy7qZydlXVIwjjBucyol8mIsIZYwu4++W1/P19d/e6+qYgT73r3epyRWw3avzZ3LW8vHInfhG2V9QxakAWF08eQvGY/uSkJVPd0MyvXv2Ivy7+mJrGAD6B75x+JF8/9YjWsZraxmbqGgP0zUyx61iMiQNLHJ9hWalJXDhpcLfq+H3CSaMi3/R+QE4av7p0Al+ZOpQfz1nFqh0HDiqu9z+uaH1eVlnPW+v34hM4siCbyromyirrW/cHFe597SN+/fpHDMvPZGBOGks/3k9jc5Bxg3M5f/wgjuifybD8zNbEMygvrVuzvxqaA6T4fZaEjPFY4jA9bvLwvrx40yks3rKPeat28eHGjxk5ZBCqUN8coK4xQF1TgOaAcmxRDjOOK2TMwGxueWY5r67eFfGYQSXswsictKTW6chBhc17a9i8t6Z1/4rSytb1wELlpidzxdShjOyfRWaqn9QkP/O3NfHxwi2M6p9FbWOAD0oreGv9Xjbuqaaqvpns1CTGDMzm/AmDOPPogSjK2rIqFmzcy8JN5TQ1KznpSYwakM2RBVkU5aVz1MAchvRNb004lbVNLNpcTmNzkBNH5lNR28iG3TU0BoL0yUhmXFEeuSELYLZoaA5Q12zL75vEYYnDxIXPJ0w9Ip+pR+RTUrKb4uJxXdZ5+OrJ7KioY9OeGoKqDMhJZd5KN/tr5Y5KWm5dkpuezH/PPIZzjivk9/M38dzSUraU1xB6axO/T6LeLKuyronfeWuCtbNqVdTYqhqaWy/A/NEL0cuFTjwASE/2oyjNAW23pEw0xxblMHFoH/bXNlHT0Ex5dQOryw7QFFBy3p7H+CF5nDgyn2BQyc1I4ZhBORxdmNPaTRcIKhW1jZTXNBJUJTc9meaAUtsYoLKuiXc3lbNxTzXHFuUyc0IR/bNTCQaVvTUN7KhwLbn8zBT21TRSVd9MarKPtCQ3K2/z3hrSkv18/sj+pKfY9TqfZZY4TEIZlJfOoLz01tdHDczh5tNHc6C+ifW7qqmsa2Ti0D7kZbjb8t542ihuPG0UdY0BNu6ppnR/LaMGZNMnI5kXP9jBul1VbC2vZWt5LbWNzYhIt5ev94lr0RyMuqZAt8qv3H6Aldsjd/EdqG/mrfV7eWt9+9sP+33CgOxU6ptccogl1n8u38FdL60hLyOZ2sYAjc1dXwfUIjstifGD8+iTmULfjGT3b2YKZWXNVH2wg7LKOmoaAjQ0B2lsDiICKUk+dh9ooLKukWS/j6r6ZvbXNpKbnkxNY4BNe6oZlp/B+eMHkZeRQorfR0aKn6zUJBTYWVnPR7ur2H2ggXGDczl+aB8CwSCNzUpTwL1PUyBIc1DJSksiLz2Z3PRkAkHlQH0zVfVNLN/djH/9HlL8PlKS3CM1yUdyy2vv32S/296xa7IpEGTdzip2VNRRUdsEAtmpSQzMTaMwN53+2an4BCpqm9hT3UBeRjL9MlPx+eLTxVle3cCW8hpG9Muib2YKwaAiArWNAdburCI/M4Xh/TLj8t6WOMxhISctmUnD+kTdn57i59iiXI4tym3ddu3JI8LKtVzQuGhTOdUNzVQ3NFPfFKC5Zj9FhYWs311NerKPowbmMHVEXyYP70t+Zgp7qht4ZeVO/rZ0Gzsr6wmqm2RwXFEunz+yPwU5aeypbmBN2QG2lteybV8tK0orWrvSwH3BH1uUS4pfWLp1PznpyYwfnEdmqp9t++pYU3YgaqskyQfRvtsDQW037tMdFd4suO6oqm/m7Q17I+/84P2DigM6T5qh/uFNvjgoy96LuWiyX9olkwP1Ta1L+XRHkk/Iy0imb2YKPhFSk/30z0olNcm7HZKXV/bsrue5HctaE5bg/raVdU1U1jVRVd+ETwS/T1Bg457q1lZ2ZoqfmsYAfp8QVG3dftLIfK4/ZQSnjRnQowksrolDRKYD9wF+4FFVvbvDfvH2zwBqgWtVdVlndUWkL/BXYDiwBbhEVdv3DxgTRZLfxznjCjlnXGG77SUlJRQXj49aryAnjWtOGs41Jw3v9PifD7nHfDCo1DQ2k+TzkeQXknzS+qUQCCoC7f5nPlDfxPyP9rCjoo78zFRy05PJSPUzdmAOy997h9ETpvLmuj1s3F1NWrKfsso6Vm6vZNPe9t10uenJ5Ge5L6nKuqbWX+8ZKX6O6J/FUQOzeX3NLlaUVrZOg85NT6bIa+ntrW6gb2YKfTJSaAwEqWsMEFRlSN8M1u+qYkt5bSwf9WGvKaA0BQKtF7gerOagsre6sd0tFKLaGfn6qK60xNixe3bBxnIWbCznd1dMZMZxhZGqHpS4JQ4R8QMPAmcApcBiEZmjqqtDip0NjPYeU4GHgKld1L0NeENV7xaR27zXP4jXeRhzsHw+ITstfLAbXOujo5y0ZM4dNyhieRFhcJ8MrvJWUw5V0+C6fdKS/eSkJZOS1PWNPb/x+ZFubKO6gYzUpNbp1l0JBt26ZLsO1LO/tpF9NU1U1Dayr6aRdVu20ze/H4Py0slNT27tClKF+qYA+Vmp5Gel0BQIkpHip29mKpV1TST5hKF9M5i/fg8fbKsgqNDYHKTGaxEqMCA7leH5mfTJTGHBhr3sPFAf1r2U4vfh9wkH6t0v9IraJpL9QlZaMjlpSVRW7Cc7N49GrwutMaA0Ngdo9Lq6XHeXevsitywG90ln1ADXNQRwoK6ZnQfqKKuob70mKjPFz4CcNPbVNFJZ1/0WXax84lq9H++rpSnQljDE2761vJZAUCnISeX0sQU9+t7xbHFMATao6iYAEXkGmAmEJo6ZwJOqqsAiEckTkUJcayJa3ZlAsVf/CaAESxzmMywzNYnMGL/4Q/l8woBuLnbp8wljC3MYW5gTtq+kpJzi4sndjqPFFVOHccXU8MTY0fWnhHdBxsK1KqfFVFZVwxJKSpKvNWFE0zLO0NKybDnOvppG9te4JFLT6CY9NAfbupQUWL16NWPHjm13PBEhJy2JvIwUstPc39hNtAgyOC+D3IxkGpoD1DcFyUpNIqhKUJXUJD/bK+p4YsEWBuWmxfRjojvimTiKgG0hr0txrYquyhR1UbdAVcsAVLVMRAZEenMRmQXMAigoKKCkpOSgTqK6uvqg6x4qiR5joscHiR9joscHiR9jIsUXKV0fm11PVsX6iOUrvEeoPTG8z0kZQBOUlGztXoBdiGfiiDQS03HkL1qZWOp2SlUfBh4GmDx5shYXF3eneiv3K+Xg6h4qiR5joscHiR9joscHiR+jxddzerb90l4pEHpf08FAxxtGRCvTWd1dXncW3r+7ezBmY4wxXYhn4lgMjBaRESKSAlwGzOlQZg5wtTjTgEqvG6qzunOAa7zn1wAvxPEcjDHGdBC3ripVbRaRm4B5uCm1j6vqKhG5wds/G5iLm4q7ATcd97rO6nqHvht4VkSuBz4GLo7XORhjjAkX1+s4VHUuLjmEbpsd8lyBG2Ot620vB77Ys5EaY4yJVTy7qowxxnwKWeIwxhjTLaL66V+uWUT2AAc7kbkfEGVhnoSR6DEmenyQ+DEmenyQ+DFafN03TFX7d9z4mUgcn4SILFHVg78c9hBI9BgTPT5I/BgTPT5I/Bgtvp5jXVXGGGO6xRKHMcaYbrHE0bWHezuAGCR6jIkeHyR+jIkeHyR+jBZfD7ExDmOMMd1iLQ5jjDHdYonDGGNMt1ji6ISITBeRdSKywbvbYG/HM0RE3hSRNSKySkRu9rbfKSLbRWS595jRy3FuEZEPvViWeNv6ishrIrLe+zf6DcTjG9uYkM9puYgcEJFbevszFJHHRWS3iKwM2Rb1MxOR273/LteJyFm9FN8vRWStiKwQkX+ISJ63fbiI1IV8lrOjHznuxG657AAABTFJREFUMUb9uybIZ/jXkNi2iMhyb3uvfIYxU1V7RHjgFlfcCBwBpAAfAEf3ckyFwETveTbwEXA0cCfw3d7+zELi3AL067DtF8Bt3vPbgJ8nQJx+YCcwrLc/Q+BUYCKwsqvPzPubfwCkAiO8/079vRDfmUCS9/znIfENDy3Xy59hxL9ronyGHfbfC/yoNz/DWB/W4oiu9da3qtoItNy+tteoapmqLvOeVwFrcHdLPBzMxN3qF+/fC3oxlhZfBDaqas/eHu0gqOp8YF+HzdE+s5nAM6raoKqbcatLTznU8anqq6ra7L1chLtvTq+J8hlGkxCfYQtx95q9BHg6njH0FEsc0UW7rW1CEJHhwPHAu96mm7wug8d7qxsohAKvishS7xa+0OGWv0DEW/4eYpfR/n/URPoMIfpnloj/bX4V+P/t3U1oHHUYx/Hvz1aKbbS+UKEIalMVRNBYb9aKoAcjWnyp+FKLiBehl+KlSBTBu97EFhGsGkGqLRTBizkEepBIo9H6Lj0VQ4QilSqKpo+H/7O6edk1g7s7g/w+sGTyZ3byn2dmeWb+k/0/H7T9vknSJ5ImJW2rq1NpuePatBhuA+Yior12bJNiuIATR2f/uXxtv0gaAt4D9kTEz8ArwGZgBJil3PLWaWtEbAFGgd2Sbq25P0tkgbDtwMFsaloMu2nUuSlpDPgTGM+mWeDyiLgReBp4W9IFNXWv03FtVAyBR1h4EdOkGC7hxNHZSkrfDpykcylJYzwiDgFExFxEzEfEWeBV+nzL/W8i4of8+SNwOPvTtJK/o8B0RMxB82KYOsWsMeempMeBu4GdkYPzOfxzKpePUZ4fXFNH/7oc1ybFcDVwP/BOq61JMVyOE0dnKyl9O1A5Dvoa8FVEvNTWvrFttfuA44vfOyiS1kk6v7VMeYB6nOaV/F1whdekGLbpFLMjwMOS1kjaBFwNTA26c5LuBPYC2yPi17b2DZJW5fJw9u/EoPuXf7/TcW1EDNMdwNcRcbLV0KQYLqvup/NNflHK2n5LyfZjDejPLZTb6c+AT/N1F/Am8Hm2HwE21tjHYcp/q8wAX7TiBlwCTADf5c+La+zjWuAUsL6trdYYUpLYLPAH5Wr4yW4xA8byvPwGGK2pf99TnhO0zsV9ue4DeexngGngnhpj2PG4NiGG2f468NSidWuJ4UpfnnLEzMwq8VCVmZlV4sRhZmaVOHGYmVklThxmZlaJE4eZmVXixGHWcJJuk/R+3f0wa3HiMDOzSpw4zHpE0mOSprJ+wn5JqySdkfSipGlJE5I25Lojkj5qq2VxUbZfJelDSTP5ns25+SFJ72b9i/GcRcCsFk4cZj0g6VrgIcoEjyPAPLATWEeZE2sLMAk8n295A9gbEddTvtncah8HXo6IG4CbKd80hjIT8h5KHYlhYGvfd8qsg9V1d8Dsf+J24Cbg47wZOI8yKeFZ/pm87i3gkKT1wIURMZntB4CDOcfXZRFxGCAifgPI7U1FzmWUVeKuBI72f7fMlnLiMOsNAQci4pkFjdJzi9brNsdPt+Gn39uW5/Fn12rkoSqz3pgAdki6FP6uF34F5TO2I9d5FDgaEaeBn9qK8+wCJqPUVjkp6d7cxhpJawe6F2Yr4KsWsx6IiC8lPUupfHgOZQbU3cAvwHWSjgGnKc9BoEyTvi8TwwngiWzfBeyX9EJu48EB7obZinh2XLM+knQmIobq7odZL3moyszMKvEdh5mZVeI7DjMzq8SJw8zMKnHiMDOzSpw4zMysEicOMzOr5C9/f/wc5rfehQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_o_dups_jcw model created and file saved for future use.\n",
      "End model and train\n",
      "\n",
      "Opening file:  clean_wo_dups.p\n",
      "cleantrain/clean_wo_dups.p\n",
      "Train Shape: (6478, 31)\n",
      "Begin model and train:\n",
      "Model name: clean_wo_dups_jcw\n",
      "Scaling 6478 images...\n",
      "Scaling of 6478 observations complete.\n",
      "Index(['left_eye_center_x', 'left_eye_center_y', 'right_eye_center_x',\n",
      "       'right_eye_center_y', 'nose_tip_x', 'nose_tip_y',\n",
      "       'mouth_center_bottom_lip_x', 'mouth_center_bottom_lip_y', 'image'],\n",
      "      dtype='object')\n",
      "Begining the split of Train with all features\n",
      "Looking for model JW\n",
      "JW model file not found. Model creation beginning\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 32, 32, 32)        288       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 8, 8, 64)          8192      \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 2, 2, 128)         32768     \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 2, 2, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 8)                 4104      \n",
      "=================================================================\n",
      "Total params: 374,952\n",
      "Trainable params: 374,504\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "None\n",
      "Done compiling\n",
      "Epoch 1/300\n",
      "161/161 [==============================] - 4s 20ms/step - loss: 0.0946 - mae: 0.1883 - mse: 0.0946 - val_loss: 0.0124 - val_mae: 0.0893 - val_mse: 0.0124\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 0.08933, saving model to data/models/clean_wo_dups_jcw.h5\n",
      "Epoch 2/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 0.0090 - mae: 0.0702 - mse: 0.0090 - val_loss: 0.0128 - val_mae: 0.0881 - val_mse: 0.0128\n",
      "\n",
      "Epoch 00002: val_mae improved from 0.08933 to 0.08810, saving model to data/models/clean_wo_dups_jcw.h5\n",
      "Epoch 3/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0071 - mae: 0.0620 - mse: 0.0071 - val_loss: 0.0083 - val_mae: 0.0669 - val_mse: 0.0083\n",
      "\n",
      "Epoch 00003: val_mae improved from 0.08810 to 0.06691, saving model to data/models/clean_wo_dups_jcw.h5\n",
      "Epoch 4/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0062 - mae: 0.0568 - mse: 0.0062 - val_loss: 0.0072 - val_mae: 0.0616 - val_mse: 0.0072\n",
      "\n",
      "Epoch 00004: val_mae improved from 0.06691 to 0.06157, saving model to data/models/clean_wo_dups_jcw.h5\n",
      "Epoch 5/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 0.0056 - mae: 0.0543 - mse: 0.0056 - val_loss: 0.0070 - val_mae: 0.0608 - val_mse: 0.0070\n",
      "\n",
      "Epoch 00005: val_mae improved from 0.06157 to 0.06085, saving model to data/models/clean_wo_dups_jcw.h5\n",
      "Epoch 6/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0050 - mae: 0.0518 - mse: 0.0050 - val_loss: 0.0069 - val_mae: 0.0602 - val_mse: 0.0069\n",
      "\n",
      "Epoch 00006: val_mae improved from 0.06085 to 0.06023, saving model to data/models/clean_wo_dups_jcw.h5\n",
      "Epoch 7/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0047 - mae: 0.0498 - mse: 0.0047 - val_loss: 0.0075 - val_mae: 0.0629 - val_mse: 0.0075\n",
      "\n",
      "Epoch 00007: val_mae did not improve from 0.06023\n",
      "Epoch 8/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 0.0046 - mae: 0.0493 - mse: 0.0046 - val_loss: 0.0073 - val_mae: 0.0611 - val_mse: 0.0073\n",
      "\n",
      "Epoch 00008: val_mae did not improve from 0.06023\n",
      "Epoch 9/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 0.0042 - mae: 0.0476 - mse: 0.0042 - val_loss: 0.0069 - val_mae: 0.0601 - val_mse: 0.0069\n",
      "\n",
      "Epoch 00009: val_mae improved from 0.06023 to 0.06008, saving model to data/models/clean_wo_dups_jcw.h5\n",
      "Epoch 10/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0036 - mae: 0.0442 - mse: 0.0036 - val_loss: 0.0068 - val_mae: 0.0594 - val_mse: 0.0068\n",
      "\n",
      "Epoch 00010: val_mae improved from 0.06008 to 0.05939, saving model to data/models/clean_wo_dups_jcw.h5\n",
      "Epoch 11/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 0.0036 - mae: 0.0445 - mse: 0.0036 - val_loss: 0.0069 - val_mae: 0.0592 - val_mse: 0.0069\n",
      "\n",
      "Epoch 00011: val_mae improved from 0.05939 to 0.05923, saving model to data/models/clean_wo_dups_jcw.h5\n",
      "Epoch 12/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 0.0033 - mae: 0.0431 - mse: 0.0033 - val_loss: 0.0068 - val_mae: 0.0582 - val_mse: 0.0068\n",
      "\n",
      "Epoch 00012: val_mae improved from 0.05923 to 0.05824, saving model to data/models/clean_wo_dups_jcw.h5\n",
      "Epoch 13/300\n",
      "161/161 [==============================] - 3s 22ms/step - loss: 0.0031 - mae: 0.0417 - mse: 0.0031 - val_loss: 0.0075 - val_mae: 0.0627 - val_mse: 0.0075\n",
      "\n",
      "Epoch 00013: val_mae did not improve from 0.05824\n",
      "Epoch 14/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 0.0030 - mae: 0.0410 - mse: 0.0030 - val_loss: 0.0065 - val_mae: 0.0575 - val_mse: 0.0065\n",
      "\n",
      "Epoch 00014: val_mae improved from 0.05824 to 0.05749, saving model to data/models/clean_wo_dups_jcw.h5\n",
      "Epoch 15/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 0.0026 - mae: 0.0387 - mse: 0.0026 - val_loss: 0.0066 - val_mae: 0.0579 - val_mse: 0.0066\n",
      "\n",
      "Epoch 00015: val_mae did not improve from 0.05749\n",
      "Epoch 16/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 0.0026 - mae: 0.0384 - mse: 0.0026 - val_loss: 0.0063 - val_mae: 0.0563 - val_mse: 0.0063\n",
      "\n",
      "Epoch 00016: val_mae improved from 0.05749 to 0.05626, saving model to data/models/clean_wo_dups_jcw.h5\n",
      "Epoch 17/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 0.0025 - mae: 0.0375 - mse: 0.0025 - val_loss: 0.0069 - val_mae: 0.0589 - val_mse: 0.0069\n",
      "\n",
      "Epoch 00017: val_mae did not improve from 0.05626\n",
      "Epoch 18/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 0.0023 - mae: 0.0361 - mse: 0.0023 - val_loss: 0.0064 - val_mae: 0.0570 - val_mse: 0.0064\n",
      "\n",
      "Epoch 00018: val_mae did not improve from 0.05626\n",
      "Epoch 19/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 0.0023 - mae: 0.0364 - mse: 0.0023 - val_loss: 0.0073 - val_mae: 0.0613 - val_mse: 0.0073\n",
      "\n",
      "Epoch 00019: val_mae did not improve from 0.05626\n",
      "Epoch 20/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 3s 21ms/step - loss: 0.0023 - mae: 0.0363 - mse: 0.0023 - val_loss: 0.0066 - val_mae: 0.0576 - val_mse: 0.0066\n",
      "\n",
      "Epoch 00020: val_mae did not improve from 0.05626\n",
      "Epoch 21/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 0.0025 - mae: 0.0367 - mse: 0.0025 - val_loss: 0.0066 - val_mae: 0.0587 - val_mse: 0.0066\n",
      "\n",
      "Epoch 00021: val_mae did not improve from 0.05626\n",
      "Epoch 22/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 0.0020 - mae: 0.0340 - mse: 0.0020 - val_loss: 0.0061 - val_mae: 0.0549 - val_mse: 0.0061\n",
      "\n",
      "Epoch 00022: val_mae improved from 0.05626 to 0.05491, saving model to data/models/clean_wo_dups_jcw.h5\n",
      "Epoch 23/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0020 - mae: 0.0332 - mse: 0.0020 - val_loss: 0.0066 - val_mae: 0.0578 - val_mse: 0.0066\n",
      "\n",
      "Epoch 00023: val_mae did not improve from 0.05491\n",
      "Epoch 24/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0020 - mae: 0.0338 - mse: 0.0020 - val_loss: 0.0069 - val_mae: 0.0590 - val_mse: 0.0069\n",
      "\n",
      "Epoch 00024: val_mae did not improve from 0.05491\n",
      "Epoch 25/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0020 - mae: 0.0336 - mse: 0.0020 - val_loss: 0.0059 - val_mae: 0.0542 - val_mse: 0.0059\n",
      "\n",
      "Epoch 00025: val_mae improved from 0.05491 to 0.05423, saving model to data/models/clean_wo_dups_jcw.h5\n",
      "Epoch 26/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0019 - mae: 0.0326 - mse: 0.0019 - val_loss: 0.0061 - val_mae: 0.0553 - val_mse: 0.0061\n",
      "\n",
      "Epoch 00026: val_mae did not improve from 0.05423\n",
      "Epoch 27/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0019 - mae: 0.0325 - mse: 0.0019 - val_loss: 0.0072 - val_mae: 0.0600 - val_mse: 0.0072\n",
      "\n",
      "Epoch 00027: val_mae did not improve from 0.05423\n",
      "Epoch 28/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0020 - mae: 0.0333 - mse: 0.0020 - val_loss: 0.0062 - val_mae: 0.0551 - val_mse: 0.0062\n",
      "\n",
      "Epoch 00028: val_mae did not improve from 0.05423\n",
      "Epoch 29/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0019 - mae: 0.0323 - mse: 0.0019 - val_loss: 0.0062 - val_mae: 0.0552 - val_mse: 0.0062\n",
      "\n",
      "Epoch 00029: val_mae did not improve from 0.05423\n",
      "Epoch 30/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0018 - mae: 0.0320 - mse: 0.0018 - val_loss: 0.0060 - val_mae: 0.0540 - val_mse: 0.0060\n",
      "\n",
      "Epoch 00030: val_mae improved from 0.05423 to 0.05395, saving model to data/models/clean_wo_dups_jcw.h5\n",
      "Epoch 31/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 0.0020 - mae: 0.0321 - mse: 0.0020 - val_loss: 0.0057 - val_mae: 0.0530 - val_mse: 0.0057\n",
      "\n",
      "Epoch 00031: val_mae improved from 0.05395 to 0.05302, saving model to data/models/clean_wo_dups_jcw.h5\n",
      "Epoch 32/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 0.0019 - mae: 0.0318 - mse: 0.0019 - val_loss: 0.0062 - val_mae: 0.0559 - val_mse: 0.0062\n",
      "\n",
      "Epoch 00032: val_mae did not improve from 0.05302\n",
      "Epoch 33/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 0.0016 - mae: 0.0301 - mse: 0.0016 - val_loss: 0.0059 - val_mae: 0.0534 - val_mse: 0.0059\n",
      "\n",
      "Epoch 00033: val_mae did not improve from 0.05302\n",
      "Epoch 34/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 0.0016 - mae: 0.0299 - mse: 0.0016 - val_loss: 0.0059 - val_mae: 0.0533 - val_mse: 0.0059\n",
      "\n",
      "Epoch 00034: val_mae did not improve from 0.05302\n",
      "Epoch 35/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 0.0017 - mae: 0.0304 - mse: 0.0017 - val_loss: 0.0060 - val_mae: 0.0547 - val_mse: 0.0060\n",
      "\n",
      "Epoch 00035: val_mae did not improve from 0.05302\n",
      "Epoch 36/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 0.0015 - mae: 0.0296 - mse: 0.0015 - val_loss: 0.0060 - val_mae: 0.0543 - val_mse: 0.0060\n",
      "\n",
      "Epoch 00036: val_mae did not improve from 0.05302\n",
      "Epoch 37/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0017 - mae: 0.0301 - mse: 0.0017 - val_loss: 0.0056 - val_mae: 0.0518 - val_mse: 0.0056\n",
      "\n",
      "Epoch 00037: val_mae improved from 0.05302 to 0.05184, saving model to data/models/clean_wo_dups_jcw.h5\n",
      "Epoch 38/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0015 - mae: 0.0290 - mse: 0.0015 - val_loss: 0.0057 - val_mae: 0.0529 - val_mse: 0.0057\n",
      "\n",
      "Epoch 00038: val_mae did not improve from 0.05184\n",
      "Epoch 39/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 0.0016 - mae: 0.0294 - mse: 0.0016 - val_loss: 0.0058 - val_mae: 0.0529 - val_mse: 0.0058\n",
      "\n",
      "Epoch 00039: val_mae did not improve from 0.05184\n",
      "Epoch 40/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0016 - mae: 0.0292 - mse: 0.0016 - val_loss: 0.0058 - val_mae: 0.0531 - val_mse: 0.0058\n",
      "\n",
      "Epoch 00040: val_mae did not improve from 0.05184\n",
      "Epoch 41/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 0.0014 - mae: 0.0278 - mse: 0.0014 - val_loss: 0.0059 - val_mae: 0.0530 - val_mse: 0.0059\n",
      "\n",
      "Epoch 00041: val_mae did not improve from 0.05184\n",
      "Epoch 42/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0013 - mae: 0.0272 - mse: 0.0013 - val_loss: 0.0055 - val_mae: 0.0513 - val_mse: 0.0055\n",
      "\n",
      "Epoch 00042: val_mae improved from 0.05184 to 0.05125, saving model to data/models/clean_wo_dups_jcw.h5\n",
      "Epoch 43/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 0.0017 - mae: 0.0291 - mse: 0.0017 - val_loss: 0.0053 - val_mae: 0.0502 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00043: val_mae improved from 0.05125 to 0.05016, saving model to data/models/clean_wo_dups_jcw.h5\n",
      "Epoch 44/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 0.0019 - mae: 0.0295 - mse: 0.0019 - val_loss: 0.0054 - val_mae: 0.0510 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00044: val_mae did not improve from 0.05016\n",
      "Epoch 45/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 0.0014 - mae: 0.0276 - mse: 0.0014 - val_loss: 0.0054 - val_mae: 0.0510 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00045: val_mae did not improve from 0.05016\n",
      "Epoch 46/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0016 - mae: 0.0290 - mse: 0.0016 - val_loss: 0.0053 - val_mae: 0.0502 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00046: val_mae did not improve from 0.05016\n",
      "Epoch 47/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 0.0014 - mae: 0.0268 - mse: 0.0014 - val_loss: 0.0060 - val_mae: 0.0548 - val_mse: 0.0060\n",
      "\n",
      "Epoch 00047: val_mae did not improve from 0.05016\n",
      "Epoch 48/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 0.0013 - mae: 0.0269 - mse: 0.0013 - val_loss: 0.0053 - val_mae: 0.0507 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00048: val_mae did not improve from 0.05016\n",
      "Epoch 49/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 0.0012 - mae: 0.0256 - mse: 0.0012 - val_loss: 0.0055 - val_mae: 0.0522 - val_mse: 0.0055\n",
      "\n",
      "Epoch 00049: val_mae did not improve from 0.05016\n",
      "Epoch 50/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 0.0011 - mae: 0.0252 - mse: 0.0011 - val_loss: 0.0054 - val_mae: 0.0508 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00050: val_mae did not improve from 0.05016\n",
      "Epoch 51/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0012 - mae: 0.0252 - mse: 0.0012 - val_loss: 0.0053 - val_mae: 0.0508 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00051: val_mae did not improve from 0.05016\n",
      "Epoch 52/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 0.0011 - mae: 0.0249 - mse: 0.0011 - val_loss: 0.0054 - val_mae: 0.0508 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00052: val_mae did not improve from 0.05016\n",
      "Epoch 53/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 0.0010 - mae: 0.0237 - mse: 0.0010 - val_loss: 0.0056 - val_mae: 0.0517 - val_mse: 0.0056\n",
      "\n",
      "Epoch 00053: val_mae did not improve from 0.05016\n",
      "Epoch 54/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0011 - mae: 0.0247 - mse: 0.0011 - val_loss: 0.0055 - val_mae: 0.0517 - val_mse: 0.0055\n",
      "\n",
      "Epoch 00054: val_mae did not improve from 0.05016\n",
      "Epoch 55/300\n",
      "161/161 [==============================] - 4s 22ms/step - loss: 0.0011 - mae: 0.0249 - mse: 0.0011 - val_loss: 0.0053 - val_mae: 0.0502 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00055: val_mae improved from 0.05016 to 0.05016, saving model to data/models/clean_wo_dups_jcw.h5\n",
      "Epoch 56/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 3s 21ms/step - loss: 0.0010 - mae: 0.0237 - mse: 0.0010 - val_loss: 0.0057 - val_mae: 0.0524 - val_mse: 0.0057\n",
      "\n",
      "Epoch 00056: val_mae did not improve from 0.05016\n",
      "Epoch 57/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 0.0013 - mae: 0.0260 - mse: 0.0013 - val_loss: 0.0052 - val_mae: 0.0494 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00057: val_mae improved from 0.05016 to 0.04937, saving model to data/models/clean_wo_dups_jcw.h5\n",
      "Epoch 58/300\n",
      "161/161 [==============================] - 3s 22ms/step - loss: 0.0011 - mae: 0.0240 - mse: 0.0011 - val_loss: 0.0053 - val_mae: 0.0501 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00058: val_mae did not improve from 0.04937\n",
      "Epoch 59/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0012 - mae: 0.0254 - mse: 0.0012 - val_loss: 0.0059 - val_mae: 0.0526 - val_mse: 0.0059\n",
      "\n",
      "Epoch 00059: val_mae did not improve from 0.04937\n",
      "Epoch 60/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 0.0012 - mae: 0.0249 - mse: 0.0012 - val_loss: 0.0056 - val_mae: 0.0515 - val_mse: 0.0056\n",
      "\n",
      "Epoch 00060: val_mae did not improve from 0.04937\n",
      "Epoch 61/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 0.0011 - mae: 0.0237 - mse: 0.0011 - val_loss: 0.0054 - val_mae: 0.0501 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00061: val_mae did not improve from 0.04937\n",
      "Epoch 62/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 9.6259e-04 - mae: 0.0225 - mse: 9.6259e-04 - val_loss: 0.0051 - val_mae: 0.0487 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00062: val_mae improved from 0.04937 to 0.04872, saving model to data/models/clean_wo_dups_jcw.h5\n",
      "Epoch 63/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 8.3275e-04 - mae: 0.0216 - mse: 8.3275e-04 - val_loss: 0.0053 - val_mae: 0.0505 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00063: val_mae did not improve from 0.04872\n",
      "Epoch 64/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 8.3698e-04 - mae: 0.0216 - mse: 8.3698e-04 - val_loss: 0.0052 - val_mae: 0.0493 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00064: val_mae did not improve from 0.04872\n",
      "Epoch 65/300\n",
      "161/161 [==============================] - 3s 22ms/step - loss: 8.1051e-04 - mae: 0.0213 - mse: 8.1051e-04 - val_loss: 0.0051 - val_mae: 0.0493 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00065: val_mae did not improve from 0.04872\n",
      "Epoch 66/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 9.0782e-04 - mae: 0.0223 - mse: 9.0782e-04 - val_loss: 0.0057 - val_mae: 0.0513 - val_mse: 0.0057\n",
      "\n",
      "Epoch 00066: val_mae did not improve from 0.04872\n",
      "Epoch 67/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0011 - mae: 0.0245 - mse: 0.0011 - val_loss: 0.0052 - val_mae: 0.0492 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00067: val_mae did not improve from 0.04872\n",
      "Epoch 68/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0015 - mae: 0.0236 - mse: 0.0015 - val_loss: 0.0050 - val_mae: 0.0485 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00068: val_mae improved from 0.04872 to 0.04850, saving model to data/models/clean_wo_dups_jcw.h5\n",
      "Epoch 69/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 9.0901e-04 - mae: 0.0217 - mse: 9.0901e-04 - val_loss: 0.0052 - val_mae: 0.0492 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00069: val_mae did not improve from 0.04850\n",
      "Epoch 70/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 8.2678e-04 - mae: 0.0213 - mse: 8.2678e-04 - val_loss: 0.0053 - val_mae: 0.0498 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00070: val_mae did not improve from 0.04850\n",
      "Epoch 71/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 8.9656e-04 - mae: 0.0221 - mse: 8.9656e-04 - val_loss: 0.0052 - val_mae: 0.0493 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00071: val_mae did not improve from 0.04850\n",
      "Epoch 72/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 7.6662e-04 - mae: 0.0208 - mse: 7.6662e-04 - val_loss: 0.0052 - val_mae: 0.0493 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00072: val_mae did not improve from 0.04850\n",
      "Epoch 73/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 9.3333e-04 - mae: 0.0214 - mse: 9.3333e-04 - val_loss: 0.0050 - val_mae: 0.0482 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00073: val_mae improved from 0.04850 to 0.04824, saving model to data/models/clean_wo_dups_jcw.h5\n",
      "Epoch 74/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0010 - mae: 0.0216 - mse: 0.0010 - val_loss: 0.0054 - val_mae: 0.0509 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00074: val_mae did not improve from 0.04824\n",
      "Epoch 75/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 0.0012 - mae: 0.0239 - mse: 0.0012 - val_loss: 0.0050 - val_mae: 0.0484 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00075: val_mae did not improve from 0.04824\n",
      "Epoch 76/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 8.1181e-04 - mae: 0.0212 - mse: 8.1181e-04 - val_loss: 0.0053 - val_mae: 0.0495 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00076: val_mae did not improve from 0.04824\n",
      "Epoch 77/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 7.9243e-04 - mae: 0.0203 - mse: 7.9243e-04 - val_loss: 0.0048 - val_mae: 0.0472 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00077: val_mae improved from 0.04824 to 0.04724, saving model to data/models/clean_wo_dups_jcw.h5\n",
      "Epoch 78/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 6.6700e-04 - mae: 0.0194 - mse: 6.6700e-04 - val_loss: 0.0053 - val_mae: 0.0501 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00078: val_mae did not improve from 0.04724\n",
      "Epoch 79/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 8.1816e-04 - mae: 0.0211 - mse: 8.1816e-04 - val_loss: 0.0051 - val_mae: 0.0490 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00079: val_mae did not improve from 0.04724\n",
      "Epoch 80/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 7.6020e-04 - mae: 0.0205 - mse: 7.6020e-04 - val_loss: 0.0049 - val_mae: 0.0476 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00080: val_mae did not improve from 0.04724\n",
      "Epoch 81/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 7.4001e-04 - mae: 0.0200 - mse: 7.4001e-04 - val_loss: 0.0049 - val_mae: 0.0474 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00081: val_mae did not improve from 0.04724\n",
      "Epoch 82/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 6.8596e-04 - mae: 0.0193 - mse: 6.8596e-04 - val_loss: 0.0052 - val_mae: 0.0491 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00082: val_mae did not improve from 0.04724\n",
      "Epoch 83/300\n",
      "161/161 [==============================] - 3s 22ms/step - loss: 7.0391e-04 - mae: 0.0200 - mse: 7.0391e-04 - val_loss: 0.0055 - val_mae: 0.0512 - val_mse: 0.0055\n",
      "\n",
      "Epoch 00083: val_mae did not improve from 0.04724\n",
      "Epoch 84/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 9.2218e-04 - mae: 0.0221 - mse: 9.2218e-04 - val_loss: 0.0049 - val_mae: 0.0476 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00084: val_mae did not improve from 0.04724\n",
      "Epoch 85/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 7.1986e-04 - mae: 0.0199 - mse: 7.1986e-04 - val_loss: 0.0051 - val_mae: 0.0487 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00085: val_mae did not improve from 0.04724\n",
      "Epoch 86/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 7.2047e-04 - mae: 0.0199 - mse: 7.2047e-04 - val_loss: 0.0052 - val_mae: 0.0498 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00086: val_mae did not improve from 0.04724\n",
      "Epoch 87/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 8.9201e-04 - mae: 0.0220 - mse: 8.9201e-04 - val_loss: 0.0051 - val_mae: 0.0486 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00087: val_mae did not improve from 0.04724\n",
      "Epoch 88/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 8.2178e-04 - mae: 0.0209 - mse: 8.2178e-04 - val_loss: 0.0048 - val_mae: 0.0476 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00088: val_mae did not improve from 0.04724\n",
      "Epoch 89/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 7.5884e-04 - mae: 0.0199 - mse: 7.5884e-04 - val_loss: 0.0051 - val_mae: 0.0487 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00089: val_mae did not improve from 0.04724\n",
      "Epoch 90/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 7.5784e-04 - mae: 0.0197 - mse: 7.5784e-04 - val_loss: 0.0051 - val_mae: 0.0485 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00090: val_mae did not improve from 0.04724\n",
      "Epoch 91/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 3s 21ms/step - loss: 7.8796e-04 - mae: 0.0201 - mse: 7.8796e-04 - val_loss: 0.0048 - val_mae: 0.0474 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00091: val_mae did not improve from 0.04724\n",
      "Epoch 92/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 7.9266e-04 - mae: 0.0196 - mse: 7.9266e-04 - val_loss: 0.0050 - val_mae: 0.0481 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00092: val_mae did not improve from 0.04724\n",
      "Epoch 93/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 6.2489e-04 - mae: 0.0186 - mse: 6.2489e-04 - val_loss: 0.0049 - val_mae: 0.0475 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00093: val_mae did not improve from 0.04724\n",
      "Epoch 94/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 6.8456e-04 - mae: 0.0191 - mse: 6.8456e-04 - val_loss: 0.0049 - val_mae: 0.0476 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00094: val_mae did not improve from 0.04724\n",
      "Epoch 95/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 8.5837e-04 - mae: 0.0196 - mse: 8.5837e-04 - val_loss: 0.0050 - val_mae: 0.0478 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00095: val_mae did not improve from 0.04724\n",
      "Epoch 96/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 6.4324e-04 - mae: 0.0180 - mse: 6.4324e-04 - val_loss: 0.0050 - val_mae: 0.0478 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00096: val_mae did not improve from 0.04724\n",
      "Epoch 97/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 6.8036e-04 - mae: 0.0183 - mse: 6.8036e-04 - val_loss: 0.0048 - val_mae: 0.0467 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00097: val_mae improved from 0.04724 to 0.04668, saving model to data/models/clean_wo_dups_jcw.h5\n",
      "Epoch 98/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 6.1865e-04 - mae: 0.0180 - mse: 6.1865e-04 - val_loss: 0.0049 - val_mae: 0.0473 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00098: val_mae did not improve from 0.04668\n",
      "Epoch 99/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 5.9830e-04 - mae: 0.0178 - mse: 5.9830e-04 - val_loss: 0.0051 - val_mae: 0.0488 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00099: val_mae did not improve from 0.04668\n",
      "Epoch 100/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 8.3225e-04 - mae: 0.0197 - mse: 8.3225e-04 - val_loss: 0.0051 - val_mae: 0.0483 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00100: val_mae did not improve from 0.04668\n",
      "Epoch 101/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 7.3847e-04 - mae: 0.0186 - mse: 7.3847e-04 - val_loss: 0.0050 - val_mae: 0.0483 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00101: val_mae did not improve from 0.04668\n",
      "Epoch 102/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 8.2903e-04 - mae: 0.0194 - mse: 8.2903e-04 - val_loss: 0.0050 - val_mae: 0.0480 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00102: val_mae did not improve from 0.04668\n",
      "Epoch 103/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 5.8249e-04 - mae: 0.0178 - mse: 5.8249e-04 - val_loss: 0.0048 - val_mae: 0.0470 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00103: val_mae did not improve from 0.04668\n",
      "Epoch 104/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 6.6077e-04 - mae: 0.0185 - mse: 6.6077e-04 - val_loss: 0.0051 - val_mae: 0.0486 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00104: val_mae did not improve from 0.04668\n",
      "Epoch 105/300\n",
      "161/161 [==============================] - 4s 23ms/step - loss: 8.8690e-04 - mae: 0.0200 - mse: 8.8690e-04 - val_loss: 0.0047 - val_mae: 0.0463 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00105: val_mae improved from 0.04668 to 0.04629, saving model to data/models/clean_wo_dups_jcw.h5\n",
      "Epoch 106/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 6.2270e-04 - mae: 0.0177 - mse: 6.2270e-04 - val_loss: 0.0048 - val_mae: 0.0468 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00106: val_mae did not improve from 0.04629\n",
      "Epoch 107/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 4.6985e-04 - mae: 0.0164 - mse: 4.6985e-04 - val_loss: 0.0048 - val_mae: 0.0467 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00107: val_mae did not improve from 0.04629\n",
      "Epoch 108/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 5.4562e-04 - mae: 0.0168 - mse: 5.4562e-04 - val_loss: 0.0048 - val_mae: 0.0470 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00108: val_mae did not improve from 0.04629\n",
      "Epoch 109/300\n",
      "161/161 [==============================] - 4s 22ms/step - loss: 6.4709e-04 - mae: 0.0171 - mse: 6.4709e-04 - val_loss: 0.0048 - val_mae: 0.0468 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00109: val_mae did not improve from 0.04629\n",
      "Epoch 110/300\n",
      "161/161 [==============================] - 4s 24ms/step - loss: 4.7058e-04 - mae: 0.0160 - mse: 4.7058e-04 - val_loss: 0.0047 - val_mae: 0.0463 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00110: val_mae did not improve from 0.04629\n",
      "Epoch 111/300\n",
      "161/161 [==============================] - 4s 25ms/step - loss: 5.1117e-04 - mae: 0.0166 - mse: 5.1117e-04 - val_loss: 0.0049 - val_mae: 0.0475 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00111: val_mae did not improve from 0.04629\n",
      "Epoch 112/300\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 5.7208e-04 - mae: 0.0169 - mse: 5.7208e-04 - val_loss: 0.0048 - val_mae: 0.0466 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00112: val_mae did not improve from 0.04629\n",
      "Epoch 113/300\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 5.5896e-04 - mae: 0.0166 - mse: 5.5896e-04 - val_loss: 0.0048 - val_mae: 0.0465 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00113: val_mae did not improve from 0.04629\n",
      "Epoch 114/300\n",
      "161/161 [==============================] - 4s 25ms/step - loss: 4.9615e-04 - mae: 0.0165 - mse: 4.9615e-04 - val_loss: 0.0048 - val_mae: 0.0470 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00114: val_mae did not improve from 0.04629\n",
      "Epoch 115/300\n",
      "161/161 [==============================] - 4s 23ms/step - loss: 6.7867e-04 - mae: 0.0181 - mse: 6.7867e-04 - val_loss: 0.0050 - val_mae: 0.0476 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00115: val_mae did not improve from 0.04629\n",
      "Epoch 116/300\n",
      "161/161 [==============================] - 4s 23ms/step - loss: 7.0619e-04 - mae: 0.0175 - mse: 7.0619e-04 - val_loss: 0.0047 - val_mae: 0.0461 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00116: val_mae improved from 0.04629 to 0.04610, saving model to data/models/clean_wo_dups_jcw.h5\n",
      "Epoch 117/300\n",
      "161/161 [==============================] - 4s 24ms/step - loss: 4.5664e-04 - mae: 0.0160 - mse: 4.5664e-04 - val_loss: 0.0048 - val_mae: 0.0471 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00117: val_mae did not improve from 0.04610\n",
      "Epoch 118/300\n",
      "161/161 [==============================] - 4s 26ms/step - loss: 4.4087e-04 - mae: 0.0159 - mse: 4.4087e-04 - val_loss: 0.0048 - val_mae: 0.0469 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00118: val_mae did not improve from 0.04610\n",
      "Epoch 119/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 4.4977e-04 - mae: 0.0156 - mse: 4.4977e-04 - val_loss: 0.0047 - val_mae: 0.0460 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00119: val_mae improved from 0.04610 to 0.04599, saving model to data/models/clean_wo_dups_jcw.h5\n",
      "Epoch 120/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 4.8625e-04 - mae: 0.0160 - mse: 4.8625e-04 - val_loss: 0.0050 - val_mae: 0.0472 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00120: val_mae did not improve from 0.04599\n",
      "Epoch 121/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 6.4919e-04 - mae: 0.0176 - mse: 6.4919e-04 - val_loss: 0.0050 - val_mae: 0.0476 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00121: val_mae did not improve from 0.04599\n",
      "Epoch 122/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 4.9529e-04 - mae: 0.0162 - mse: 4.9529e-04 - val_loss: 0.0048 - val_mae: 0.0469 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00122: val_mae did not improve from 0.04599\n",
      "Epoch 123/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 4.8547e-04 - mae: 0.0162 - mse: 4.8547e-04 - val_loss: 0.0048 - val_mae: 0.0467 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00123: val_mae did not improve from 0.04599\n",
      "Epoch 124/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 7.1187e-04 - mae: 0.0173 - mse: 7.1187e-04 - val_loss: 0.0048 - val_mae: 0.0465 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00124: val_mae did not improve from 0.04599\n",
      "Epoch 125/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 6.1693e-04 - mae: 0.0170 - mse: 6.1693e-04 - val_loss: 0.0050 - val_mae: 0.0481 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00125: val_mae did not improve from 0.04599\n",
      "Epoch 126/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 3s 20ms/step - loss: 4.4270e-04 - mae: 0.0154 - mse: 4.4270e-04 - val_loss: 0.0049 - val_mae: 0.0469 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00126: val_mae did not improve from 0.04599\n",
      "Epoch 127/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 4.6501e-04 - mae: 0.0153 - mse: 4.6501e-04 - val_loss: 0.0047 - val_mae: 0.0463 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00127: val_mae did not improve from 0.04599\n",
      "Epoch 128/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 4.6609e-04 - mae: 0.0157 - mse: 4.6609e-04 - val_loss: 0.0047 - val_mae: 0.0461 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00128: val_mae did not improve from 0.04599\n",
      "Epoch 129/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 3.9453e-04 - mae: 0.0145 - mse: 3.9453e-04 - val_loss: 0.0049 - val_mae: 0.0472 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00129: val_mae did not improve from 0.04599\n",
      "Epoch 130/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 4.3796e-04 - mae: 0.0154 - mse: 4.3796e-04 - val_loss: 0.0048 - val_mae: 0.0471 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00130: val_mae did not improve from 0.04599\n",
      "Epoch 131/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 3.7864e-04 - mae: 0.0145 - mse: 3.7864e-04 - val_loss: 0.0047 - val_mae: 0.0460 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00131: val_mae did not improve from 0.04599\n",
      "Epoch 132/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 3.9139e-04 - mae: 0.0147 - mse: 3.9139e-04 - val_loss: 0.0049 - val_mae: 0.0472 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00132: val_mae did not improve from 0.04599\n",
      "Epoch 133/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 4.1437e-04 - mae: 0.0149 - mse: 4.1437e-04 - val_loss: 0.0047 - val_mae: 0.0461 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00133: val_mae did not improve from 0.04599\n",
      "Epoch 134/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 5.0569e-04 - mae: 0.0160 - mse: 5.0569e-04 - val_loss: 0.0049 - val_mae: 0.0474 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00134: val_mae did not improve from 0.04599\n",
      "Epoch 135/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 4.5047e-04 - mae: 0.0155 - mse: 4.5047e-04 - val_loss: 0.0047 - val_mae: 0.0461 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00135: val_mae did not improve from 0.04599\n",
      "Epoch 136/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 4.5612e-04 - mae: 0.0155 - mse: 4.5612e-04 - val_loss: 0.0048 - val_mae: 0.0468 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00136: val_mae did not improve from 0.04599\n",
      "Epoch 137/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 4.2887e-04 - mae: 0.0152 - mse: 4.2887e-04 - val_loss: 0.0046 - val_mae: 0.0454 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00137: val_mae improved from 0.04599 to 0.04543, saving model to data/models/clean_wo_dups_jcw.h5\n",
      "Epoch 138/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 4.8314e-04 - mae: 0.0158 - mse: 4.8314e-04 - val_loss: 0.0048 - val_mae: 0.0465 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00138: val_mae did not improve from 0.04543\n",
      "Epoch 139/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 5.3519e-04 - mae: 0.0157 - mse: 5.3519e-04 - val_loss: 0.0048 - val_mae: 0.0463 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00139: val_mae did not improve from 0.04543\n",
      "Epoch 140/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 3.9234e-04 - mae: 0.0145 - mse: 3.9234e-04 - val_loss: 0.0048 - val_mae: 0.0469 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00140: val_mae did not improve from 0.04543\n",
      "Epoch 141/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 3.7192e-04 - mae: 0.0144 - mse: 3.7192e-04 - val_loss: 0.0048 - val_mae: 0.0467 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00141: val_mae did not improve from 0.04543\n",
      "Epoch 142/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 3.6051e-04 - mae: 0.0139 - mse: 3.6051e-04 - val_loss: 0.0049 - val_mae: 0.0475 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00142: val_mae did not improve from 0.04543\n",
      "Epoch 143/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 3.7851e-04 - mae: 0.0146 - mse: 3.7851e-04 - val_loss: 0.0047 - val_mae: 0.0458 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00143: val_mae did not improve from 0.04543\n",
      "Epoch 144/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 4.2697e-04 - mae: 0.0146 - mse: 4.2697e-04 - val_loss: 0.0048 - val_mae: 0.0464 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00144: val_mae did not improve from 0.04543\n",
      "Epoch 145/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 3.5600e-04 - mae: 0.0141 - mse: 3.5600e-04 - val_loss: 0.0049 - val_mae: 0.0469 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00145: val_mae did not improve from 0.04543\n",
      "Epoch 146/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 3.5237e-04 - mae: 0.0141 - mse: 3.5237e-04 - val_loss: 0.0049 - val_mae: 0.0473 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00146: val_mae did not improve from 0.04543\n",
      "Epoch 147/300\n",
      "161/161 [==============================] - 4s 23ms/step - loss: 3.8925e-04 - mae: 0.0147 - mse: 3.8925e-04 - val_loss: 0.0048 - val_mae: 0.0469 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00147: val_mae did not improve from 0.04543\n",
      "Epoch 148/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 6.6097e-04 - mae: 0.0153 - mse: 6.6097e-04 - val_loss: 0.0046 - val_mae: 0.0456 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00148: val_mae did not improve from 0.04543\n",
      "Epoch 149/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 3.8964e-04 - mae: 0.0142 - mse: 3.8964e-04 - val_loss: 0.0045 - val_mae: 0.0449 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00149: val_mae improved from 0.04543 to 0.04492, saving model to data/models/clean_wo_dups_jcw.h5\n",
      "Epoch 150/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 4.2258e-04 - mae: 0.0145 - mse: 4.2258e-04 - val_loss: 0.0047 - val_mae: 0.0459 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00150: val_mae did not improve from 0.04492\n",
      "Epoch 151/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 4.1132e-04 - mae: 0.0142 - mse: 4.1132e-04 - val_loss: 0.0048 - val_mae: 0.0463 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00151: val_mae did not improve from 0.04492\n",
      "Epoch 152/300\n",
      "161/161 [==============================] - 3s 22ms/step - loss: 3.4095e-04 - mae: 0.0136 - mse: 3.4095e-04 - val_loss: 0.0048 - val_mae: 0.0465 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00152: val_mae did not improve from 0.04492\n",
      "Epoch 153/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 4.1604e-04 - mae: 0.0143 - mse: 4.1604e-04 - val_loss: 0.0047 - val_mae: 0.0459 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00153: val_mae did not improve from 0.04492\n",
      "Epoch 154/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 3.6611e-04 - mae: 0.0139 - mse: 3.6611e-04 - val_loss: 0.0048 - val_mae: 0.0466 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00154: val_mae did not improve from 0.04492\n",
      "Epoch 155/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 4.4741e-04 - mae: 0.0143 - mse: 4.4741e-04 - val_loss: 0.0048 - val_mae: 0.0464 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00155: val_mae did not improve from 0.04492\n",
      "Epoch 156/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 3.3295e-04 - mae: 0.0135 - mse: 3.3295e-04 - val_loss: 0.0047 - val_mae: 0.0463 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00156: val_mae did not improve from 0.04492\n",
      "Epoch 157/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 3.4824e-04 - mae: 0.0136 - mse: 3.4824e-04 - val_loss: 0.0046 - val_mae: 0.0452 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00157: val_mae did not improve from 0.04492\n",
      "Epoch 158/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 3.2568e-04 - mae: 0.0134 - mse: 3.2568e-04 - val_loss: 0.0045 - val_mae: 0.0450 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00158: val_mae did not improve from 0.04492\n",
      "Epoch 159/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 3.6766e-04 - mae: 0.0139 - mse: 3.6766e-04 - val_loss: 0.0048 - val_mae: 0.0467 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00159: val_mae did not improve from 0.04492\n",
      "Epoch 160/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 3.8752e-04 - mae: 0.0142 - mse: 3.8752e-04 - val_loss: 0.0047 - val_mae: 0.0460 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00160: val_mae did not improve from 0.04492\n",
      "Epoch 161/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 3.8666e-04 - mae: 0.0138 - mse: 3.8666e-04 - val_loss: 0.0046 - val_mae: 0.0457 - val_mse: 0.0046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00161: val_mae did not improve from 0.04492\n",
      "Epoch 162/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 3.8975e-04 - mae: 0.0142 - mse: 3.8975e-04 - val_loss: 0.0048 - val_mae: 0.0468 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00162: val_mae did not improve from 0.04492\n",
      "Epoch 163/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 3.5757e-04 - mae: 0.0138 - mse: 3.5757e-04 - val_loss: 0.0047 - val_mae: 0.0459 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00163: val_mae did not improve from 0.04492\n",
      "Epoch 164/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 3.4454e-04 - mae: 0.0137 - mse: 3.4454e-04 - val_loss: 0.0046 - val_mae: 0.0452 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00164: val_mae did not improve from 0.04492\n",
      "Epoch 165/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 3.8609e-04 - mae: 0.0142 - mse: 3.8609e-04 - val_loss: 0.0046 - val_mae: 0.0455 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00165: val_mae did not improve from 0.04492\n",
      "Epoch 166/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 3.4657e-04 - mae: 0.0135 - mse: 3.4657e-04 - val_loss: 0.0046 - val_mae: 0.0455 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00166: val_mae did not improve from 0.04492\n",
      "Epoch 167/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 2.9798e-04 - mae: 0.0129 - mse: 2.9798e-04 - val_loss: 0.0047 - val_mae: 0.0462 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00167: val_mae did not improve from 0.04492\n",
      "Epoch 168/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 2.9715e-04 - mae: 0.0127 - mse: 2.9715e-04 - val_loss: 0.0047 - val_mae: 0.0458 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00168: val_mae did not improve from 0.04492\n",
      "Epoch 169/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 2.9731e-04 - mae: 0.0127 - mse: 2.9731e-04 - val_loss: 0.0047 - val_mae: 0.0459 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00169: val_mae did not improve from 0.04492\n",
      "Epoch 170/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 3.0075e-04 - mae: 0.0128 - mse: 3.0075e-04 - val_loss: 0.0048 - val_mae: 0.0464 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00170: val_mae did not improve from 0.04492\n",
      "Epoch 171/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 3.1593e-04 - mae: 0.0131 - mse: 3.1593e-04 - val_loss: 0.0046 - val_mae: 0.0456 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00171: val_mae did not improve from 0.04492\n",
      "Epoch 172/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 3.6767e-04 - mae: 0.0135 - mse: 3.6767e-04 - val_loss: 0.0046 - val_mae: 0.0457 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00172: val_mae did not improve from 0.04492\n",
      "Epoch 173/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 3.4619e-04 - mae: 0.0136 - mse: 3.4619e-04 - val_loss: 0.0049 - val_mae: 0.0474 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00173: val_mae did not improve from 0.04492\n",
      "Epoch 174/300\n",
      "161/161 [==============================] - 3s 22ms/step - loss: 3.1391e-04 - mae: 0.0132 - mse: 3.1391e-04 - val_loss: 0.0046 - val_mae: 0.0456 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00174: val_mae did not improve from 0.04492\n",
      "Epoch 175/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 2.8454e-04 - mae: 0.0127 - mse: 2.8454e-04 - val_loss: 0.0046 - val_mae: 0.0454 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00175: val_mae did not improve from 0.04492\n",
      "Epoch 176/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 2.8092e-04 - mae: 0.0125 - mse: 2.8092e-04 - val_loss: 0.0046 - val_mae: 0.0454 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00176: val_mae did not improve from 0.04492\n",
      "Epoch 177/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 2.6645e-04 - mae: 0.0121 - mse: 2.6645e-04 - val_loss: 0.0047 - val_mae: 0.0462 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00177: val_mae did not improve from 0.04492\n",
      "Epoch 178/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 3.1024e-04 - mae: 0.0129 - mse: 3.1024e-04 - val_loss: 0.0046 - val_mae: 0.0458 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00178: val_mae did not improve from 0.04492\n",
      "Epoch 179/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 3.5808e-04 - mae: 0.0133 - mse: 3.5808e-04 - val_loss: 0.0046 - val_mae: 0.0454 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00179: val_mae did not improve from 0.04492\n",
      "Epoch 180/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 3.1486e-04 - mae: 0.0130 - mse: 3.1486e-04 - val_loss: 0.0048 - val_mae: 0.0469 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00180: val_mae did not improve from 0.04492\n",
      "Epoch 181/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 3.0169e-04 - mae: 0.0129 - mse: 3.0169e-04 - val_loss: 0.0045 - val_mae: 0.0448 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00181: val_mae improved from 0.04492 to 0.04483, saving model to data/models/clean_wo_dups_jcw.h5\n",
      "Epoch 182/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 2.9450e-04 - mae: 0.0125 - mse: 2.9450e-04 - val_loss: 0.0047 - val_mae: 0.0460 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00182: val_mae did not improve from 0.04483\n",
      "Epoch 183/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 3.6618e-04 - mae: 0.0129 - mse: 3.6618e-04 - val_loss: 0.0046 - val_mae: 0.0452 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00183: val_mae did not improve from 0.04483\n",
      "Epoch 184/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 2.9685e-04 - mae: 0.0125 - mse: 2.9685e-04 - val_loss: 0.0048 - val_mae: 0.0464 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00184: val_mae did not improve from 0.04483\n",
      "Epoch 185/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 3.3716e-04 - mae: 0.0127 - mse: 3.3716e-04 - val_loss: 0.0048 - val_mae: 0.0459 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00185: val_mae did not improve from 0.04483\n",
      "Epoch 186/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 3.2095e-04 - mae: 0.0126 - mse: 3.2095e-04 - val_loss: 0.0047 - val_mae: 0.0456 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00186: val_mae did not improve from 0.04483\n",
      "Epoch 187/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 2.8208e-04 - mae: 0.0124 - mse: 2.8208e-04 - val_loss: 0.0047 - val_mae: 0.0457 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00187: val_mae did not improve from 0.04483\n",
      "Epoch 188/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 3.4936e-04 - mae: 0.0129 - mse: 3.4936e-04 - val_loss: 0.0048 - val_mae: 0.0465 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00188: val_mae did not improve from 0.04483\n",
      "Epoch 189/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 2.6908e-04 - mae: 0.0121 - mse: 2.6908e-04 - val_loss: 0.0046 - val_mae: 0.0455 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00189: val_mae did not improve from 0.04483\n",
      "Epoch 190/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 2.5548e-04 - mae: 0.0118 - mse: 2.5548e-04 - val_loss: 0.0049 - val_mae: 0.0469 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00190: val_mae did not improve from 0.04483\n",
      "Epoch 191/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 3.2231e-04 - mae: 0.0130 - mse: 3.2231e-04 - val_loss: 0.0047 - val_mae: 0.0456 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00191: val_mae did not improve from 0.04483\n",
      "Epoch 192/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 3.5808e-04 - mae: 0.0128 - mse: 3.5808e-04 - val_loss: 0.0047 - val_mae: 0.0457 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00192: val_mae did not improve from 0.04483\n",
      "Epoch 193/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 2.6827e-04 - mae: 0.0121 - mse: 2.6827e-04 - val_loss: 0.0047 - val_mae: 0.0454 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00193: val_mae did not improve from 0.04483\n",
      "Epoch 194/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 2.5744e-04 - mae: 0.0119 - mse: 2.5744e-04 - val_loss: 0.0047 - val_mae: 0.0458 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00194: val_mae did not improve from 0.04483\n",
      "Epoch 195/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 2.8411e-04 - mae: 0.0123 - mse: 2.8411e-04 - val_loss: 0.0046 - val_mae: 0.0453 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00195: val_mae did not improve from 0.04483\n",
      "Epoch 196/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 2.4047e-04 - mae: 0.0115 - mse: 2.4047e-04 - val_loss: 0.0047 - val_mae: 0.0455 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00196: val_mae did not improve from 0.04483\n",
      "Epoch 197/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 2.5852e-04 - mae: 0.0119 - mse: 2.5852e-04 - val_loss: 0.0046 - val_mae: 0.0452 - val_mse: 0.0046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00197: val_mae did not improve from 0.04483\n",
      "Epoch 198/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 2.5093e-04 - mae: 0.0118 - mse: 2.5093e-04 - val_loss: 0.0048 - val_mae: 0.0464 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00198: val_mae did not improve from 0.04483\n",
      "Epoch 199/300\n",
      "161/161 [==============================] - 3s 19ms/step - loss: 3.0152e-04 - mae: 0.0127 - mse: 3.0152e-04 - val_loss: 0.0046 - val_mae: 0.0453 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00199: val_mae did not improve from 0.04483\n",
      "Epoch 200/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 3.2223e-04 - mae: 0.0129 - mse: 3.2223e-04 - val_loss: 0.0046 - val_mae: 0.0455 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00200: val_mae did not improve from 0.04483\n",
      "Epoch 201/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 2.9252e-04 - mae: 0.0124 - mse: 2.9252e-04 - val_loss: 0.0047 - val_mae: 0.0462 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00201: val_mae did not improve from 0.04483\n",
      "Epoch 202/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 2.7345e-04 - mae: 0.0121 - mse: 2.7345e-04 - val_loss: 0.0045 - val_mae: 0.0447 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00202: val_mae improved from 0.04483 to 0.04468, saving model to data/models/clean_wo_dups_jcw.h5\n",
      "Epoch 203/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 2.4719e-04 - mae: 0.0116 - mse: 2.4719e-04 - val_loss: 0.0047 - val_mae: 0.0457 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00203: val_mae did not improve from 0.04468\n",
      "Epoch 204/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 2.7684e-04 - mae: 0.0122 - mse: 2.7684e-04 - val_loss: 0.0046 - val_mae: 0.0454 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00204: val_mae did not improve from 0.04468\n",
      "Epoch 205/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 2.4283e-04 - mae: 0.0114 - mse: 2.4283e-04 - val_loss: 0.0049 - val_mae: 0.0472 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00205: val_mae did not improve from 0.04468\n",
      "Epoch 206/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 2.7380e-04 - mae: 0.0121 - mse: 2.7380e-04 - val_loss: 0.0046 - val_mae: 0.0455 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00206: val_mae did not improve from 0.04468\n",
      "Epoch 207/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 3.4810e-04 - mae: 0.0126 - mse: 3.4810e-04 - val_loss: 0.0046 - val_mae: 0.0451 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00207: val_mae did not improve from 0.04468\n",
      "Epoch 208/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 2.6378e-04 - mae: 0.0118 - mse: 2.6378e-04 - val_loss: 0.0045 - val_mae: 0.0446 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00208: val_mae improved from 0.04468 to 0.04463, saving model to data/models/clean_wo_dups_jcw.h5\n",
      "Epoch 209/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 2.4481e-04 - mae: 0.0116 - mse: 2.4481e-04 - val_loss: 0.0046 - val_mae: 0.0455 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00209: val_mae did not improve from 0.04463\n",
      "Epoch 210/300\n",
      "161/161 [==============================] - 4s 22ms/step - loss: 2.6159e-04 - mae: 0.0120 - mse: 2.6159e-04 - val_loss: 0.0048 - val_mae: 0.0461 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00210: val_mae did not improve from 0.04463\n",
      "Epoch 211/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 2.4775e-04 - mae: 0.0117 - mse: 2.4775e-04 - val_loss: 0.0046 - val_mae: 0.0449 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00211: val_mae did not improve from 0.04463\n",
      "Epoch 212/300\n",
      "161/161 [==============================] - 4s 22ms/step - loss: 2.5085e-04 - mae: 0.0115 - mse: 2.5085e-04 - val_loss: 0.0047 - val_mae: 0.0458 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00212: val_mae did not improve from 0.04463\n",
      "Epoch 213/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 2.4394e-04 - mae: 0.0114 - mse: 2.4394e-04 - val_loss: 0.0046 - val_mae: 0.0452 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00213: val_mae did not improve from 0.04463\n",
      "Epoch 214/300\n",
      "161/161 [==============================] - 4s 22ms/step - loss: 2.3426e-04 - mae: 0.0113 - mse: 2.3426e-04 - val_loss: 0.0047 - val_mae: 0.0458 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00214: val_mae did not improve from 0.04463\n",
      "Epoch 215/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 2.8391e-04 - mae: 0.0120 - mse: 2.8391e-04 - val_loss: 0.0048 - val_mae: 0.0464 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00215: val_mae did not improve from 0.04463\n",
      "Epoch 216/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 2.3763e-04 - mae: 0.0113 - mse: 2.3763e-04 - val_loss: 0.0046 - val_mae: 0.0450 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00216: val_mae did not improve from 0.04463\n",
      "Epoch 217/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 2.5081e-04 - mae: 0.0115 - mse: 2.5081e-04 - val_loss: 0.0046 - val_mae: 0.0454 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00217: val_mae did not improve from 0.04463\n",
      "Epoch 218/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 2.7222e-04 - mae: 0.0118 - mse: 2.7222e-04 - val_loss: 0.0048 - val_mae: 0.0467 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00218: val_mae did not improve from 0.04463\n",
      "Epoch 219/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 3.1327e-04 - mae: 0.0123 - mse: 3.1327e-04 - val_loss: 0.0046 - val_mae: 0.0451 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00219: val_mae did not improve from 0.04463\n",
      "Epoch 220/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 2.6700e-04 - mae: 0.0117 - mse: 2.6700e-04 - val_loss: 0.0047 - val_mae: 0.0458 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00220: val_mae did not improve from 0.04463\n",
      "Epoch 221/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 2.8163e-04 - mae: 0.0118 - mse: 2.8163e-04 - val_loss: 0.0047 - val_mae: 0.0457 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00221: val_mae did not improve from 0.04463\n",
      "Epoch 222/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 2.3600e-04 - mae: 0.0114 - mse: 2.3600e-04 - val_loss: 0.0047 - val_mae: 0.0455 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00222: val_mae did not improve from 0.04463\n",
      "Epoch 223/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 2.3040e-04 - mae: 0.0110 - mse: 2.3040e-04 - val_loss: 0.0046 - val_mae: 0.0453 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00223: val_mae did not improve from 0.04463\n",
      "Epoch 224/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 2.2753e-04 - mae: 0.0111 - mse: 2.2753e-04 - val_loss: 0.0046 - val_mae: 0.0451 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00224: val_mae did not improve from 0.04463\n",
      "Epoch 225/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 2.3325e-04 - mae: 0.0111 - mse: 2.3325e-04 - val_loss: 0.0046 - val_mae: 0.0449 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00225: val_mae did not improve from 0.04463\n",
      "Epoch 226/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 2.8613e-04 - mae: 0.0117 - mse: 2.8613e-04 - val_loss: 0.0045 - val_mae: 0.0448 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00226: val_mae did not improve from 0.04463\n",
      "Epoch 227/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 2.5064e-04 - mae: 0.0112 - mse: 2.5064e-04 - val_loss: 0.0046 - val_mae: 0.0456 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00227: val_mae did not improve from 0.04463\n",
      "Epoch 228/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 2.1532e-04 - mae: 0.0109 - mse: 2.1532e-04 - val_loss: 0.0045 - val_mae: 0.0447 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00228: val_mae did not improve from 0.04463\n",
      "Epoch 229/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 2.0934e-04 - mae: 0.0108 - mse: 2.0934e-04 - val_loss: 0.0046 - val_mae: 0.0454 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00229: val_mae did not improve from 0.04463\n",
      "Epoch 230/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 2.2136e-04 - mae: 0.0109 - mse: 2.2136e-04 - val_loss: 0.0046 - val_mae: 0.0449 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00230: val_mae did not improve from 0.04463\n",
      "Epoch 231/300\n",
      "161/161 [==============================] - 3s 20ms/step - loss: 2.2956e-04 - mae: 0.0109 - mse: 2.2956e-04 - val_loss: 0.0046 - val_mae: 0.0455 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00231: val_mae did not improve from 0.04463\n",
      "Epoch 232/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 2.5977e-04 - mae: 0.0115 - mse: 2.5977e-04 - val_loss: 0.0047 - val_mae: 0.0461 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00232: val_mae did not improve from 0.04463\n",
      "Epoch 233/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 3s 21ms/step - loss: 2.3768e-04 - mae: 0.0114 - mse: 2.3768e-04 - val_loss: 0.0047 - val_mae: 0.0461 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00233: val_mae did not improve from 0.04463\n",
      "Epoch 234/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 2.4057e-04 - mae: 0.0115 - mse: 2.4057e-04 - val_loss: 0.0045 - val_mae: 0.0450 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00234: val_mae did not improve from 0.04463\n",
      "Epoch 235/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 2.3497e-04 - mae: 0.0113 - mse: 2.3497e-04 - val_loss: 0.0045 - val_mae: 0.0449 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00235: val_mae did not improve from 0.04463\n",
      "Epoch 236/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 2.1549e-04 - mae: 0.0109 - mse: 2.1549e-04 - val_loss: 0.0048 - val_mae: 0.0463 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00236: val_mae did not improve from 0.04463\n",
      "Epoch 237/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 1.9723e-04 - mae: 0.0105 - mse: 1.9723e-04 - val_loss: 0.0051 - val_mae: 0.0484 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00237: val_mae did not improve from 0.04463\n",
      "Epoch 238/300\n",
      "161/161 [==============================] - 3s 21ms/step - loss: 2.3366e-04 - mae: 0.0113 - mse: 2.3366e-04 - val_loss: 0.0046 - val_mae: 0.0457 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00238: val_mae did not improve from 0.04463\n",
      "Epoch 00238: early stopping\n",
      "Done fitting\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_wo_dups_jcw model created and file saved for future use.\n",
      "End model and train\n",
      "\n",
      "Opening file:  clean_all_outliers.p\n",
      "cleantrain/clean_all_outliers.p\n",
      "Train Shape: (7041, 31)\n",
      "Begin model and train:\n",
      "Model name: clean_all_outliers_jcw\n",
      "Scaling 7041 images...\n",
      "Scaling of 7041 observations complete.\n",
      "Index(['left_eye_center_x', 'left_eye_center_y', 'right_eye_center_x',\n",
      "       'right_eye_center_y', 'nose_tip_x', 'nose_tip_y',\n",
      "       'mouth_center_bottom_lip_x', 'mouth_center_bottom_lip_y', 'image'],\n",
      "      dtype='object')\n",
      "Begining the split of Train with all features\n",
      "Looking for model JW\n",
      "JW model file not found. Model creation beginning\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 32, 32, 32)        288       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 8, 8, 64)          8192      \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 2, 2, 128)         32768     \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 2, 2, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 8)                 4104      \n",
      "=================================================================\n",
      "Total params: 374,952\n",
      "Trainable params: 374,504\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "None\n",
      "Done compiling\n",
      "Epoch 1/300\n",
      "175/175 [==============================] - 4s 19ms/step - loss: 0.0877 - mae: 0.1815 - mse: 0.0877 - val_loss: 0.0187 - val_mae: 0.1033 - val_mse: 0.0187\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 0.10333, saving model to data/models/clean_all_outliers_jcw.h5\n",
      "Epoch 2/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0085 - mae: 0.0684 - mse: 0.0085 - val_loss: 0.0147 - val_mae: 0.0937 - val_mse: 0.0147\n",
      "\n",
      "Epoch 00002: val_mae improved from 0.10333 to 0.09372, saving model to data/models/clean_all_outliers_jcw.h5\n",
      "Epoch 3/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0073 - mae: 0.0620 - mse: 0.0073 - val_loss: 0.0090 - val_mae: 0.0697 - val_mse: 0.0090\n",
      "\n",
      "Epoch 00003: val_mae improved from 0.09372 to 0.06967, saving model to data/models/clean_all_outliers_jcw.h5\n",
      "Epoch 4/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0060 - mae: 0.0567 - mse: 0.0060 - val_loss: 0.0079 - val_mae: 0.0643 - val_mse: 0.0079\n",
      "\n",
      "Epoch 00004: val_mae improved from 0.06967 to 0.06435, saving model to data/models/clean_all_outliers_jcw.h5\n",
      "Epoch 5/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0058 - mae: 0.0554 - mse: 0.0058 - val_loss: 0.0075 - val_mae: 0.0621 - val_mse: 0.0075\n",
      "\n",
      "Epoch 00005: val_mae improved from 0.06435 to 0.06214, saving model to data/models/clean_all_outliers_jcw.h5\n",
      "Epoch 6/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0049 - mae: 0.0510 - mse: 0.0049 - val_loss: 0.0071 - val_mae: 0.0609 - val_mse: 0.0071\n",
      "\n",
      "Epoch 00006: val_mae improved from 0.06214 to 0.06093, saving model to data/models/clean_all_outliers_jcw.h5\n",
      "Epoch 7/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0049 - mae: 0.0507 - mse: 0.0049 - val_loss: 0.0070 - val_mae: 0.0596 - val_mse: 0.0070\n",
      "\n",
      "Epoch 00007: val_mae improved from 0.06093 to 0.05961, saving model to data/models/clean_all_outliers_jcw.h5\n",
      "Epoch 8/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0044 - mae: 0.0487 - mse: 0.0044 - val_loss: 0.0068 - val_mae: 0.0583 - val_mse: 0.0068\n",
      "\n",
      "Epoch 00008: val_mae improved from 0.05961 to 0.05833, saving model to data/models/clean_all_outliers_jcw.h5\n",
      "Epoch 9/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0041 - mae: 0.0468 - mse: 0.0041 - val_loss: 0.0075 - val_mae: 0.0626 - val_mse: 0.0075\n",
      "\n",
      "Epoch 00009: val_mae did not improve from 0.05833\n",
      "Epoch 10/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0039 - mae: 0.0457 - mse: 0.0039 - val_loss: 0.0069 - val_mae: 0.0594 - val_mse: 0.0069\n",
      "\n",
      "Epoch 00010: val_mae did not improve from 0.05833\n",
      "Epoch 11/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0037 - mae: 0.0453 - mse: 0.0037 - val_loss: 0.0065 - val_mae: 0.0570 - val_mse: 0.0065\n",
      "\n",
      "Epoch 00011: val_mae improved from 0.05833 to 0.05704, saving model to data/models/clean_all_outliers_jcw.h5\n",
      "Epoch 12/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0033 - mae: 0.0428 - mse: 0.0033 - val_loss: 0.0071 - val_mae: 0.0599 - val_mse: 0.0071\n",
      "\n",
      "Epoch 00012: val_mae did not improve from 0.05704\n",
      "Epoch 13/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0031 - mae: 0.0416 - mse: 0.0031 - val_loss: 0.0066 - val_mae: 0.0576 - val_mse: 0.0066\n",
      "\n",
      "Epoch 00013: val_mae did not improve from 0.05704\n",
      "Epoch 14/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0029 - mae: 0.0404 - mse: 0.0029 - val_loss: 0.0066 - val_mae: 0.0577 - val_mse: 0.0066\n",
      "\n",
      "Epoch 00014: val_mae did not improve from 0.05704\n",
      "Epoch 15/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0028 - mae: 0.0400 - mse: 0.0028 - val_loss: 0.0066 - val_mae: 0.0575 - val_mse: 0.0066\n",
      "\n",
      "Epoch 00015: val_mae did not improve from 0.05704\n",
      "Epoch 16/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0027 - mae: 0.0394 - mse: 0.0027 - val_loss: 0.0065 - val_mae: 0.0562 - val_mse: 0.0065\n",
      "\n",
      "Epoch 00016: val_mae improved from 0.05704 to 0.05624, saving model to data/models/clean_all_outliers_jcw.h5\n",
      "Epoch 17/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.0025 - mae: 0.0382 - mse: 0.0025 - val_loss: 0.0066 - val_mae: 0.0573 - val_mse: 0.0066\n",
      "\n",
      "Epoch 00017: val_mae did not improve from 0.05624\n",
      "Epoch 18/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.0024 - mae: 0.0371 - mse: 0.0024 - val_loss: 0.0064 - val_mae: 0.0558 - val_mse: 0.0064\n",
      "\n",
      "Epoch 00018: val_mae improved from 0.05624 to 0.05576, saving model to data/models/clean_all_outliers_jcw.h5\n",
      "Epoch 19/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0024 - mae: 0.0368 - mse: 0.0024 - val_loss: 0.0060 - val_mae: 0.0544 - val_mse: 0.0060\n",
      "\n",
      "Epoch 00019: val_mae improved from 0.05576 to 0.05436, saving model to data/models/clean_all_outliers_jcw.h5\n",
      "Epoch 20/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0023 - mae: 0.0364 - mse: 0.0023 - val_loss: 0.0058 - val_mae: 0.0534 - val_mse: 0.0058\n",
      "\n",
      "Epoch 00020: val_mae improved from 0.05436 to 0.05338, saving model to data/models/clean_all_outliers_jcw.h5\n",
      "Epoch 21/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0022 - mae: 0.0352 - mse: 0.0022 - val_loss: 0.0063 - val_mae: 0.0553 - val_mse: 0.0063\n",
      "\n",
      "Epoch 00021: val_mae did not improve from 0.05338\n",
      "Epoch 22/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0021 - mae: 0.0349 - mse: 0.0021 - val_loss: 0.0062 - val_mae: 0.0549 - val_mse: 0.0062\n",
      "\n",
      "Epoch 00022: val_mae did not improve from 0.05338\n",
      "Epoch 23/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0024 - mae: 0.0354 - mse: 0.0024 - val_loss: 0.0060 - val_mae: 0.0535 - val_mse: 0.0060\n",
      "\n",
      "Epoch 00023: val_mae did not improve from 0.05338\n",
      "Epoch 24/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0020 - mae: 0.0334 - mse: 0.0020 - val_loss: 0.0061 - val_mae: 0.0535 - val_mse: 0.0061\n",
      "\n",
      "Epoch 00024: val_mae did not improve from 0.05338\n",
      "Epoch 25/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0021 - mae: 0.0344 - mse: 0.0021 - val_loss: 0.0059 - val_mae: 0.0539 - val_mse: 0.0059\n",
      "\n",
      "Epoch 00025: val_mae did not improve from 0.05338\n",
      "Epoch 26/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0019 - mae: 0.0327 - mse: 0.0019 - val_loss: 0.0060 - val_mae: 0.0535 - val_mse: 0.0060\n",
      "\n",
      "Epoch 00026: val_mae did not improve from 0.05338\n",
      "Epoch 27/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0021 - mae: 0.0336 - mse: 0.0021 - val_loss: 0.0055 - val_mae: 0.0511 - val_mse: 0.0055\n",
      "\n",
      "Epoch 00027: val_mae improved from 0.05338 to 0.05113, saving model to data/models/clean_all_outliers_jcw.h5\n",
      "Epoch 28/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0021 - mae: 0.0335 - mse: 0.0021 - val_loss: 0.0056 - val_mae: 0.0515 - val_mse: 0.0056\n",
      "\n",
      "Epoch 00028: val_mae did not improve from 0.05113\n",
      "Epoch 29/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0021 - mae: 0.0332 - mse: 0.0021 - val_loss: 0.0059 - val_mae: 0.0531 - val_mse: 0.0059\n",
      "\n",
      "Epoch 00029: val_mae did not improve from 0.05113\n",
      "Epoch 30/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0019 - mae: 0.0323 - mse: 0.0019 - val_loss: 0.0058 - val_mae: 0.0529 - val_mse: 0.0058\n",
      "\n",
      "Epoch 00030: val_mae did not improve from 0.05113\n",
      "Epoch 31/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0019 - mae: 0.0325 - mse: 0.0019 - val_loss: 0.0059 - val_mae: 0.0524 - val_mse: 0.0059\n",
      "\n",
      "Epoch 00031: val_mae did not improve from 0.05113\n",
      "Epoch 32/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0019 - mae: 0.0325 - mse: 0.0019 - val_loss: 0.0054 - val_mae: 0.0503 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00032: val_mae improved from 0.05113 to 0.05031, saving model to data/models/clean_all_outliers_jcw.h5\n",
      "Epoch 33/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0016 - mae: 0.0301 - mse: 0.0016 - val_loss: 0.0056 - val_mae: 0.0520 - val_mse: 0.0056\n",
      "\n",
      "Epoch 00033: val_mae did not improve from 0.05031\n",
      "Epoch 34/300\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 0.0016 - mae: 0.0301 - mse: 0.0016 - val_loss: 0.0053 - val_mae: 0.0498 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00034: val_mae improved from 0.05031 to 0.04981, saving model to data/models/clean_all_outliers_jcw.h5\n",
      "Epoch 35/300\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 0.0016 - mae: 0.0301 - mse: 0.0016 - val_loss: 0.0083 - val_mae: 0.0667 - val_mse: 0.0083\n",
      "\n",
      "Epoch 00035: val_mae did not improve from 0.04981\n",
      "Epoch 36/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.0017 - mae: 0.0307 - mse: 0.0017 - val_loss: 0.0057 - val_mae: 0.0517 - val_mse: 0.0057\n",
      "\n",
      "Epoch 00036: val_mae did not improve from 0.04981\n",
      "Epoch 37/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.0017 - mae: 0.0312 - mse: 0.0017 - val_loss: 0.0056 - val_mae: 0.0510 - val_mse: 0.0056\n",
      "\n",
      "Epoch 00037: val_mae did not improve from 0.04981\n",
      "Epoch 38/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.0014 - mae: 0.0281 - mse: 0.0014 - val_loss: 0.0054 - val_mae: 0.0502 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00038: val_mae did not improve from 0.04981\n",
      "Epoch 39/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.0014 - mae: 0.0283 - mse: 0.0014 - val_loss: 0.0052 - val_mae: 0.0491 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00039: val_mae improved from 0.04981 to 0.04913, saving model to data/models/clean_all_outliers_jcw.h5\n",
      "Epoch 40/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.0016 - mae: 0.0295 - mse: 0.0016 - val_loss: 0.0056 - val_mae: 0.0526 - val_mse: 0.0056\n",
      "\n",
      "Epoch 00040: val_mae did not improve from 0.04913\n",
      "Epoch 41/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.0015 - mae: 0.0291 - mse: 0.0015 - val_loss: 0.0054 - val_mae: 0.0505 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00041: val_mae did not improve from 0.04913\n",
      "Epoch 42/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.0014 - mae: 0.0285 - mse: 0.0014 - val_loss: 0.0057 - val_mae: 0.0519 - val_mse: 0.0057\n",
      "\n",
      "Epoch 00042: val_mae did not improve from 0.04913\n",
      "Epoch 43/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.0014 - mae: 0.0278 - mse: 0.0014 - val_loss: 0.0066 - val_mae: 0.0578 - val_mse: 0.0066\n",
      "\n",
      "Epoch 00043: val_mae did not improve from 0.04913\n",
      "Epoch 44/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0015 - mae: 0.0281 - mse: 0.0015 - val_loss: 0.0060 - val_mae: 0.0530 - val_mse: 0.0060\n",
      "\n",
      "Epoch 00044: val_mae did not improve from 0.04913\n",
      "Epoch 45/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0016 - mae: 0.0288 - mse: 0.0016 - val_loss: 0.0053 - val_mae: 0.0493 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00045: val_mae did not improve from 0.04913\n",
      "Epoch 46/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0017 - mae: 0.0293 - mse: 0.0017 - val_loss: 0.0051 - val_mae: 0.0483 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00046: val_mae improved from 0.04913 to 0.04835, saving model to data/models/clean_all_outliers_jcw.h5\n",
      "Epoch 47/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0013 - mae: 0.0267 - mse: 0.0013 - val_loss: 0.0051 - val_mae: 0.0478 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00047: val_mae improved from 0.04835 to 0.04778, saving model to data/models/clean_all_outliers_jcw.h5\n",
      "Epoch 48/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0013 - mae: 0.0255 - mse: 0.0013 - val_loss: 0.0053 - val_mae: 0.0488 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00048: val_mae did not improve from 0.04778\n",
      "Epoch 49/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0014 - mae: 0.0271 - mse: 0.0014 - val_loss: 0.0051 - val_mae: 0.0477 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00049: val_mae improved from 0.04778 to 0.04765, saving model to data/models/clean_all_outliers_jcw.h5\n",
      "Epoch 50/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0012 - mae: 0.0259 - mse: 0.0012 - val_loss: 0.0064 - val_mae: 0.0571 - val_mse: 0.0064\n",
      "\n",
      "Epoch 00050: val_mae did not improve from 0.04765\n",
      "Epoch 51/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0015 - mae: 0.0282 - mse: 0.0015 - val_loss: 0.0050 - val_mae: 0.0477 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00051: val_mae did not improve from 0.04765\n",
      "Epoch 52/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0016 - mae: 0.0274 - mse: 0.0016 - val_loss: 0.0051 - val_mae: 0.0481 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00052: val_mae did not improve from 0.04765\n",
      "Epoch 53/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0011 - mae: 0.0248 - mse: 0.0011 - val_loss: 0.0049 - val_mae: 0.0473 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00053: val_mae improved from 0.04765 to 0.04733, saving model to data/models/clean_all_outliers_jcw.h5\n",
      "Epoch 54/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0012 - mae: 0.0259 - mse: 0.0012 - val_loss: 0.0053 - val_mae: 0.0506 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00054: val_mae did not improve from 0.04733\n",
      "Epoch 55/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0013 - mae: 0.0259 - mse: 0.0013 - val_loss: 0.0049 - val_mae: 0.0463 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00055: val_mae improved from 0.04733 to 0.04632, saving model to data/models/clean_all_outliers_jcw.h5\n",
      "Epoch 56/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0012 - mae: 0.0250 - mse: 0.0012 - val_loss: 0.0053 - val_mae: 0.0495 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00056: val_mae did not improve from 0.04632\n",
      "Epoch 57/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0014 - mae: 0.0254 - mse: 0.0014 - val_loss: 0.0050 - val_mae: 0.0485 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00057: val_mae did not improve from 0.04632\n",
      "Epoch 58/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0011 - mae: 0.0242 - mse: 0.0011 - val_loss: 0.0051 - val_mae: 0.0491 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00058: val_mae did not improve from 0.04632\n",
      "Epoch 59/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0011 - mae: 0.0244 - mse: 0.0011 - val_loss: 0.0049 - val_mae: 0.0465 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00059: val_mae did not improve from 0.04632\n",
      "Epoch 60/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 9.9488e-04 - mae: 0.0233 - mse: 9.9488e-04 - val_loss: 0.0051 - val_mae: 0.0480 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00060: val_mae did not improve from 0.04632\n",
      "Epoch 61/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0011 - mae: 0.0243 - mse: 0.0011 - val_loss: 0.0050 - val_mae: 0.0478 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00061: val_mae did not improve from 0.04632\n",
      "Epoch 62/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0012 - mae: 0.0253 - mse: 0.0012 - val_loss: 0.0047 - val_mae: 0.0455 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00062: val_mae improved from 0.04632 to 0.04554, saving model to data/models/clean_all_outliers_jcw.h5\n",
      "Epoch 63/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.0010 - mae: 0.0238 - mse: 0.0010 - val_loss: 0.0049 - val_mae: 0.0470 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00063: val_mae did not improve from 0.04554\n",
      "Epoch 64/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.0011 - mae: 0.0250 - mse: 0.0011 - val_loss: 0.0049 - val_mae: 0.0464 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00064: val_mae did not improve from 0.04554\n",
      "Epoch 65/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 9.4640e-04 - mae: 0.0227 - mse: 9.4640e-04 - val_loss: 0.0049 - val_mae: 0.0465 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00065: val_mae did not improve from 0.04554\n",
      "Epoch 66/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.0011 - mae: 0.0238 - mse: 0.0011 - val_loss: 0.0048 - val_mae: 0.0459 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00066: val_mae did not improve from 0.04554\n",
      "Epoch 67/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.0010 - mae: 0.0225 - mse: 0.0010 - val_loss: 0.0047 - val_mae: 0.0459 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00067: val_mae did not improve from 0.04554\n",
      "Epoch 68/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 9.0713e-04 - mae: 0.0217 - mse: 9.0713e-04 - val_loss: 0.0051 - val_mae: 0.0482 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00068: val_mae did not improve from 0.04554\n",
      "Epoch 69/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 8.2558e-04 - mae: 0.0211 - mse: 8.2558e-04 - val_loss: 0.0049 - val_mae: 0.0469 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00069: val_mae did not improve from 0.04554\n",
      "Epoch 70/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 9.3469e-04 - mae: 0.0218 - mse: 9.3469e-04 - val_loss: 0.0049 - val_mae: 0.0469 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00070: val_mae did not improve from 0.04554\n",
      "Epoch 71/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 8.2521e-04 - mae: 0.0211 - mse: 8.2521e-04 - val_loss: 0.0047 - val_mae: 0.0451 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00071: val_mae improved from 0.04554 to 0.04512, saving model to data/models/clean_all_outliers_jcw.h5\n",
      "Epoch 72/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 8.9500e-04 - mae: 0.0219 - mse: 8.9500e-04 - val_loss: 0.0050 - val_mae: 0.0482 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00072: val_mae did not improve from 0.04512\n",
      "Epoch 73/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0012 - mae: 0.0246 - mse: 0.0012 - val_loss: 0.0050 - val_mae: 0.0471 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00073: val_mae did not improve from 0.04512\n",
      "Epoch 74/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 9.7294e-04 - mae: 0.0218 - mse: 9.7294e-04 - val_loss: 0.0047 - val_mae: 0.0456 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00074: val_mae did not improve from 0.04512\n",
      "Epoch 75/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 7.1442e-04 - mae: 0.0201 - mse: 7.1442e-04 - val_loss: 0.0047 - val_mae: 0.0456 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00075: val_mae did not improve from 0.04512\n",
      "Epoch 76/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 7.9984e-04 - mae: 0.0210 - mse: 7.9984e-04 - val_loss: 0.0048 - val_mae: 0.0456 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00076: val_mae did not improve from 0.04512\n",
      "Epoch 77/300\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 9.0345e-04 - mae: 0.0213 - mse: 9.0345e-04 - val_loss: 0.0048 - val_mae: 0.0458 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00077: val_mae did not improve from 0.04512\n",
      "Epoch 78/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 9.1045e-04 - mae: 0.0215 - mse: 9.1045e-04 - val_loss: 0.0047 - val_mae: 0.0452 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00078: val_mae did not improve from 0.04512\n",
      "Epoch 79/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 9.3047e-04 - mae: 0.0214 - mse: 9.3047e-04 - val_loss: 0.0046 - val_mae: 0.0448 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00079: val_mae improved from 0.04512 to 0.04482, saving model to data/models/clean_all_outliers_jcw.h5\n",
      "Epoch 80/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 8.3693e-04 - mae: 0.0206 - mse: 8.3693e-04 - val_loss: 0.0048 - val_mae: 0.0458 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00080: val_mae did not improve from 0.04482\n",
      "Epoch 81/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 7.6389e-04 - mae: 0.0200 - mse: 7.6389e-04 - val_loss: 0.0050 - val_mae: 0.0479 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00081: val_mae did not improve from 0.04482\n",
      "Epoch 82/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0011 - mae: 0.0225 - mse: 0.0011 - val_loss: 0.0047 - val_mae: 0.0452 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00082: val_mae did not improve from 0.04482\n",
      "Epoch 83/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 9.1789e-04 - mae: 0.0205 - mse: 9.1789e-04 - val_loss: 0.0047 - val_mae: 0.0450 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00083: val_mae did not improve from 0.04482\n",
      "Epoch 84/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 8.3357e-04 - mae: 0.0202 - mse: 8.3357e-04 - val_loss: 0.0050 - val_mae: 0.0477 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00084: val_mae did not improve from 0.04482\n",
      "Epoch 85/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 7.2495e-04 - mae: 0.0202 - mse: 7.2495e-04 - val_loss: 0.0047 - val_mae: 0.0451 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00085: val_mae did not improve from 0.04482\n",
      "Epoch 86/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 6.4957e-04 - mae: 0.0192 - mse: 6.4957e-04 - val_loss: 0.0047 - val_mae: 0.0452 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00086: val_mae did not improve from 0.04482\n",
      "Epoch 87/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 7.2726e-04 - mae: 0.0195 - mse: 7.2726e-04 - val_loss: 0.0048 - val_mae: 0.0460 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00087: val_mae did not improve from 0.04482\n",
      "Epoch 88/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 8.7834e-04 - mae: 0.0205 - mse: 8.7834e-04 - val_loss: 0.0047 - val_mae: 0.0457 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00088: val_mae did not improve from 0.04482\n",
      "Epoch 89/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 7.4507e-04 - mae: 0.0201 - mse: 7.4507e-04 - val_loss: 0.0048 - val_mae: 0.0460 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00089: val_mae did not improve from 0.04482\n",
      "Epoch 90/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 6.3727e-04 - mae: 0.0190 - mse: 6.3727e-04 - val_loss: 0.0049 - val_mae: 0.0460 - val_mse: 0.0049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00090: val_mae did not improve from 0.04482\n",
      "Epoch 91/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 6.3187e-04 - mae: 0.0189 - mse: 6.3187e-04 - val_loss: 0.0046 - val_mae: 0.0449 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00091: val_mae did not improve from 0.04482\n",
      "Epoch 92/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 6.4163e-04 - mae: 0.0187 - mse: 6.4163e-04 - val_loss: 0.0047 - val_mae: 0.0450 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00092: val_mae did not improve from 0.04482\n",
      "Epoch 93/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 8.2065e-04 - mae: 0.0204 - mse: 8.2065e-04 - val_loss: 0.0050 - val_mae: 0.0470 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00093: val_mae did not improve from 0.04482\n",
      "Epoch 94/300\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 7.8218e-04 - mae: 0.0193 - mse: 7.8218e-04 - val_loss: 0.0046 - val_mae: 0.0446 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00094: val_mae improved from 0.04482 to 0.04463, saving model to data/models/clean_all_outliers_jcw.h5\n",
      "Epoch 95/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 6.6478e-04 - mae: 0.0186 - mse: 6.6478e-04 - val_loss: 0.0049 - val_mae: 0.0471 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00095: val_mae did not improve from 0.04463\n",
      "Epoch 96/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 7.4146e-04 - mae: 0.0199 - mse: 7.4146e-04 - val_loss: 0.0047 - val_mae: 0.0454 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00096: val_mae did not improve from 0.04463\n",
      "Epoch 97/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 8.3755e-04 - mae: 0.0192 - mse: 8.3755e-04 - val_loss: 0.0047 - val_mae: 0.0451 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00097: val_mae did not improve from 0.04463\n",
      "Epoch 98/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 5.7846e-04 - mae: 0.0179 - mse: 5.7846e-04 - val_loss: 0.0045 - val_mae: 0.0445 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00098: val_mae improved from 0.04463 to 0.04451, saving model to data/models/clean_all_outliers_jcw.h5\n",
      "Epoch 99/300\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 6.2714e-04 - mae: 0.0184 - mse: 6.2714e-04 - val_loss: 0.0046 - val_mae: 0.0448 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00099: val_mae did not improve from 0.04451\n",
      "Epoch 100/300\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 6.1553e-04 - mae: 0.0179 - mse: 6.1553e-04 - val_loss: 0.0046 - val_mae: 0.0446 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00100: val_mae did not improve from 0.04451\n",
      "Epoch 101/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 5.0900e-04 - mae: 0.0169 - mse: 5.0900e-04 - val_loss: 0.0047 - val_mae: 0.0452 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00101: val_mae did not improve from 0.04451\n",
      "Epoch 102/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 5.6810e-04 - mae: 0.0177 - mse: 5.6810e-04 - val_loss: 0.0050 - val_mae: 0.0479 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00102: val_mae did not improve from 0.04451\n",
      "Epoch 103/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 6.8280e-04 - mae: 0.0194 - mse: 6.8280e-04 - val_loss: 0.0045 - val_mae: 0.0445 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00103: val_mae did not improve from 0.04451\n",
      "Epoch 104/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 6.0787e-04 - mae: 0.0180 - mse: 6.0787e-04 - val_loss: 0.0045 - val_mae: 0.0439 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00104: val_mae improved from 0.04451 to 0.04394, saving model to data/models/clean_all_outliers_jcw.h5\n",
      "Epoch 105/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 6.5282e-04 - mae: 0.0178 - mse: 6.5282e-04 - val_loss: 0.0046 - val_mae: 0.0441 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00105: val_mae did not improve from 0.04394\n",
      "Epoch 106/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 7.0806e-04 - mae: 0.0181 - mse: 7.0806e-04 - val_loss: 0.0045 - val_mae: 0.0442 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00106: val_mae did not improve from 0.04394\n",
      "Epoch 107/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 5.2230e-04 - mae: 0.0170 - mse: 5.2230e-04 - val_loss: 0.0046 - val_mae: 0.0443 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00107: val_mae did not improve from 0.04394\n",
      "Epoch 108/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 5.4444e-04 - mae: 0.0173 - mse: 5.4444e-04 - val_loss: 0.0047 - val_mae: 0.0457 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00108: val_mae did not improve from 0.04394\n",
      "Epoch 109/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 5.4522e-04 - mae: 0.0170 - mse: 5.4522e-04 - val_loss: 0.0046 - val_mae: 0.0448 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00109: val_mae did not improve from 0.04394\n",
      "Epoch 110/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 5.4182e-04 - mae: 0.0172 - mse: 5.4182e-04 - val_loss: 0.0047 - val_mae: 0.0450 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00110: val_mae did not improve from 0.04394\n",
      "Epoch 111/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 5.5987e-04 - mae: 0.0172 - mse: 5.5987e-04 - val_loss: 0.0045 - val_mae: 0.0439 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00111: val_mae improved from 0.04394 to 0.04394, saving model to data/models/clean_all_outliers_jcw.h5\n",
      "Epoch 112/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 4.9283e-04 - mae: 0.0166 - mse: 4.9283e-04 - val_loss: 0.0046 - val_mae: 0.0447 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00112: val_mae did not improve from 0.04394\n",
      "Epoch 113/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 7.0614e-04 - mae: 0.0190 - mse: 7.0614e-04 - val_loss: 0.0047 - val_mae: 0.0452 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00113: val_mae did not improve from 0.04394\n",
      "Epoch 114/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 8.0904e-04 - mae: 0.0179 - mse: 8.0904e-04 - val_loss: 0.0044 - val_mae: 0.0436 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00114: val_mae improved from 0.04394 to 0.04364, saving model to data/models/clean_all_outliers_jcw.h5\n",
      "Epoch 115/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 5.7247e-04 - mae: 0.0169 - mse: 5.7247e-04 - val_loss: 0.0046 - val_mae: 0.0443 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00115: val_mae did not improve from 0.04364\n",
      "Epoch 116/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 5.5187e-04 - mae: 0.0168 - mse: 5.5187e-04 - val_loss: 0.0045 - val_mae: 0.0443 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00116: val_mae did not improve from 0.04364\n",
      "Epoch 117/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 4.9885e-04 - mae: 0.0166 - mse: 4.9885e-04 - val_loss: 0.0046 - val_mae: 0.0442 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00117: val_mae did not improve from 0.04364\n",
      "Epoch 118/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 5.8271e-04 - mae: 0.0175 - mse: 5.8271e-04 - val_loss: 0.0048 - val_mae: 0.0458 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00118: val_mae did not improve from 0.04364\n",
      "Epoch 119/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 6.8390e-04 - mae: 0.0178 - mse: 6.8390e-04 - val_loss: 0.0047 - val_mae: 0.0451 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00119: val_mae did not improve from 0.04364\n",
      "Epoch 120/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 6.5769e-04 - mae: 0.0176 - mse: 6.5769e-04 - val_loss: 0.0046 - val_mae: 0.0442 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00120: val_mae did not improve from 0.04364\n",
      "Epoch 121/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 5.4309e-04 - mae: 0.0166 - mse: 5.4309e-04 - val_loss: 0.0045 - val_mae: 0.0442 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00121: val_mae did not improve from 0.04364\n",
      "Epoch 122/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 5.4410e-04 - mae: 0.0171 - mse: 5.4410e-04 - val_loss: 0.0044 - val_mae: 0.0431 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00122: val_mae improved from 0.04364 to 0.04315, saving model to data/models/clean_all_outliers_jcw.h5\n",
      "Epoch 123/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 5.8933e-04 - mae: 0.0173 - mse: 5.8933e-04 - val_loss: 0.0045 - val_mae: 0.0435 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00123: val_mae did not improve from 0.04315\n",
      "Epoch 124/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 5.0037e-04 - mae: 0.0158 - mse: 5.0037e-04 - val_loss: 0.0044 - val_mae: 0.0432 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00124: val_mae did not improve from 0.04315\n",
      "Epoch 125/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 3s 19ms/step - loss: 4.2374e-04 - mae: 0.0153 - mse: 4.2374e-04 - val_loss: 0.0045 - val_mae: 0.0435 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00125: val_mae did not improve from 0.04315\n",
      "Epoch 126/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 4.3323e-04 - mae: 0.0153 - mse: 4.3323e-04 - val_loss: 0.0046 - val_mae: 0.0443 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00126: val_mae did not improve from 0.04315\n",
      "Epoch 127/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 4.3781e-04 - mae: 0.0152 - mse: 4.3781e-04 - val_loss: 0.0046 - val_mae: 0.0440 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00127: val_mae did not improve from 0.04315\n",
      "Epoch 128/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 4.6724e-04 - mae: 0.0159 - mse: 4.6724e-04 - val_loss: 0.0046 - val_mae: 0.0444 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00128: val_mae did not improve from 0.04315\n",
      "Epoch 129/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 4.5074e-04 - mae: 0.0156 - mse: 4.5074e-04 - val_loss: 0.0045 - val_mae: 0.0435 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00129: val_mae did not improve from 0.04315\n",
      "Epoch 130/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 4.0330e-04 - mae: 0.0149 - mse: 4.0330e-04 - val_loss: 0.0045 - val_mae: 0.0434 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00130: val_mae did not improve from 0.04315\n",
      "Epoch 131/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 4.0052e-04 - mae: 0.0150 - mse: 4.0052e-04 - val_loss: 0.0046 - val_mae: 0.0443 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00131: val_mae did not improve from 0.04315\n",
      "Epoch 132/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 4.4826e-04 - mae: 0.0157 - mse: 4.4826e-04 - val_loss: 0.0045 - val_mae: 0.0440 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00132: val_mae did not improve from 0.04315\n",
      "Epoch 133/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 4.7214e-04 - mae: 0.0162 - mse: 4.7214e-04 - val_loss: 0.0045 - val_mae: 0.0440 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00133: val_mae did not improve from 0.04315\n",
      "Epoch 134/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 5.3715e-04 - mae: 0.0164 - mse: 5.3715e-04 - val_loss: 0.0044 - val_mae: 0.0429 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00134: val_mae improved from 0.04315 to 0.04290, saving model to data/models/clean_all_outliers_jcw.h5\n",
      "Epoch 135/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 4.4256e-04 - mae: 0.0154 - mse: 4.4256e-04 - val_loss: 0.0046 - val_mae: 0.0442 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00135: val_mae did not improve from 0.04290\n",
      "Epoch 136/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 4.7189e-04 - mae: 0.0154 - mse: 4.7189e-04 - val_loss: 0.0046 - val_mae: 0.0443 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00136: val_mae did not improve from 0.04290\n",
      "Epoch 137/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 4.1795e-04 - mae: 0.0151 - mse: 4.1795e-04 - val_loss: 0.0046 - val_mae: 0.0443 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00137: val_mae did not improve from 0.04290\n",
      "Epoch 138/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 3.9715e-04 - mae: 0.0148 - mse: 3.9715e-04 - val_loss: 0.0048 - val_mae: 0.0458 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00138: val_mae did not improve from 0.04290\n",
      "Epoch 139/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 4.1340e-04 - mae: 0.0152 - mse: 4.1340e-04 - val_loss: 0.0044 - val_mae: 0.0432 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00139: val_mae did not improve from 0.04290\n",
      "Epoch 140/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 4.6346e-04 - mae: 0.0156 - mse: 4.6346e-04 - val_loss: 0.0045 - val_mae: 0.0437 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00140: val_mae did not improve from 0.04290\n",
      "Epoch 141/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 4.2551e-04 - mae: 0.0151 - mse: 4.2551e-04 - val_loss: 0.0045 - val_mae: 0.0438 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00141: val_mae did not improve from 0.04290\n",
      "Epoch 142/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 4.4416e-04 - mae: 0.0152 - mse: 4.4416e-04 - val_loss: 0.0046 - val_mae: 0.0444 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00142: val_mae did not improve from 0.04290\n",
      "Epoch 143/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 5.0376e-04 - mae: 0.0161 - mse: 5.0376e-04 - val_loss: 0.0044 - val_mae: 0.0430 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00143: val_mae did not improve from 0.04290\n",
      "Epoch 144/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 3.9249e-04 - mae: 0.0147 - mse: 3.9249e-04 - val_loss: 0.0046 - val_mae: 0.0441 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00144: val_mae did not improve from 0.04290\n",
      "Epoch 145/300\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 3.6587e-04 - mae: 0.0142 - mse: 3.6587e-04 - val_loss: 0.0044 - val_mae: 0.0428 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00145: val_mae improved from 0.04290 to 0.04284, saving model to data/models/clean_all_outliers_jcw.h5\n",
      "Epoch 146/300\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 4.0234e-04 - mae: 0.0146 - mse: 4.0234e-04 - val_loss: 0.0045 - val_mae: 0.0438 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00146: val_mae did not improve from 0.04284\n",
      "Epoch 147/300\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 3.5679e-04 - mae: 0.0141 - mse: 3.5679e-04 - val_loss: 0.0044 - val_mae: 0.0429 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00147: val_mae did not improve from 0.04284\n",
      "Epoch 148/300\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 4.2105e-04 - mae: 0.0146 - mse: 4.2105e-04 - val_loss: 0.0044 - val_mae: 0.0430 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00148: val_mae did not improve from 0.04284\n",
      "Epoch 149/300\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 3.7198e-04 - mae: 0.0143 - mse: 3.7198e-04 - val_loss: 0.0045 - val_mae: 0.0430 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00149: val_mae did not improve from 0.04284\n",
      "Epoch 150/300\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 3.6521e-04 - mae: 0.0139 - mse: 3.6521e-04 - val_loss: 0.0045 - val_mae: 0.0437 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00150: val_mae did not improve from 0.04284\n",
      "Epoch 151/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 3.6155e-04 - mae: 0.0142 - mse: 3.6155e-04 - val_loss: 0.0045 - val_mae: 0.0437 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00151: val_mae did not improve from 0.04284\n",
      "Epoch 152/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 4.2442e-04 - mae: 0.0146 - mse: 4.2442e-04 - val_loss: 0.0043 - val_mae: 0.0425 - val_mse: 0.0043\n",
      "\n",
      "Epoch 00152: val_mae improved from 0.04284 to 0.04248, saving model to data/models/clean_all_outliers_jcw.h5\n",
      "Epoch 153/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 3.5351e-04 - mae: 0.0141 - mse: 3.5351e-04 - val_loss: 0.0044 - val_mae: 0.0430 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00153: val_mae did not improve from 0.04248\n",
      "Epoch 154/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 3.3448e-04 - mae: 0.0137 - mse: 3.3448e-04 - val_loss: 0.0045 - val_mae: 0.0436 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00154: val_mae did not improve from 0.04248\n",
      "Epoch 155/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 3.7048e-04 - mae: 0.0142 - mse: 3.7048e-04 - val_loss: 0.0045 - val_mae: 0.0433 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00155: val_mae did not improve from 0.04248\n",
      "Epoch 156/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 4.3964e-04 - mae: 0.0148 - mse: 4.3964e-04 - val_loss: 0.0044 - val_mae: 0.0434 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00156: val_mae did not improve from 0.04248\n",
      "Epoch 157/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 3.8829e-04 - mae: 0.0143 - mse: 3.8829e-04 - val_loss: 0.0044 - val_mae: 0.0431 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00157: val_mae did not improve from 0.04248\n",
      "Epoch 158/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 3.7470e-04 - mae: 0.0142 - mse: 3.7470e-04 - val_loss: 0.0043 - val_mae: 0.0428 - val_mse: 0.0043\n",
      "\n",
      "Epoch 00158: val_mae did not improve from 0.04248\n",
      "Epoch 159/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 3.7390e-04 - mae: 0.0143 - mse: 3.7390e-04 - val_loss: 0.0046 - val_mae: 0.0439 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00159: val_mae did not improve from 0.04248\n",
      "Epoch 160/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 4s 21ms/step - loss: 4.0534e-04 - mae: 0.0148 - mse: 4.0534e-04 - val_loss: 0.0044 - val_mae: 0.0430 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00160: val_mae did not improve from 0.04248\n",
      "Epoch 161/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 3.8952e-04 - mae: 0.0142 - mse: 3.8952e-04 - val_loss: 0.0045 - val_mae: 0.0435 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00161: val_mae did not improve from 0.04248\n",
      "Epoch 162/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 3.5142e-04 - mae: 0.0139 - mse: 3.5142e-04 - val_loss: 0.0045 - val_mae: 0.0438 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00162: val_mae did not improve from 0.04248\n",
      "Epoch 163/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 3.4952e-04 - mae: 0.0138 - mse: 3.4952e-04 - val_loss: 0.0046 - val_mae: 0.0443 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00163: val_mae did not improve from 0.04248\n",
      "Epoch 164/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 3.8722e-04 - mae: 0.0142 - mse: 3.8722e-04 - val_loss: 0.0045 - val_mae: 0.0444 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00164: val_mae did not improve from 0.04248\n",
      "Epoch 165/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 3.6193e-04 - mae: 0.0141 - mse: 3.6193e-04 - val_loss: 0.0045 - val_mae: 0.0435 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00165: val_mae did not improve from 0.04248\n",
      "Epoch 166/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 3.6375e-04 - mae: 0.0135 - mse: 3.6375e-04 - val_loss: 0.0045 - val_mae: 0.0432 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00166: val_mae did not improve from 0.04248\n",
      "Epoch 167/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 3.3827e-04 - mae: 0.0134 - mse: 3.3827e-04 - val_loss: 0.0044 - val_mae: 0.0433 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00167: val_mae did not improve from 0.04248\n",
      "Epoch 168/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 3.4126e-04 - mae: 0.0135 - mse: 3.4126e-04 - val_loss: 0.0044 - val_mae: 0.0426 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00168: val_mae did not improve from 0.04248\n",
      "Epoch 169/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 3.7127e-04 - mae: 0.0135 - mse: 3.7127e-04 - val_loss: 0.0045 - val_mae: 0.0438 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00169: val_mae did not improve from 0.04248\n",
      "Epoch 170/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 3.2763e-04 - mae: 0.0135 - mse: 3.2763e-04 - val_loss: 0.0044 - val_mae: 0.0432 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00170: val_mae did not improve from 0.04248\n",
      "Epoch 171/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 4.1846e-04 - mae: 0.0150 - mse: 4.1846e-04 - val_loss: 0.0047 - val_mae: 0.0448 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00171: val_mae did not improve from 0.04248\n",
      "Epoch 172/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 3.9759e-04 - mae: 0.0144 - mse: 3.9759e-04 - val_loss: 0.0044 - val_mae: 0.0431 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00172: val_mae did not improve from 0.04248\n",
      "Epoch 173/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 3.2581e-04 - mae: 0.0135 - mse: 3.2581e-04 - val_loss: 0.0044 - val_mae: 0.0430 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00173: val_mae did not improve from 0.04248\n",
      "Epoch 174/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 3.1280e-04 - mae: 0.0131 - mse: 3.1280e-04 - val_loss: 0.0043 - val_mae: 0.0426 - val_mse: 0.0043\n",
      "\n",
      "Epoch 00174: val_mae did not improve from 0.04248\n",
      "Epoch 175/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 3.5001e-04 - mae: 0.0130 - mse: 3.5001e-04 - val_loss: 0.0045 - val_mae: 0.0432 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00175: val_mae did not improve from 0.04248\n",
      "Epoch 176/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 3.0595e-04 - mae: 0.0128 - mse: 3.0595e-04 - val_loss: 0.0043 - val_mae: 0.0426 - val_mse: 0.0043\n",
      "\n",
      "Epoch 00176: val_mae did not improve from 0.04248\n",
      "Epoch 177/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 3.0447e-04 - mae: 0.0129 - mse: 3.0447e-04 - val_loss: 0.0044 - val_mae: 0.0430 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00177: val_mae did not improve from 0.04248\n",
      "Epoch 178/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 3.4452e-04 - mae: 0.0133 - mse: 3.4452e-04 - val_loss: 0.0043 - val_mae: 0.0425 - val_mse: 0.0043\n",
      "\n",
      "Epoch 00178: val_mae did not improve from 0.04248\n",
      "Epoch 179/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 3.8128e-04 - mae: 0.0129 - mse: 3.8128e-04 - val_loss: 0.0044 - val_mae: 0.0428 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00179: val_mae did not improve from 0.04248\n",
      "Epoch 180/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 3.0236e-04 - mae: 0.0128 - mse: 3.0236e-04 - val_loss: 0.0044 - val_mae: 0.0428 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00180: val_mae did not improve from 0.04248\n",
      "Epoch 181/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 3.3027e-04 - mae: 0.0132 - mse: 3.3027e-04 - val_loss: 0.0043 - val_mae: 0.0425 - val_mse: 0.0043\n",
      "\n",
      "Epoch 00181: val_mae did not improve from 0.04248\n",
      "Epoch 182/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 3.9627e-04 - mae: 0.0142 - mse: 3.9627e-04 - val_loss: 0.0045 - val_mae: 0.0432 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00182: val_mae did not improve from 0.04248\n",
      "Epoch 183/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 3.1383e-04 - mae: 0.0131 - mse: 3.1383e-04 - val_loss: 0.0044 - val_mae: 0.0430 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00183: val_mae did not improve from 0.04248\n",
      "Epoch 184/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 2.9713e-04 - mae: 0.0126 - mse: 2.9713e-04 - val_loss: 0.0044 - val_mae: 0.0428 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00184: val_mae did not improve from 0.04248\n",
      "Epoch 185/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 3.3600e-04 - mae: 0.0134 - mse: 3.3600e-04 - val_loss: 0.0044 - val_mae: 0.0429 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00185: val_mae did not improve from 0.04248\n",
      "Epoch 186/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 3.2177e-04 - mae: 0.0127 - mse: 3.2177e-04 - val_loss: 0.0045 - val_mae: 0.0433 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00186: val_mae did not improve from 0.04248\n",
      "Epoch 187/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 2.9895e-04 - mae: 0.0127 - mse: 2.9895e-04 - val_loss: 0.0045 - val_mae: 0.0434 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00187: val_mae did not improve from 0.04248\n",
      "Epoch 188/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 2.8081e-04 - mae: 0.0123 - mse: 2.8081e-04 - val_loss: 0.0044 - val_mae: 0.0430 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00188: val_mae did not improve from 0.04248\n",
      "Epoch 00188: early stopping\n",
      "Done fitting\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_all_outliers_jcw model created and file saved for future use.\n",
      "End model and train\n",
      "\n",
      "Opening file:  clean_duplicates.p\n",
      "cleantrain/clean_duplicates.p\n",
      "Train Shape: (6494, 31)\n",
      "Begin model and train:\n",
      "Model name: clean_duplicates_jcw\n",
      "Scaling 6494 images...\n",
      "Scaling of 6494 observations complete.\n",
      "Index(['left_eye_center_x', 'left_eye_center_y', 'right_eye_center_x',\n",
      "       'right_eye_center_y', 'nose_tip_x', 'nose_tip_y',\n",
      "       'mouth_center_bottom_lip_x', 'mouth_center_bottom_lip_y', 'image'],\n",
      "      dtype='object')\n",
      "Begining the split of Train with all features\n",
      "Looking for model JW\n",
      "JW model file not found. Model creation beginning\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 32, 32, 32)        288       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 8, 8, 64)          8192      \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 2, 2, 128)         32768     \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 2, 2, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 8)                 4104      \n",
      "=================================================================\n",
      "Total params: 374,952\n",
      "Trainable params: 374,504\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "None\n",
      "Done compiling\n",
      "Epoch 1/300\n",
      "162/162 [==============================] - 4s 19ms/step - loss: 0.1024 - mae: 0.1955 - mse: 0.1024 - val_loss: 0.0312 - val_mae: 0.1442 - val_mse: 0.0312\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 0.14415, saving model to data/models/clean_duplicates_jcw.h5\n",
      "Epoch 2/300\n",
      "162/162 [==============================] - 3s 18ms/step - loss: 0.0086 - mae: 0.0695 - mse: 0.0086 - val_loss: 0.0190 - val_mae: 0.1074 - val_mse: 0.0190\n",
      "\n",
      "Epoch 00002: val_mae improved from 0.14415 to 0.10745, saving model to data/models/clean_duplicates_jcw.h5\n",
      "Epoch 3/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.0073 - mae: 0.0631 - mse: 0.0073 - val_loss: 0.0095 - val_mae: 0.0710 - val_mse: 0.0095\n",
      "\n",
      "Epoch 00003: val_mae improved from 0.10745 to 0.07099, saving model to data/models/clean_duplicates_jcw.h5\n",
      "Epoch 4/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0062 - mae: 0.0576 - mse: 0.0062 - val_loss: 0.0080 - val_mae: 0.0647 - val_mse: 0.0080\n",
      "\n",
      "Epoch 00004: val_mae improved from 0.07099 to 0.06467, saving model to data/models/clean_duplicates_jcw.h5\n",
      "Epoch 5/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0059 - mae: 0.0559 - mse: 0.0059 - val_loss: 0.0075 - val_mae: 0.0618 - val_mse: 0.0075\n",
      "\n",
      "Epoch 00005: val_mae improved from 0.06467 to 0.06178, saving model to data/models/clean_duplicates_jcw.h5\n",
      "Epoch 6/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0053 - mae: 0.0527 - mse: 0.0053 - val_loss: 0.0077 - val_mae: 0.0630 - val_mse: 0.0077\n",
      "\n",
      "Epoch 00006: val_mae did not improve from 0.06178\n",
      "Epoch 7/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0051 - mae: 0.0516 - mse: 0.0051 - val_loss: 0.0070 - val_mae: 0.0600 - val_mse: 0.0070\n",
      "\n",
      "Epoch 00007: val_mae improved from 0.06178 to 0.06000, saving model to data/models/clean_duplicates_jcw.h5\n",
      "Epoch 8/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0048 - mae: 0.0505 - mse: 0.0048 - val_loss: 0.0077 - val_mae: 0.0631 - val_mse: 0.0077\n",
      "\n",
      "Epoch 00008: val_mae did not improve from 0.06000\n",
      "Epoch 9/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0044 - mae: 0.0482 - mse: 0.0044 - val_loss: 0.0074 - val_mae: 0.0612 - val_mse: 0.0074\n",
      "\n",
      "Epoch 00009: val_mae did not improve from 0.06000\n",
      "Epoch 10/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0040 - mae: 0.0462 - mse: 0.0040 - val_loss: 0.0075 - val_mae: 0.0615 - val_mse: 0.0075\n",
      "\n",
      "Epoch 00010: val_mae did not improve from 0.06000\n",
      "Epoch 11/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0037 - mae: 0.0453 - mse: 0.0037 - val_loss: 0.0074 - val_mae: 0.0610 - val_mse: 0.0074\n",
      "\n",
      "Epoch 00011: val_mae did not improve from 0.06000\n",
      "Epoch 12/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0035 - mae: 0.0438 - mse: 0.0035 - val_loss: 0.0071 - val_mae: 0.0594 - val_mse: 0.0071\n",
      "\n",
      "Epoch 00012: val_mae improved from 0.06000 to 0.05945, saving model to data/models/clean_duplicates_jcw.h5\n",
      "Epoch 13/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0032 - mae: 0.0421 - mse: 0.0032 - val_loss: 0.0071 - val_mae: 0.0596 - val_mse: 0.0071\n",
      "\n",
      "Epoch 00013: val_mae did not improve from 0.05945\n",
      "Epoch 14/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0030 - mae: 0.0409 - mse: 0.0030 - val_loss: 0.0069 - val_mae: 0.0583 - val_mse: 0.0069\n",
      "\n",
      "Epoch 00014: val_mae improved from 0.05945 to 0.05827, saving model to data/models/clean_duplicates_jcw.h5\n",
      "Epoch 15/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0029 - mae: 0.0403 - mse: 0.0029 - val_loss: 0.0070 - val_mae: 0.0585 - val_mse: 0.0070\n",
      "\n",
      "Epoch 00015: val_mae did not improve from 0.05827\n",
      "Epoch 16/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.0029 - mae: 0.0402 - mse: 0.0029 - val_loss: 0.0071 - val_mae: 0.0592 - val_mse: 0.0071\n",
      "\n",
      "Epoch 00016: val_mae did not improve from 0.05827\n",
      "Epoch 17/300\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.0027 - mae: 0.0393 - mse: 0.0027 - val_loss: 0.0074 - val_mae: 0.0601 - val_mse: 0.0074\n",
      "\n",
      "Epoch 00017: val_mae did not improve from 0.05827\n",
      "Epoch 18/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0028 - mae: 0.0389 - mse: 0.0028 - val_loss: 0.0073 - val_mae: 0.0594 - val_mse: 0.0073\n",
      "\n",
      "Epoch 00018: val_mae did not improve from 0.05827\n",
      "Epoch 19/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.0023 - mae: 0.0365 - mse: 0.0023 - val_loss: 0.0065 - val_mae: 0.0569 - val_mse: 0.0065\n",
      "\n",
      "Epoch 00019: val_mae improved from 0.05827 to 0.05688, saving model to data/models/clean_duplicates_jcw.h5\n",
      "Epoch 20/300\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.0025 - mae: 0.0377 - mse: 0.0025 - val_loss: 0.0072 - val_mae: 0.0602 - val_mse: 0.0072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00020: val_mae did not improve from 0.05688\n",
      "Epoch 21/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.0026 - mae: 0.0383 - mse: 0.0026 - val_loss: 0.0071 - val_mae: 0.0592 - val_mse: 0.0071\n",
      "\n",
      "Epoch 00021: val_mae did not improve from 0.05688\n",
      "Epoch 22/300\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.0022 - mae: 0.0357 - mse: 0.0022 - val_loss: 0.0066 - val_mae: 0.0567 - val_mse: 0.0066\n",
      "\n",
      "Epoch 00022: val_mae improved from 0.05688 to 0.05666, saving model to data/models/clean_duplicates_jcw.h5\n",
      "Epoch 23/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0022 - mae: 0.0355 - mse: 0.0022 - val_loss: 0.0070 - val_mae: 0.0592 - val_mse: 0.0070\n",
      "\n",
      "Epoch 00023: val_mae did not improve from 0.05666\n",
      "Epoch 24/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0022 - mae: 0.0352 - mse: 0.0022 - val_loss: 0.0063 - val_mae: 0.0545 - val_mse: 0.0063\n",
      "\n",
      "Epoch 00024: val_mae improved from 0.05666 to 0.05447, saving model to data/models/clean_duplicates_jcw.h5\n",
      "Epoch 25/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0022 - mae: 0.0356 - mse: 0.0022 - val_loss: 0.0062 - val_mae: 0.0543 - val_mse: 0.0062\n",
      "\n",
      "Epoch 00025: val_mae improved from 0.05447 to 0.05431, saving model to data/models/clean_duplicates_jcw.h5\n",
      "Epoch 26/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0019 - mae: 0.0330 - mse: 0.0019 - val_loss: 0.0065 - val_mae: 0.0555 - val_mse: 0.0065\n",
      "\n",
      "Epoch 00026: val_mae did not improve from 0.05431\n",
      "Epoch 27/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0018 - mae: 0.0319 - mse: 0.0018 - val_loss: 0.0065 - val_mae: 0.0553 - val_mse: 0.0065\n",
      "\n",
      "Epoch 00027: val_mae did not improve from 0.05431\n",
      "Epoch 28/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0022 - mae: 0.0350 - mse: 0.0022 - val_loss: 0.0068 - val_mae: 0.0582 - val_mse: 0.0068\n",
      "\n",
      "Epoch 00028: val_mae did not improve from 0.05431\n",
      "Epoch 29/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0020 - mae: 0.0339 - mse: 0.0020 - val_loss: 0.0072 - val_mae: 0.0598 - val_mse: 0.0072\n",
      "\n",
      "Epoch 00029: val_mae did not improve from 0.05431\n",
      "Epoch 30/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0024 - mae: 0.0360 - mse: 0.0024 - val_loss: 0.0066 - val_mae: 0.0560 - val_mse: 0.0066\n",
      "\n",
      "Epoch 00030: val_mae did not improve from 0.05431\n",
      "Epoch 31/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0020 - mae: 0.0335 - mse: 0.0020 - val_loss: 0.0064 - val_mae: 0.0551 - val_mse: 0.0064\n",
      "\n",
      "Epoch 00031: val_mae did not improve from 0.05431\n",
      "Epoch 32/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0023 - mae: 0.0331 - mse: 0.0023 - val_loss: 0.0062 - val_mae: 0.0543 - val_mse: 0.0062\n",
      "\n",
      "Epoch 00032: val_mae did not improve from 0.05431\n",
      "Epoch 33/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.0019 - mae: 0.0318 - mse: 0.0019 - val_loss: 0.0063 - val_mae: 0.0544 - val_mse: 0.0063\n",
      "\n",
      "Epoch 00033: val_mae did not improve from 0.05431\n",
      "Epoch 34/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0017 - mae: 0.0313 - mse: 0.0017 - val_loss: 0.0068 - val_mae: 0.0574 - val_mse: 0.0068\n",
      "\n",
      "Epoch 00034: val_mae did not improve from 0.05431\n",
      "Epoch 35/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.0017 - mae: 0.0308 - mse: 0.0017 - val_loss: 0.0060 - val_mae: 0.0529 - val_mse: 0.0060\n",
      "\n",
      "Epoch 00035: val_mae improved from 0.05431 to 0.05286, saving model to data/models/clean_duplicates_jcw.h5\n",
      "Epoch 36/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0018 - mae: 0.0309 - mse: 0.0018 - val_loss: 0.0061 - val_mae: 0.0531 - val_mse: 0.0061\n",
      "\n",
      "Epoch 00036: val_mae did not improve from 0.05286\n",
      "Epoch 37/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0016 - mae: 0.0303 - mse: 0.0016 - val_loss: 0.0059 - val_mae: 0.0523 - val_mse: 0.0059\n",
      "\n",
      "Epoch 00037: val_mae improved from 0.05286 to 0.05231, saving model to data/models/clean_duplicates_jcw.h5\n",
      "Epoch 38/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0016 - mae: 0.0303 - mse: 0.0016 - val_loss: 0.0060 - val_mae: 0.0528 - val_mse: 0.0060\n",
      "\n",
      "Epoch 00038: val_mae did not improve from 0.05231\n",
      "Epoch 39/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0020 - mae: 0.0319 - mse: 0.0020 - val_loss: 0.0063 - val_mae: 0.0549 - val_mse: 0.0063\n",
      "\n",
      "Epoch 00039: val_mae did not improve from 0.05231\n",
      "Epoch 40/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.0027 - mae: 0.0367 - mse: 0.0027 - val_loss: 0.0058 - val_mae: 0.0518 - val_mse: 0.0058\n",
      "\n",
      "Epoch 00040: val_mae improved from 0.05231 to 0.05179, saving model to data/models/clean_duplicates_jcw.h5\n",
      "Epoch 41/300\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.0018 - mae: 0.0311 - mse: 0.0018 - val_loss: 0.0057 - val_mae: 0.0514 - val_mse: 0.0057\n",
      "\n",
      "Epoch 00041: val_mae improved from 0.05179 to 0.05143, saving model to data/models/clean_duplicates_jcw.h5\n",
      "Epoch 42/300\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.0014 - mae: 0.0286 - mse: 0.0014 - val_loss: 0.0057 - val_mae: 0.0510 - val_mse: 0.0057\n",
      "\n",
      "Epoch 00042: val_mae improved from 0.05143 to 0.05100, saving model to data/models/clean_duplicates_jcw.h5\n",
      "Epoch 43/300\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.0017 - mae: 0.0303 - mse: 0.0017 - val_loss: 0.0060 - val_mae: 0.0533 - val_mse: 0.0060\n",
      "\n",
      "Epoch 00043: val_mae did not improve from 0.05100\n",
      "Epoch 44/300\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.0018 - mae: 0.0303 - mse: 0.0018 - val_loss: 0.0058 - val_mae: 0.0517 - val_mse: 0.0058\n",
      "\n",
      "Epoch 00044: val_mae did not improve from 0.05100\n",
      "Epoch 45/300\n",
      "162/162 [==============================] - 3s 22ms/step - loss: 0.0016 - mae: 0.0289 - mse: 0.0016 - val_loss: 0.0060 - val_mae: 0.0537 - val_mse: 0.0060\n",
      "\n",
      "Epoch 00045: val_mae did not improve from 0.05100\n",
      "Epoch 46/300\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.0013 - mae: 0.0274 - mse: 0.0013 - val_loss: 0.0055 - val_mae: 0.0498 - val_mse: 0.0055\n",
      "\n",
      "Epoch 00046: val_mae improved from 0.05100 to 0.04981, saving model to data/models/clean_duplicates_jcw.h5\n",
      "Epoch 47/300\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.0014 - mae: 0.0277 - mse: 0.0014 - val_loss: 0.0059 - val_mae: 0.0541 - val_mse: 0.0059\n",
      "\n",
      "Epoch 00047: val_mae did not improve from 0.04981\n",
      "Epoch 48/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.0018 - mae: 0.0304 - mse: 0.0018 - val_loss: 0.0057 - val_mae: 0.0511 - val_mse: 0.0057\n",
      "\n",
      "Epoch 00048: val_mae did not improve from 0.04981\n",
      "Epoch 49/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.0016 - mae: 0.0284 - mse: 0.0016 - val_loss: 0.0053 - val_mae: 0.0491 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00049: val_mae improved from 0.04981 to 0.04912, saving model to data/models/clean_duplicates_jcw.h5\n",
      "Epoch 50/300\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.0012 - mae: 0.0260 - mse: 0.0012 - val_loss: 0.0058 - val_mae: 0.0519 - val_mse: 0.0058\n",
      "\n",
      "Epoch 00050: val_mae did not improve from 0.04912\n",
      "Epoch 51/300\n",
      "162/162 [==============================] - 3s 22ms/step - loss: 0.0016 - mae: 0.0281 - mse: 0.0016 - val_loss: 0.0055 - val_mae: 0.0499 - val_mse: 0.0055\n",
      "\n",
      "Epoch 00051: val_mae did not improve from 0.04912\n",
      "Epoch 52/300\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.0011 - mae: 0.0250 - mse: 0.0011 - val_loss: 0.0055 - val_mae: 0.0493 - val_mse: 0.0055\n",
      "\n",
      "Epoch 00052: val_mae did not improve from 0.04912\n",
      "Epoch 53/300\n",
      "162/162 [==============================] - 3s 22ms/step - loss: 0.0012 - mae: 0.0258 - mse: 0.0012 - val_loss: 0.0056 - val_mae: 0.0511 - val_mse: 0.0056\n",
      "\n",
      "Epoch 00053: val_mae did not improve from 0.04912\n",
      "Epoch 54/300\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.0012 - mae: 0.0252 - mse: 0.0012 - val_loss: 0.0056 - val_mae: 0.0514 - val_mse: 0.0056\n",
      "\n",
      "Epoch 00054: val_mae did not improve from 0.04912\n",
      "Epoch 55/300\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.0013 - mae: 0.0267 - mse: 0.0013 - val_loss: 0.0058 - val_mae: 0.0521 - val_mse: 0.0058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00055: val_mae did not improve from 0.04912\n",
      "Epoch 56/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0012 - mae: 0.0256 - mse: 0.0012 - val_loss: 0.0065 - val_mae: 0.0560 - val_mse: 0.0065\n",
      "\n",
      "Epoch 00056: val_mae did not improve from 0.04912\n",
      "Epoch 57/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0015 - mae: 0.0274 - mse: 0.0015 - val_loss: 0.0055 - val_mae: 0.0503 - val_mse: 0.0055\n",
      "\n",
      "Epoch 00057: val_mae did not improve from 0.04912\n",
      "Epoch 58/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0013 - mae: 0.0249 - mse: 0.0013 - val_loss: 0.0057 - val_mae: 0.0513 - val_mse: 0.0057\n",
      "\n",
      "Epoch 00058: val_mae did not improve from 0.04912\n",
      "Epoch 59/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0012 - mae: 0.0247 - mse: 0.0012 - val_loss: 0.0059 - val_mae: 0.0515 - val_mse: 0.0059\n",
      "\n",
      "Epoch 00059: val_mae did not improve from 0.04912\n",
      "Epoch 60/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0012 - mae: 0.0252 - mse: 0.0012 - val_loss: 0.0054 - val_mae: 0.0490 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00060: val_mae improved from 0.04912 to 0.04898, saving model to data/models/clean_duplicates_jcw.h5\n",
      "Epoch 61/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.0011 - mae: 0.0244 - mse: 0.0011 - val_loss: 0.0055 - val_mae: 0.0499 - val_mse: 0.0055\n",
      "\n",
      "Epoch 00061: val_mae did not improve from 0.04898\n",
      "Epoch 62/300\n",
      "162/162 [==============================] - 3s 18ms/step - loss: 0.0011 - mae: 0.0240 - mse: 0.0011 - val_loss: 0.0057 - val_mae: 0.0515 - val_mse: 0.0057\n",
      "\n",
      "Epoch 00062: val_mae did not improve from 0.04898\n",
      "Epoch 63/300\n",
      "162/162 [==============================] - 3s 18ms/step - loss: 0.0017 - mae: 0.0290 - mse: 0.0017 - val_loss: 0.0057 - val_mae: 0.0508 - val_mse: 0.0057\n",
      "\n",
      "Epoch 00063: val_mae did not improve from 0.04898\n",
      "Epoch 64/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.0013 - mae: 0.0254 - mse: 0.0013 - val_loss: 0.0056 - val_mae: 0.0496 - val_mse: 0.0056\n",
      "\n",
      "Epoch 00064: val_mae did not improve from 0.04898\n",
      "Epoch 65/300\n",
      "162/162 [==============================] - 3s 18ms/step - loss: 0.0011 - mae: 0.0250 - mse: 0.0011 - val_loss: 0.0058 - val_mae: 0.0513 - val_mse: 0.0058\n",
      "\n",
      "Epoch 00065: val_mae did not improve from 0.04898\n",
      "Epoch 66/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.0012 - mae: 0.0257 - mse: 0.0012 - val_loss: 0.0051 - val_mae: 0.0478 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00066: val_mae improved from 0.04898 to 0.04784, saving model to data/models/clean_duplicates_jcw.h5\n",
      "Epoch 67/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 9.8492e-04 - mae: 0.0227 - mse: 9.8492e-04 - val_loss: 0.0054 - val_mae: 0.0488 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00067: val_mae did not improve from 0.04784\n",
      "Epoch 68/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 9.7895e-04 - mae: 0.0231 - mse: 9.7895e-04 - val_loss: 0.0055 - val_mae: 0.0495 - val_mse: 0.0055\n",
      "\n",
      "Epoch 00068: val_mae did not improve from 0.04784\n",
      "Epoch 69/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 9.9866e-04 - mae: 0.0228 - mse: 9.9866e-04 - val_loss: 0.0054 - val_mae: 0.0494 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00069: val_mae did not improve from 0.04784\n",
      "Epoch 70/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.0015 - mae: 0.0259 - mse: 0.0015 - val_loss: 0.0057 - val_mae: 0.0510 - val_mse: 0.0057\n",
      "\n",
      "Epoch 00070: val_mae did not improve from 0.04784\n",
      "Epoch 71/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.0011 - mae: 0.0248 - mse: 0.0011 - val_loss: 0.0055 - val_mae: 0.0498 - val_mse: 0.0055\n",
      "\n",
      "Epoch 00071: val_mae did not improve from 0.04784\n",
      "Epoch 72/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 9.4822e-04 - mae: 0.0230 - mse: 9.4822e-04 - val_loss: 0.0054 - val_mae: 0.0495 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00072: val_mae did not improve from 0.04784\n",
      "Epoch 73/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.0037 - mae: 0.0340 - mse: 0.0037 - val_loss: 0.0057 - val_mae: 0.0504 - val_mse: 0.0057\n",
      "\n",
      "Epoch 00073: val_mae did not improve from 0.04784\n",
      "Epoch 74/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.0015 - mae: 0.0265 - mse: 0.0015 - val_loss: 0.0054 - val_mae: 0.0487 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00074: val_mae did not improve from 0.04784\n",
      "Epoch 75/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.0010 - mae: 0.0234 - mse: 0.0010 - val_loss: 0.0052 - val_mae: 0.0482 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00075: val_mae did not improve from 0.04784\n",
      "Epoch 76/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 9.8431e-04 - mae: 0.0233 - mse: 9.8431e-04 - val_loss: 0.0052 - val_mae: 0.0479 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00076: val_mae did not improve from 0.04784\n",
      "Epoch 77/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 9.4320e-04 - mae: 0.0222 - mse: 9.4320e-04 - val_loss: 0.0052 - val_mae: 0.0478 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00077: val_mae improved from 0.04784 to 0.04777, saving model to data/models/clean_duplicates_jcw.h5\n",
      "Epoch 78/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 7.4400e-04 - mae: 0.0204 - mse: 7.4400e-04 - val_loss: 0.0054 - val_mae: 0.0488 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00078: val_mae did not improve from 0.04777\n",
      "Epoch 79/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 9.2860e-04 - mae: 0.0217 - mse: 9.2860e-04 - val_loss: 0.0052 - val_mae: 0.0480 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00079: val_mae did not improve from 0.04777\n",
      "Epoch 80/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 6.7114e-04 - mae: 0.0195 - mse: 6.7114e-04 - val_loss: 0.0052 - val_mae: 0.0479 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00080: val_mae did not improve from 0.04777\n",
      "Epoch 81/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 6.4814e-04 - mae: 0.0191 - mse: 6.4814e-04 - val_loss: 0.0053 - val_mae: 0.0484 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00081: val_mae did not improve from 0.04777\n",
      "Epoch 82/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 7.5752e-04 - mae: 0.0201 - mse: 7.5752e-04 - val_loss: 0.0050 - val_mae: 0.0469 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00082: val_mae improved from 0.04777 to 0.04694, saving model to data/models/clean_duplicates_jcw.h5\n",
      "Epoch 83/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 7.9386e-04 - mae: 0.0208 - mse: 7.9386e-04 - val_loss: 0.0051 - val_mae: 0.0472 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00083: val_mae did not improve from 0.04694\n",
      "Epoch 84/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 7.4137e-04 - mae: 0.0198 - mse: 7.4137e-04 - val_loss: 0.0054 - val_mae: 0.0493 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00084: val_mae did not improve from 0.04694\n",
      "Epoch 85/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 7.1657e-04 - mae: 0.0198 - mse: 7.1657e-04 - val_loss: 0.0053 - val_mae: 0.0486 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00085: val_mae did not improve from 0.04694\n",
      "Epoch 86/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 7.0268e-04 - mae: 0.0197 - mse: 7.0268e-04 - val_loss: 0.0054 - val_mae: 0.0490 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00086: val_mae did not improve from 0.04694\n",
      "Epoch 87/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 7.8246e-04 - mae: 0.0205 - mse: 7.8246e-04 - val_loss: 0.0053 - val_mae: 0.0484 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00087: val_mae did not improve from 0.04694\n",
      "Epoch 88/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 6.4772e-04 - mae: 0.0187 - mse: 6.4772e-04 - val_loss: 0.0051 - val_mae: 0.0477 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00088: val_mae did not improve from 0.04694\n",
      "Epoch 89/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 6.1967e-04 - mae: 0.0186 - mse: 6.1967e-04 - val_loss: 0.0052 - val_mae: 0.0477 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00089: val_mae did not improve from 0.04694\n",
      "Epoch 90/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 6.7283e-04 - mae: 0.0193 - mse: 6.7283e-04 - val_loss: 0.0052 - val_mae: 0.0476 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00090: val_mae did not improve from 0.04694\n",
      "Epoch 91/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 6.1781e-04 - mae: 0.0187 - mse: 6.1781e-04 - val_loss: 0.0050 - val_mae: 0.0467 - val_mse: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00091: val_mae improved from 0.04694 to 0.04668, saving model to data/models/clean_duplicates_jcw.h5\n",
      "Epoch 92/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 7.0063e-04 - mae: 0.0196 - mse: 7.0063e-04 - val_loss: 0.0055 - val_mae: 0.0495 - val_mse: 0.0055\n",
      "\n",
      "Epoch 00092: val_mae did not improve from 0.04668\n",
      "Epoch 93/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 6.9054e-04 - mae: 0.0195 - mse: 6.9054e-04 - val_loss: 0.0051 - val_mae: 0.0478 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00093: val_mae did not improve from 0.04668\n",
      "Epoch 94/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 8.0744e-04 - mae: 0.0199 - mse: 8.0744e-04 - val_loss: 0.0053 - val_mae: 0.0483 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00094: val_mae did not improve from 0.04668\n",
      "Epoch 95/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 6.8065e-04 - mae: 0.0191 - mse: 6.8065e-04 - val_loss: 0.0050 - val_mae: 0.0471 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00095: val_mae did not improve from 0.04668\n",
      "Epoch 96/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 5.8717e-04 - mae: 0.0180 - mse: 5.8717e-04 - val_loss: 0.0054 - val_mae: 0.0491 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00096: val_mae did not improve from 0.04668\n",
      "Epoch 97/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.0020 - mae: 0.0320 - mse: 0.0020 - val_loss: 0.0054 - val_mae: 0.0486 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00097: val_mae did not improve from 0.04668\n",
      "Epoch 98/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.0014 - mae: 0.0253 - mse: 0.0014 - val_loss: 0.0050 - val_mae: 0.0471 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00098: val_mae did not improve from 0.04668\n",
      "Epoch 99/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 9.3537e-04 - mae: 0.0218 - mse: 9.3537e-04 - val_loss: 0.0050 - val_mae: 0.0470 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00099: val_mae did not improve from 0.04668\n",
      "Epoch 100/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 7.2364e-04 - mae: 0.0198 - mse: 7.2364e-04 - val_loss: 0.0051 - val_mae: 0.0470 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00100: val_mae did not improve from 0.04668\n",
      "Epoch 101/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 6.3062e-04 - mae: 0.0188 - mse: 6.3062e-04 - val_loss: 0.0050 - val_mae: 0.0472 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00101: val_mae did not improve from 0.04668\n",
      "Epoch 102/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 6.5500e-04 - mae: 0.0181 - mse: 6.5500e-04 - val_loss: 0.0049 - val_mae: 0.0460 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00102: val_mae improved from 0.04668 to 0.04603, saving model to data/models/clean_duplicates_jcw.h5\n",
      "Epoch 103/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 5.9265e-04 - mae: 0.0177 - mse: 5.9265e-04 - val_loss: 0.0051 - val_mae: 0.0473 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00103: val_mae did not improve from 0.04603\n",
      "Epoch 104/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 6.7071e-04 - mae: 0.0190 - mse: 6.7071e-04 - val_loss: 0.0051 - val_mae: 0.0476 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00104: val_mae did not improve from 0.04603\n",
      "Epoch 105/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 7.6104e-04 - mae: 0.0182 - mse: 7.6104e-04 - val_loss: 0.0049 - val_mae: 0.0463 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00105: val_mae did not improve from 0.04603\n",
      "Epoch 106/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 5.2711e-04 - mae: 0.0171 - mse: 5.2711e-04 - val_loss: 0.0051 - val_mae: 0.0469 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00106: val_mae did not improve from 0.04603\n",
      "Epoch 107/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 4.9202e-04 - mae: 0.0164 - mse: 4.9202e-04 - val_loss: 0.0050 - val_mae: 0.0472 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00107: val_mae did not improve from 0.04603\n",
      "Epoch 108/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 7.4692e-04 - mae: 0.0194 - mse: 7.4692e-04 - val_loss: 0.0050 - val_mae: 0.0469 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00108: val_mae did not improve from 0.04603\n",
      "Epoch 109/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 5.4863e-04 - mae: 0.0171 - mse: 5.4863e-04 - val_loss: 0.0049 - val_mae: 0.0463 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00109: val_mae did not improve from 0.04603\n",
      "Epoch 110/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 5.7890e-04 - mae: 0.0176 - mse: 5.7890e-04 - val_loss: 0.0050 - val_mae: 0.0464 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00110: val_mae did not improve from 0.04603\n",
      "Epoch 111/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 5.7235e-04 - mae: 0.0178 - mse: 5.7235e-04 - val_loss: 0.0049 - val_mae: 0.0462 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00111: val_mae did not improve from 0.04603\n",
      "Epoch 112/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 7.5297e-04 - mae: 0.0202 - mse: 7.5297e-04 - val_loss: 0.0052 - val_mae: 0.0480 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00112: val_mae did not improve from 0.04603\n",
      "Epoch 113/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 7.0609e-04 - mae: 0.0195 - mse: 7.0609e-04 - val_loss: 0.0050 - val_mae: 0.0468 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00113: val_mae did not improve from 0.04603\n",
      "Epoch 114/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 5.4668e-04 - mae: 0.0175 - mse: 5.4668e-04 - val_loss: 0.0047 - val_mae: 0.0453 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00114: val_mae improved from 0.04603 to 0.04526, saving model to data/models/clean_duplicates_jcw.h5\n",
      "Epoch 115/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 4.9838e-04 - mae: 0.0168 - mse: 4.9838e-04 - val_loss: 0.0049 - val_mae: 0.0460 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00115: val_mae did not improve from 0.04526\n",
      "Epoch 116/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 4.7527e-04 - mae: 0.0163 - mse: 4.7527e-04 - val_loss: 0.0049 - val_mae: 0.0462 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00116: val_mae did not improve from 0.04526\n",
      "Epoch 117/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 5.2940e-04 - mae: 0.0169 - mse: 5.2940e-04 - val_loss: 0.0050 - val_mae: 0.0470 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00117: val_mae did not improve from 0.04526\n",
      "Epoch 118/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 5.3220e-04 - mae: 0.0170 - mse: 5.3220e-04 - val_loss: 0.0050 - val_mae: 0.0466 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00118: val_mae did not improve from 0.04526\n",
      "Epoch 119/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 5.1226e-04 - mae: 0.0169 - mse: 5.1226e-04 - val_loss: 0.0050 - val_mae: 0.0471 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00119: val_mae did not improve from 0.04526\n",
      "Epoch 120/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 7.2636e-04 - mae: 0.0195 - mse: 7.2636e-04 - val_loss: 0.0050 - val_mae: 0.0465 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00120: val_mae did not improve from 0.04526\n",
      "Epoch 121/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 5.7670e-04 - mae: 0.0176 - mse: 5.7670e-04 - val_loss: 0.0048 - val_mae: 0.0455 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00121: val_mae did not improve from 0.04526\n",
      "Epoch 122/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 5.5196e-04 - mae: 0.0169 - mse: 5.5196e-04 - val_loss: 0.0050 - val_mae: 0.0468 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00122: val_mae did not improve from 0.04526\n",
      "Epoch 123/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 5.9510e-04 - mae: 0.0169 - mse: 5.9510e-04 - val_loss: 0.0050 - val_mae: 0.0464 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00123: val_mae did not improve from 0.04526\n",
      "Epoch 124/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 6.0823e-04 - mae: 0.0175 - mse: 6.0823e-04 - val_loss: 0.0050 - val_mae: 0.0468 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00124: val_mae did not improve from 0.04526\n",
      "Epoch 125/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 5.8008e-04 - mae: 0.0173 - mse: 5.8008e-04 - val_loss: 0.0049 - val_mae: 0.0463 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00125: val_mae did not improve from 0.04526\n",
      "Epoch 126/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 4.7121e-04 - mae: 0.0161 - mse: 4.7121e-04 - val_loss: 0.0049 - val_mae: 0.0461 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00126: val_mae did not improve from 0.04526\n",
      "Epoch 127/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 3s 20ms/step - loss: 4.8315e-04 - mae: 0.0165 - mse: 4.8315e-04 - val_loss: 0.0050 - val_mae: 0.0466 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00127: val_mae did not improve from 0.04526\n",
      "Epoch 128/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 4.8343e-04 - mae: 0.0167 - mse: 4.8343e-04 - val_loss: 0.0050 - val_mae: 0.0470 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00128: val_mae did not improve from 0.04526\n",
      "Epoch 129/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 4.9602e-04 - mae: 0.0165 - mse: 4.9602e-04 - val_loss: 0.0048 - val_mae: 0.0454 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00129: val_mae did not improve from 0.04526\n",
      "Epoch 130/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 5.2778e-04 - mae: 0.0167 - mse: 5.2778e-04 - val_loss: 0.0050 - val_mae: 0.0463 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00130: val_mae did not improve from 0.04526\n",
      "Epoch 131/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 5.4750e-04 - mae: 0.0165 - mse: 5.4750e-04 - val_loss: 0.0051 - val_mae: 0.0469 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00131: val_mae did not improve from 0.04526\n",
      "Epoch 132/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 5.2485e-04 - mae: 0.0169 - mse: 5.2485e-04 - val_loss: 0.0049 - val_mae: 0.0457 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00132: val_mae did not improve from 0.04526\n",
      "Epoch 133/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 5.6756e-04 - mae: 0.0172 - mse: 5.6756e-04 - val_loss: 0.0050 - val_mae: 0.0463 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00133: val_mae did not improve from 0.04526\n",
      "Epoch 134/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 6.9928e-04 - mae: 0.0188 - mse: 6.9928e-04 - val_loss: 0.0050 - val_mae: 0.0468 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00134: val_mae did not improve from 0.04526\n",
      "Epoch 135/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 5.5291e-04 - mae: 0.0173 - mse: 5.5291e-04 - val_loss: 0.0050 - val_mae: 0.0469 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00135: val_mae did not improve from 0.04526\n",
      "Epoch 136/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 7.8481e-04 - mae: 0.0187 - mse: 7.8481e-04 - val_loss: 0.0050 - val_mae: 0.0471 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00136: val_mae did not improve from 0.04526\n",
      "Epoch 137/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 5.8141e-04 - mae: 0.0172 - mse: 5.8141e-04 - val_loss: 0.0049 - val_mae: 0.0458 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00137: val_mae did not improve from 0.04526\n",
      "Epoch 138/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 4.9386e-04 - mae: 0.0163 - mse: 4.9386e-04 - val_loss: 0.0050 - val_mae: 0.0466 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00138: val_mae did not improve from 0.04526\n",
      "Epoch 139/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 4.5798e-04 - mae: 0.0155 - mse: 4.5798e-04 - val_loss: 0.0049 - val_mae: 0.0461 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00139: val_mae did not improve from 0.04526\n",
      "Epoch 140/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 4.4249e-04 - mae: 0.0151 - mse: 4.4249e-04 - val_loss: 0.0047 - val_mae: 0.0449 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00140: val_mae improved from 0.04526 to 0.04492, saving model to data/models/clean_duplicates_jcw.h5\n",
      "Epoch 141/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 3.8332e-04 - mae: 0.0146 - mse: 3.8332e-04 - val_loss: 0.0048 - val_mae: 0.0450 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00141: val_mae did not improve from 0.04492\n",
      "Epoch 142/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 4.0666e-04 - mae: 0.0149 - mse: 4.0666e-04 - val_loss: 0.0049 - val_mae: 0.0461 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00142: val_mae did not improve from 0.04492\n",
      "Epoch 143/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 4.4318e-04 - mae: 0.0157 - mse: 4.4318e-04 - val_loss: 0.0049 - val_mae: 0.0460 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00143: val_mae did not improve from 0.04492\n",
      "Epoch 144/300\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 3.9946e-04 - mae: 0.0146 - mse: 3.9946e-04 - val_loss: 0.0049 - val_mae: 0.0460 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00144: val_mae did not improve from 0.04492\n",
      "Epoch 145/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 4.9546e-04 - mae: 0.0156 - mse: 4.9546e-04 - val_loss: 0.0048 - val_mae: 0.0455 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00145: val_mae did not improve from 0.04492\n",
      "Epoch 146/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 4.0758e-04 - mae: 0.0148 - mse: 4.0758e-04 - val_loss: 0.0048 - val_mae: 0.0455 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00146: val_mae did not improve from 0.04492\n",
      "Epoch 147/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 4.4067e-04 - mae: 0.0152 - mse: 4.4067e-04 - val_loss: 0.0051 - val_mae: 0.0475 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00147: val_mae did not improve from 0.04492\n",
      "Epoch 148/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 4.3238e-04 - mae: 0.0152 - mse: 4.3238e-04 - val_loss: 0.0048 - val_mae: 0.0452 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00148: val_mae did not improve from 0.04492\n",
      "Epoch 149/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 4.0610e-04 - mae: 0.0152 - mse: 4.0610e-04 - val_loss: 0.0047 - val_mae: 0.0452 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00149: val_mae did not improve from 0.04492\n",
      "Epoch 150/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 4.8447e-04 - mae: 0.0163 - mse: 4.8447e-04 - val_loss: 0.0051 - val_mae: 0.0471 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00150: val_mae did not improve from 0.04492\n",
      "Epoch 151/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 4.5224e-04 - mae: 0.0152 - mse: 4.5224e-04 - val_loss: 0.0049 - val_mae: 0.0461 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00151: val_mae did not improve from 0.04492\n",
      "Epoch 152/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 4.6458e-04 - mae: 0.0159 - mse: 4.6458e-04 - val_loss: 0.0049 - val_mae: 0.0460 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00152: val_mae did not improve from 0.04492\n",
      "Epoch 153/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 3.9900e-04 - mae: 0.0149 - mse: 3.9900e-04 - val_loss: 0.0050 - val_mae: 0.0466 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00153: val_mae did not improve from 0.04492\n",
      "Epoch 154/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 4.6423e-04 - mae: 0.0153 - mse: 4.6423e-04 - val_loss: 0.0046 - val_mae: 0.0449 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00154: val_mae improved from 0.04492 to 0.04490, saving model to data/models/clean_duplicates_jcw.h5\n",
      "Epoch 155/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 3.8389e-04 - mae: 0.0147 - mse: 3.8389e-04 - val_loss: 0.0049 - val_mae: 0.0457 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00155: val_mae did not improve from 0.04490\n",
      "Epoch 156/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 4.5118e-04 - mae: 0.0156 - mse: 4.5118e-04 - val_loss: 0.0050 - val_mae: 0.0463 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00156: val_mae did not improve from 0.04490\n",
      "Epoch 157/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 4.9087e-04 - mae: 0.0157 - mse: 4.9087e-04 - val_loss: 0.0051 - val_mae: 0.0473 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00157: val_mae did not improve from 0.04490\n",
      "Epoch 158/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 5.6921e-04 - mae: 0.0173 - mse: 5.6921e-04 - val_loss: 0.0049 - val_mae: 0.0459 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00158: val_mae did not improve from 0.04490\n",
      "Epoch 159/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 4.9085e-04 - mae: 0.0157 - mse: 4.9085e-04 - val_loss: 0.0049 - val_mae: 0.0462 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00159: val_mae did not improve from 0.04490\n",
      "Epoch 160/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 4.1438e-04 - mae: 0.0152 - mse: 4.1438e-04 - val_loss: 0.0048 - val_mae: 0.0456 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00160: val_mae did not improve from 0.04490\n",
      "Epoch 161/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 4.1550e-04 - mae: 0.0149 - mse: 4.1550e-04 - val_loss: 0.0049 - val_mae: 0.0458 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00161: val_mae did not improve from 0.04490\n",
      "Epoch 162/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 3.5721e-04 - mae: 0.0138 - mse: 3.5721e-04 - val_loss: 0.0047 - val_mae: 0.0450 - val_mse: 0.0047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00162: val_mae did not improve from 0.04490\n",
      "Epoch 163/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 5.3686e-04 - mae: 0.0163 - mse: 5.3686e-04 - val_loss: 0.0049 - val_mae: 0.0461 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00163: val_mae did not improve from 0.04490\n",
      "Epoch 164/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 4.2214e-04 - mae: 0.0150 - mse: 4.2214e-04 - val_loss: 0.0049 - val_mae: 0.0458 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00164: val_mae did not improve from 0.04490\n",
      "Epoch 165/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 4.3623e-04 - mae: 0.0147 - mse: 4.3623e-04 - val_loss: 0.0048 - val_mae: 0.0449 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00165: val_mae improved from 0.04490 to 0.04488, saving model to data/models/clean_duplicates_jcw.h5\n",
      "Epoch 166/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 4.0988e-04 - mae: 0.0146 - mse: 4.0988e-04 - val_loss: 0.0048 - val_mae: 0.0454 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00166: val_mae did not improve from 0.04488\n",
      "Epoch 167/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 3.9650e-04 - mae: 0.0146 - mse: 3.9650e-04 - val_loss: 0.0049 - val_mae: 0.0459 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00167: val_mae did not improve from 0.04488\n",
      "Epoch 168/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 3.6139e-04 - mae: 0.0139 - mse: 3.6139e-04 - val_loss: 0.0048 - val_mae: 0.0456 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00168: val_mae did not improve from 0.04488\n",
      "Epoch 169/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 3.1535e-04 - mae: 0.0133 - mse: 3.1535e-04 - val_loss: 0.0048 - val_mae: 0.0453 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00169: val_mae did not improve from 0.04488\n",
      "Epoch 170/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 3.0571e-04 - mae: 0.0131 - mse: 3.0571e-04 - val_loss: 0.0047 - val_mae: 0.0448 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00170: val_mae improved from 0.04488 to 0.04481, saving model to data/models/clean_duplicates_jcw.h5\n",
      "Epoch 171/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 4.0940e-04 - mae: 0.0140 - mse: 4.0940e-04 - val_loss: 0.0048 - val_mae: 0.0452 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00171: val_mae did not improve from 0.04481\n",
      "Epoch 172/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 3.4270e-04 - mae: 0.0136 - mse: 3.4270e-04 - val_loss: 0.0048 - val_mae: 0.0457 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00172: val_mae did not improve from 0.04481\n",
      "Epoch 173/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 3.2337e-04 - mae: 0.0134 - mse: 3.2337e-04 - val_loss: 0.0048 - val_mae: 0.0452 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00173: val_mae did not improve from 0.04481\n",
      "Epoch 174/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 3.8543e-04 - mae: 0.0144 - mse: 3.8543e-04 - val_loss: 0.0048 - val_mae: 0.0454 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00174: val_mae did not improve from 0.04481\n",
      "Epoch 175/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 3.8756e-04 - mae: 0.0146 - mse: 3.8756e-04 - val_loss: 0.0049 - val_mae: 0.0456 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00175: val_mae did not improve from 0.04481\n",
      "Epoch 176/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 4.1818e-04 - mae: 0.0143 - mse: 4.1818e-04 - val_loss: 0.0048 - val_mae: 0.0454 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00176: val_mae did not improve from 0.04481\n",
      "Epoch 177/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 4.0953e-04 - mae: 0.0148 - mse: 4.0953e-04 - val_loss: 0.0048 - val_mae: 0.0456 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00177: val_mae did not improve from 0.04481\n",
      "Epoch 178/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 3.8069e-04 - mae: 0.0143 - mse: 3.8069e-04 - val_loss: 0.0049 - val_mae: 0.0457 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00178: val_mae did not improve from 0.04481\n",
      "Epoch 179/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 3.6130e-04 - mae: 0.0140 - mse: 3.6130e-04 - val_loss: 0.0049 - val_mae: 0.0460 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00179: val_mae did not improve from 0.04481\n",
      "Epoch 180/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 4.1055e-04 - mae: 0.0147 - mse: 4.1055e-04 - val_loss: 0.0051 - val_mae: 0.0463 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00180: val_mae did not improve from 0.04481\n",
      "Epoch 181/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 3.8696e-04 - mae: 0.0142 - mse: 3.8696e-04 - val_loss: 0.0049 - val_mae: 0.0456 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00181: val_mae did not improve from 0.04481\n",
      "Epoch 182/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 3.7738e-04 - mae: 0.0142 - mse: 3.7738e-04 - val_loss: 0.0049 - val_mae: 0.0461 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00182: val_mae did not improve from 0.04481\n",
      "Epoch 183/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 3.3497e-04 - mae: 0.0136 - mse: 3.3497e-04 - val_loss: 0.0048 - val_mae: 0.0453 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00183: val_mae did not improve from 0.04481\n",
      "Epoch 184/300\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 3.8200e-04 - mae: 0.0139 - mse: 3.8200e-04 - val_loss: 0.0047 - val_mae: 0.0444 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00184: val_mae improved from 0.04481 to 0.04443, saving model to data/models/clean_duplicates_jcw.h5\n",
      "Epoch 00184: early stopping\n",
      "Done fitting\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_duplicates_jcw model created and file saved for future use.\n",
      "End model and train\n",
      "\n",
      "Opening file:  clean_o_outliers.p\n",
      "cleantrain/clean_o_outliers.p\n",
      "Train Shape: (7020, 31)\n",
      "Begin model and train:\n",
      "Model name: clean_o_outliers_jcw\n",
      "Scaling 7020 images...\n",
      "Scaling of 7020 observations complete.\n",
      "Index(['left_eye_center_x', 'left_eye_center_y', 'right_eye_center_x',\n",
      "       'right_eye_center_y', 'nose_tip_x', 'nose_tip_y',\n",
      "       'mouth_center_bottom_lip_x', 'mouth_center_bottom_lip_y', 'image'],\n",
      "      dtype='object')\n",
      "Begining the split of Train with all features\n",
      "Looking for model JW\n",
      "JW model file not found. Model creation beginning\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_27 (Conv2D)           (None, 32, 32, 32)        288       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 8, 8, 64)          8192      \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 2, 2, 128)         32768     \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 2, 2, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 8)                 4104      \n",
      "=================================================================\n",
      "Total params: 374,952\n",
      "Trainable params: 374,504\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "None\n",
      "Done compiling\n",
      "Epoch 1/300\n",
      "175/175 [==============================] - 4s 19ms/step - loss: 0.0920 - mae: 0.1828 - mse: 0.0920 - val_loss: 0.0224 - val_mae: 0.1201 - val_mse: 0.0224\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 0.12008, saving model to data/models/clean_o_outliers_jcw.h5\n",
      "Epoch 2/300\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0084 - mae: 0.0694 - mse: 0.0084 - val_loss: 0.0122 - val_mae: 0.0862 - val_mse: 0.0122\n",
      "\n",
      "Epoch 00002: val_mae improved from 0.12008 to 0.08619, saving model to data/models/clean_o_outliers_jcw.h5\n",
      "Epoch 3/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0071 - mae: 0.0623 - mse: 0.0071 - val_loss: 0.0087 - val_mae: 0.0683 - val_mse: 0.0087\n",
      "\n",
      "Epoch 00003: val_mae improved from 0.08619 to 0.06832, saving model to data/models/clean_o_outliers_jcw.h5\n",
      "Epoch 4/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0060 - mae: 0.0569 - mse: 0.0060 - val_loss: 0.0073 - val_mae: 0.0620 - val_mse: 0.0073\n",
      "\n",
      "Epoch 00004: val_mae improved from 0.06832 to 0.06196, saving model to data/models/clean_o_outliers_jcw.h5\n",
      "Epoch 5/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0058 - mae: 0.0549 - mse: 0.0058 - val_loss: 0.0071 - val_mae: 0.0604 - val_mse: 0.0071\n",
      "\n",
      "Epoch 00005: val_mae improved from 0.06196 to 0.06037, saving model to data/models/clean_o_outliers_jcw.h5\n",
      "Epoch 6/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0050 - mae: 0.0510 - mse: 0.0050 - val_loss: 0.0068 - val_mae: 0.0584 - val_mse: 0.0068\n",
      "\n",
      "Epoch 00006: val_mae improved from 0.06037 to 0.05838, saving model to data/models/clean_o_outliers_jcw.h5\n",
      "Epoch 7/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0043 - mae: 0.0484 - mse: 0.0043 - val_loss: 0.0069 - val_mae: 0.0597 - val_mse: 0.0069\n",
      "\n",
      "Epoch 00007: val_mae did not improve from 0.05838\n",
      "Epoch 8/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0041 - mae: 0.0474 - mse: 0.0041 - val_loss: 0.0068 - val_mae: 0.0589 - val_mse: 0.0068\n",
      "\n",
      "Epoch 00008: val_mae did not improve from 0.05838\n",
      "Epoch 9/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0038 - mae: 0.0455 - mse: 0.0038 - val_loss: 0.0067 - val_mae: 0.0581 - val_mse: 0.0067\n",
      "\n",
      "Epoch 00009: val_mae improved from 0.05838 to 0.05814, saving model to data/models/clean_o_outliers_jcw.h5\n",
      "Epoch 10/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0036 - mae: 0.0445 - mse: 0.0036 - val_loss: 0.0066 - val_mae: 0.0577 - val_mse: 0.0066\n",
      "\n",
      "Epoch 00010: val_mae improved from 0.05814 to 0.05766, saving model to data/models/clean_o_outliers_jcw.h5\n",
      "Epoch 11/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0033 - mae: 0.0431 - mse: 0.0033 - val_loss: 0.0066 - val_mae: 0.0574 - val_mse: 0.0066\n",
      "\n",
      "Epoch 00011: val_mae improved from 0.05766 to 0.05744, saving model to data/models/clean_o_outliers_jcw.h5\n",
      "Epoch 12/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0030 - mae: 0.0412 - mse: 0.0030 - val_loss: 0.0066 - val_mae: 0.0571 - val_mse: 0.0066\n",
      "\n",
      "Epoch 00012: val_mae improved from 0.05744 to 0.05707, saving model to data/models/clean_o_outliers_jcw.h5\n",
      "Epoch 13/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0028 - mae: 0.0399 - mse: 0.0028 - val_loss: 0.0062 - val_mae: 0.0554 - val_mse: 0.0062\n",
      "\n",
      "Epoch 00013: val_mae improved from 0.05707 to 0.05541, saving model to data/models/clean_o_outliers_jcw.h5\n",
      "Epoch 14/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0026 - mae: 0.0384 - mse: 0.0026 - val_loss: 0.0060 - val_mae: 0.0546 - val_mse: 0.0060\n",
      "\n",
      "Epoch 00014: val_mae improved from 0.05541 to 0.05459, saving model to data/models/clean_o_outliers_jcw.h5\n",
      "Epoch 15/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0026 - mae: 0.0383 - mse: 0.0026 - val_loss: 0.0061 - val_mae: 0.0544 - val_mse: 0.0061\n",
      "\n",
      "Epoch 00015: val_mae improved from 0.05459 to 0.05436, saving model to data/models/clean_o_outliers_jcw.h5\n",
      "Epoch 16/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0025 - mae: 0.0374 - mse: 0.0025 - val_loss: 0.0061 - val_mae: 0.0544 - val_mse: 0.0061\n",
      "\n",
      "Epoch 00016: val_mae improved from 0.05436 to 0.05436, saving model to data/models/clean_o_outliers_jcw.h5\n",
      "Epoch 17/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0024 - mae: 0.0370 - mse: 0.0024 - val_loss: 0.0069 - val_mae: 0.0580 - val_mse: 0.0069\n",
      "\n",
      "Epoch 00017: val_mae did not improve from 0.05436\n",
      "Epoch 18/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0024 - mae: 0.0364 - mse: 0.0024 - val_loss: 0.0059 - val_mae: 0.0530 - val_mse: 0.0059\n",
      "\n",
      "Epoch 00018: val_mae improved from 0.05436 to 0.05302, saving model to data/models/clean_o_outliers_jcw.h5\n",
      "Epoch 19/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0022 - mae: 0.0354 - mse: 0.0022 - val_loss: 0.0064 - val_mae: 0.0553 - val_mse: 0.0064\n",
      "\n",
      "Epoch 00019: val_mae did not improve from 0.05302\n",
      "Epoch 20/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0021 - mae: 0.0350 - mse: 0.0021 - val_loss: 0.0064 - val_mae: 0.0570 - val_mse: 0.0064\n",
      "\n",
      "Epoch 00020: val_mae did not improve from 0.05302\n",
      "Epoch 21/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0024 - mae: 0.0367 - mse: 0.0024 - val_loss: 0.0065 - val_mae: 0.0564 - val_mse: 0.0065\n",
      "\n",
      "Epoch 00021: val_mae did not improve from 0.05302\n",
      "Epoch 22/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0024 - mae: 0.0362 - mse: 0.0024 - val_loss: 0.0057 - val_mae: 0.0519 - val_mse: 0.0057\n",
      "\n",
      "Epoch 00022: val_mae improved from 0.05302 to 0.05193, saving model to data/models/clean_o_outliers_jcw.h5\n",
      "Epoch 23/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0021 - mae: 0.0339 - mse: 0.0021 - val_loss: 0.0056 - val_mae: 0.0515 - val_mse: 0.0056\n",
      "\n",
      "Epoch 00023: val_mae improved from 0.05193 to 0.05149, saving model to data/models/clean_o_outliers_jcw.h5\n",
      "Epoch 24/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0019 - mae: 0.0329 - mse: 0.0019 - val_loss: 0.0057 - val_mae: 0.0529 - val_mse: 0.0057\n",
      "\n",
      "Epoch 00024: val_mae did not improve from 0.05149\n",
      "Epoch 25/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0019 - mae: 0.0327 - mse: 0.0019 - val_loss: 0.0060 - val_mae: 0.0533 - val_mse: 0.0060\n",
      "\n",
      "Epoch 00025: val_mae did not improve from 0.05149\n",
      "Epoch 26/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0019 - mae: 0.0333 - mse: 0.0019 - val_loss: 0.0058 - val_mae: 0.0528 - val_mse: 0.0058\n",
      "\n",
      "Epoch 00026: val_mae did not improve from 0.05149\n",
      "Epoch 27/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0019 - mae: 0.0322 - mse: 0.0019 - val_loss: 0.0057 - val_mae: 0.0520 - val_mse: 0.0057\n",
      "\n",
      "Epoch 00027: val_mae did not improve from 0.05149\n",
      "Epoch 28/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0019 - mae: 0.0325 - mse: 0.0019 - val_loss: 0.0055 - val_mae: 0.0507 - val_mse: 0.0055\n",
      "\n",
      "Epoch 00028: val_mae improved from 0.05149 to 0.05068, saving model to data/models/clean_o_outliers_jcw.h5\n",
      "Epoch 29/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0018 - mae: 0.0318 - mse: 0.0018 - val_loss: 0.0062 - val_mae: 0.0538 - val_mse: 0.0062\n",
      "\n",
      "Epoch 00029: val_mae did not improve from 0.05068\n",
      "Epoch 30/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0017 - mae: 0.0305 - mse: 0.0017 - val_loss: 0.0056 - val_mae: 0.0519 - val_mse: 0.0056\n",
      "\n",
      "Epoch 00030: val_mae did not improve from 0.05068\n",
      "Epoch 31/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0020 - mae: 0.0333 - mse: 0.0020 - val_loss: 0.0055 - val_mae: 0.0510 - val_mse: 0.0055\n",
      "\n",
      "Epoch 00031: val_mae did not improve from 0.05068\n",
      "Epoch 32/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0018 - mae: 0.0317 - mse: 0.0018 - val_loss: 0.0054 - val_mae: 0.0505 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00032: val_mae improved from 0.05068 to 0.05055, saving model to data/models/clean_o_outliers_jcw.h5\n",
      "Epoch 33/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0018 - mae: 0.0311 - mse: 0.0018 - val_loss: 0.0059 - val_mae: 0.0528 - val_mse: 0.0059\n",
      "\n",
      "Epoch 00033: val_mae did not improve from 0.05055\n",
      "Epoch 34/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0019 - mae: 0.0315 - mse: 0.0019 - val_loss: 0.0052 - val_mae: 0.0489 - val_mse: 0.0052\n",
      "\n",
      "Epoch 00034: val_mae improved from 0.05055 to 0.04887, saving model to data/models/clean_o_outliers_jcw.h5\n",
      "Epoch 35/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0019 - mae: 0.0309 - mse: 0.0019 - val_loss: 0.0054 - val_mae: 0.0492 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00035: val_mae did not improve from 0.04887\n",
      "Epoch 36/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0014 - mae: 0.0282 - mse: 0.0014 - val_loss: 0.0054 - val_mae: 0.0494 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00036: val_mae did not improve from 0.04887\n",
      "Epoch 37/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0016 - mae: 0.0300 - mse: 0.0016 - val_loss: 0.0055 - val_mae: 0.0497 - val_mse: 0.0055\n",
      "\n",
      "Epoch 00037: val_mae did not improve from 0.04887\n",
      "Epoch 38/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0016 - mae: 0.0303 - mse: 0.0016 - val_loss: 0.0061 - val_mae: 0.0539 - val_mse: 0.0061\n",
      "\n",
      "Epoch 00038: val_mae did not improve from 0.04887\n",
      "Epoch 39/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0017 - mae: 0.0297 - mse: 0.0017 - val_loss: 0.0057 - val_mae: 0.0512 - val_mse: 0.0057\n",
      "\n",
      "Epoch 00039: val_mae did not improve from 0.04887\n",
      "Epoch 40/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0014 - mae: 0.0284 - mse: 0.0014 - val_loss: 0.0058 - val_mae: 0.0514 - val_mse: 0.0058\n",
      "\n",
      "Epoch 00040: val_mae did not improve from 0.04887\n",
      "Epoch 41/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0017 - mae: 0.0295 - mse: 0.0017 - val_loss: 0.0055 - val_mae: 0.0500 - val_mse: 0.0055\n",
      "\n",
      "Epoch 00041: val_mae did not improve from 0.04887\n",
      "Epoch 42/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0015 - mae: 0.0278 - mse: 0.0015 - val_loss: 0.0050 - val_mae: 0.0477 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00042: val_mae improved from 0.04887 to 0.04774, saving model to data/models/clean_o_outliers_jcw.h5\n",
      "Epoch 43/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0015 - mae: 0.0287 - mse: 0.0015 - val_loss: 0.0050 - val_mae: 0.0473 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00043: val_mae improved from 0.04774 to 0.04732, saving model to data/models/clean_o_outliers_jcw.h5\n",
      "Epoch 44/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0013 - mae: 0.0266 - mse: 0.0013 - val_loss: 0.0048 - val_mae: 0.0462 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00044: val_mae improved from 0.04732 to 0.04619, saving model to data/models/clean_o_outliers_jcw.h5\n",
      "Epoch 45/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0011 - mae: 0.0254 - mse: 0.0011 - val_loss: 0.0050 - val_mae: 0.0476 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00045: val_mae did not improve from 0.04619\n",
      "Epoch 46/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0014 - mae: 0.0271 - mse: 0.0014 - val_loss: 0.0053 - val_mae: 0.0491 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00046: val_mae did not improve from 0.04619\n",
      "Epoch 47/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.0012 - mae: 0.0259 - mse: 0.0012 - val_loss: 0.0056 - val_mae: 0.0498 - val_mse: 0.0056\n",
      "\n",
      "Epoch 00047: val_mae did not improve from 0.04619\n",
      "Epoch 48/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0012 - mae: 0.0257 - mse: 0.0012 - val_loss: 0.0050 - val_mae: 0.0476 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00048: val_mae did not improve from 0.04619\n",
      "Epoch 49/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.0013 - mae: 0.0262 - mse: 0.0013 - val_loss: 0.0049 - val_mae: 0.0466 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00049: val_mae did not improve from 0.04619\n",
      "Epoch 50/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.0012 - mae: 0.0253 - mse: 0.0012 - val_loss: 0.0049 - val_mae: 0.0468 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00050: val_mae did not improve from 0.04619\n",
      "Epoch 51/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 0.0013 - mae: 0.0265 - mse: 0.0013 - val_loss: 0.0054 - val_mae: 0.0496 - val_mse: 0.0054\n",
      "\n",
      "Epoch 00051: val_mae did not improve from 0.04619\n",
      "Epoch 52/300\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 0.0012 - mae: 0.0250 - mse: 0.0012 - val_loss: 0.0053 - val_mae: 0.0488 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00052: val_mae did not improve from 0.04619\n",
      "Epoch 53/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0012 - mae: 0.0250 - mse: 0.0012 - val_loss: 0.0051 - val_mae: 0.0480 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00053: val_mae did not improve from 0.04619\n",
      "Epoch 54/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0011 - mae: 0.0251 - mse: 0.0011 - val_loss: 0.0051 - val_mae: 0.0482 - val_mse: 0.0051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00054: val_mae did not improve from 0.04619\n",
      "Epoch 55/300\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0011 - mae: 0.0242 - mse: 0.0011 - val_loss: 0.0053 - val_mae: 0.0486 - val_mse: 0.0053\n",
      "\n",
      "Epoch 00055: val_mae did not improve from 0.04619\n",
      "Epoch 56/300\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0011 - mae: 0.0241 - mse: 0.0011 - val_loss: 0.0047 - val_mae: 0.0459 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00056: val_mae improved from 0.04619 to 0.04591, saving model to data/models/clean_o_outliers_jcw.h5\n",
      "Epoch 57/300\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0010 - mae: 0.0241 - mse: 0.0010 - val_loss: 0.0047 - val_mae: 0.0460 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00057: val_mae did not improve from 0.04591\n",
      "Epoch 58/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 0.0012 - mae: 0.0250 - mse: 0.0012 - val_loss: 0.0051 - val_mae: 0.0474 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00058: val_mae did not improve from 0.04591\n",
      "Epoch 59/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0012 - mae: 0.0246 - mse: 0.0012 - val_loss: 0.0048 - val_mae: 0.0454 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00059: val_mae improved from 0.04591 to 0.04544, saving model to data/models/clean_o_outliers_jcw.h5\n",
      "Epoch 60/300\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0011 - mae: 0.0238 - mse: 0.0011 - val_loss: 0.0051 - val_mae: 0.0475 - val_mse: 0.0051\n",
      "\n",
      "Epoch 00060: val_mae did not improve from 0.04544\n",
      "Epoch 61/300\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 9.7978e-04 - mae: 0.0233 - mse: 9.7978e-04 - val_loss: 0.0048 - val_mae: 0.0462 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00061: val_mae did not improve from 0.04544\n",
      "Epoch 62/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 9.7995e-04 - mae: 0.0233 - mse: 9.7995e-04 - val_loss: 0.0048 - val_mae: 0.0457 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00062: val_mae did not improve from 0.04544\n",
      "Epoch 63/300\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0010 - mae: 0.0229 - mse: 0.0010 - val_loss: 0.0047 - val_mae: 0.0452 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00063: val_mae improved from 0.04544 to 0.04517, saving model to data/models/clean_o_outliers_jcw.h5\n",
      "Epoch 64/300\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0016 - mae: 0.0275 - mse: 0.0016 - val_loss: 0.0049 - val_mae: 0.0465 - val_mse: 0.0049\n",
      "\n",
      "Epoch 00064: val_mae did not improve from 0.04517\n",
      "Epoch 65/300\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0015 - mae: 0.0249 - mse: 0.0015 - val_loss: 0.0047 - val_mae: 0.0450 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00065: val_mae improved from 0.04517 to 0.04499, saving model to data/models/clean_o_outliers_jcw.h5\n",
      "Epoch 66/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 9.2617e-04 - mae: 0.0225 - mse: 9.2617e-04 - val_loss: 0.0048 - val_mae: 0.0458 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00066: val_mae did not improve from 0.04499\n",
      "Epoch 67/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 8.6731e-04 - mae: 0.0221 - mse: 8.6731e-04 - val_loss: 0.0047 - val_mae: 0.0452 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00067: val_mae did not improve from 0.04499\n",
      "Epoch 68/300\n",
      "175/175 [==============================] - 25s 146ms/step - loss: 8.5110e-04 - mae: 0.0215 - mse: 8.5110e-04 - val_loss: 0.0048 - val_mae: 0.0460 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00068: val_mae did not improve from 0.04499\n",
      "Epoch 69/300\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 8.1416e-04 - mae: 0.0214 - mse: 8.1416e-04 - val_loss: 0.0047 - val_mae: 0.0459 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00069: val_mae did not improve from 0.04499\n",
      "Epoch 70/300\n",
      "175/175 [==============================] - 32s 182ms/step - loss: 8.8285e-04 - mae: 0.0212 - mse: 8.8285e-04 - val_loss: 0.0047 - val_mae: 0.0451 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00070: val_mae did not improve from 0.04499\n",
      "Epoch 71/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 7.9294e-04 - mae: 0.0211 - mse: 7.9294e-04 - val_loss: 0.0045 - val_mae: 0.0440 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00071: val_mae improved from 0.04499 to 0.04402, saving model to data/models/clean_o_outliers_jcw.h5\n",
      "Epoch 72/300\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 8.0423e-04 - mae: 0.0211 - mse: 8.0423e-04 - val_loss: 0.0045 - val_mae: 0.0438 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00072: val_mae improved from 0.04402 to 0.04376, saving model to data/models/clean_o_outliers_jcw.h5\n",
      "Epoch 73/300\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 8.1037e-04 - mae: 0.0211 - mse: 8.1037e-04 - val_loss: 0.0064 - val_mae: 0.0562 - val_mse: 0.0064\n",
      "\n",
      "Epoch 00073: val_mae did not improve from 0.04376\n",
      "Epoch 74/300\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 0.0010 - mae: 0.0241 - mse: 0.0010 - val_loss: 0.0050 - val_mae: 0.0464 - val_mse: 0.0050\n",
      "\n",
      "Epoch 00074: val_mae did not improve from 0.04376\n",
      "Epoch 75/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 0.0011 - mae: 0.0236 - mse: 0.0011 - val_loss: 0.0048 - val_mae: 0.0461 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00075: val_mae did not improve from 0.04376\n",
      "Epoch 76/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 9.6396e-04 - mae: 0.0219 - mse: 9.6396e-04 - val_loss: 0.0048 - val_mae: 0.0457 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00076: val_mae did not improve from 0.04376\n",
      "Epoch 77/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 0.0011 - mae: 0.0227 - mse: 0.0011 - val_loss: 0.0047 - val_mae: 0.0453 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00077: val_mae did not improve from 0.04376\n",
      "Epoch 78/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 8.2975e-04 - mae: 0.0212 - mse: 8.2975e-04 - val_loss: 0.0047 - val_mae: 0.0452 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00078: val_mae did not improve from 0.04376\n",
      "Epoch 79/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 7.2383e-04 - mae: 0.0199 - mse: 7.2383e-04 - val_loss: 0.0045 - val_mae: 0.0441 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00079: val_mae did not improve from 0.04376\n",
      "Epoch 80/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 6.5281e-04 - mae: 0.0190 - mse: 6.5281e-04 - val_loss: 0.0047 - val_mae: 0.0445 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00080: val_mae did not improve from 0.04376\n",
      "Epoch 81/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 6.6567e-04 - mae: 0.0192 - mse: 6.6567e-04 - val_loss: 0.0046 - val_mae: 0.0443 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00081: val_mae did not improve from 0.04376\n",
      "Epoch 82/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 6.4743e-04 - mae: 0.0189 - mse: 6.4743e-04 - val_loss: 0.0045 - val_mae: 0.0440 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00082: val_mae did not improve from 0.04376\n",
      "Epoch 83/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 6.8761e-04 - mae: 0.0195 - mse: 6.8761e-04 - val_loss: 0.0047 - val_mae: 0.0452 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00083: val_mae did not improve from 0.04376\n",
      "Epoch 84/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 7.4432e-04 - mae: 0.0194 - mse: 7.4432e-04 - val_loss: 0.0046 - val_mae: 0.0442 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00084: val_mae did not improve from 0.04376\n",
      "Epoch 85/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 7.2496e-04 - mae: 0.0197 - mse: 7.2496e-04 - val_loss: 0.0044 - val_mae: 0.0432 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00085: val_mae improved from 0.04376 to 0.04324, saving model to data/models/clean_o_outliers_jcw.h5\n",
      "Epoch 86/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 7.1206e-04 - mae: 0.0190 - mse: 7.1206e-04 - val_loss: 0.0048 - val_mae: 0.0457 - val_mse: 0.0048\n",
      "\n",
      "Epoch 00086: val_mae did not improve from 0.04324\n",
      "Epoch 87/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 7.3340e-04 - mae: 0.0197 - mse: 7.3340e-04 - val_loss: 0.0045 - val_mae: 0.0440 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00087: val_mae did not improve from 0.04324\n",
      "Epoch 88/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 6.1927e-04 - mae: 0.0185 - mse: 6.1927e-04 - val_loss: 0.0046 - val_mae: 0.0438 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00088: val_mae did not improve from 0.04324\n",
      "Epoch 89/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 6.5513e-04 - mae: 0.0186 - mse: 6.5513e-04 - val_loss: 0.0045 - val_mae: 0.0437 - val_mse: 0.0045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00089: val_mae did not improve from 0.04324\n",
      "Epoch 90/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 5.6651e-04 - mae: 0.0178 - mse: 5.6651e-04 - val_loss: 0.0045 - val_mae: 0.0436 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00090: val_mae did not improve from 0.04324\n",
      "Epoch 91/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 6.6225e-04 - mae: 0.0188 - mse: 6.6225e-04 - val_loss: 0.0047 - val_mae: 0.0452 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00091: val_mae did not improve from 0.04324\n",
      "Epoch 92/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 7.1766e-04 - mae: 0.0198 - mse: 7.1766e-04 - val_loss: 0.0044 - val_mae: 0.0432 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00092: val_mae improved from 0.04324 to 0.04317, saving model to data/models/clean_o_outliers_jcw.h5\n",
      "Epoch 93/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 7.2395e-04 - mae: 0.0192 - mse: 7.2395e-04 - val_loss: 0.0044 - val_mae: 0.0434 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00093: val_mae did not improve from 0.04317\n",
      "Epoch 94/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 6.0712e-04 - mae: 0.0183 - mse: 6.0712e-04 - val_loss: 0.0045 - val_mae: 0.0440 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00094: val_mae did not improve from 0.04317\n",
      "Epoch 95/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 6.1124e-04 - mae: 0.0184 - mse: 6.1124e-04 - val_loss: 0.0044 - val_mae: 0.0429 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00095: val_mae improved from 0.04317 to 0.04291, saving model to data/models/clean_o_outliers_jcw.h5\n",
      "Epoch 96/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 6.5889e-04 - mae: 0.0186 - mse: 6.5889e-04 - val_loss: 0.0045 - val_mae: 0.0442 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00096: val_mae did not improve from 0.04291\n",
      "Epoch 97/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 6.2310e-04 - mae: 0.0183 - mse: 6.2310e-04 - val_loss: 0.0045 - val_mae: 0.0438 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00097: val_mae did not improve from 0.04291\n",
      "Epoch 98/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 6.2837e-04 - mae: 0.0178 - mse: 6.2837e-04 - val_loss: 0.0047 - val_mae: 0.0452 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00098: val_mae did not improve from 0.04291\n",
      "Epoch 99/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 6.2037e-04 - mae: 0.0181 - mse: 6.2037e-04 - val_loss: 0.0046 - val_mae: 0.0443 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00099: val_mae did not improve from 0.04291\n",
      "Epoch 100/300\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 5.5413e-04 - mae: 0.0176 - mse: 5.5413e-04 - val_loss: 0.0047 - val_mae: 0.0450 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00100: val_mae did not improve from 0.04291\n",
      "Epoch 101/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 5.6729e-04 - mae: 0.0176 - mse: 5.6729e-04 - val_loss: 0.0045 - val_mae: 0.0441 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00101: val_mae did not improve from 0.04291\n",
      "Epoch 102/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 6.2151e-04 - mae: 0.0178 - mse: 6.2151e-04 - val_loss: 0.0045 - val_mae: 0.0436 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00102: val_mae did not improve from 0.04291\n",
      "Epoch 103/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 6.0199e-04 - mae: 0.0180 - mse: 6.0199e-04 - val_loss: 0.0044 - val_mae: 0.0430 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00103: val_mae did not improve from 0.04291\n",
      "Epoch 104/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 8.5725e-04 - mae: 0.0209 - mse: 8.5725e-04 - val_loss: 0.0045 - val_mae: 0.0438 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00104: val_mae did not improve from 0.04291\n",
      "Epoch 105/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 7.4420e-04 - mae: 0.0194 - mse: 7.4420e-04 - val_loss: 0.0045 - val_mae: 0.0443 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00105: val_mae did not improve from 0.04291\n",
      "Epoch 106/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 5.5773e-04 - mae: 0.0175 - mse: 5.5773e-04 - val_loss: 0.0044 - val_mae: 0.0431 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00106: val_mae did not improve from 0.04291\n",
      "Epoch 107/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 5.6929e-04 - mae: 0.0171 - mse: 5.6929e-04 - val_loss: 0.0045 - val_mae: 0.0435 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00107: val_mae did not improve from 0.04291\n",
      "Epoch 108/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 5.0949e-04 - mae: 0.0168 - mse: 5.0949e-04 - val_loss: 0.0043 - val_mae: 0.0427 - val_mse: 0.0043\n",
      "\n",
      "Epoch 00108: val_mae improved from 0.04291 to 0.04273, saving model to data/models/clean_o_outliers_jcw.h5\n",
      "Epoch 109/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 5.5437e-04 - mae: 0.0169 - mse: 5.5437e-04 - val_loss: 0.0045 - val_mae: 0.0435 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00109: val_mae did not improve from 0.04273\n",
      "Epoch 110/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 5.0853e-04 - mae: 0.0166 - mse: 5.0853e-04 - val_loss: 0.0044 - val_mae: 0.0433 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00110: val_mae did not improve from 0.04273\n",
      "Epoch 111/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 4.6111e-04 - mae: 0.0161 - mse: 4.6111e-04 - val_loss: 0.0045 - val_mae: 0.0436 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00111: val_mae did not improve from 0.04273\n",
      "Epoch 112/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 4.4669e-04 - mae: 0.0160 - mse: 4.4669e-04 - val_loss: 0.0045 - val_mae: 0.0437 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00112: val_mae did not improve from 0.04273\n",
      "Epoch 113/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 4.2600e-04 - mae: 0.0154 - mse: 4.2600e-04 - val_loss: 0.0045 - val_mae: 0.0434 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00113: val_mae did not improve from 0.04273\n",
      "Epoch 114/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 4.7393e-04 - mae: 0.0159 - mse: 4.7393e-04 - val_loss: 0.0044 - val_mae: 0.0428 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00114: val_mae did not improve from 0.04273\n",
      "Epoch 115/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 4.9828e-04 - mae: 0.0165 - mse: 4.9828e-04 - val_loss: 0.0045 - val_mae: 0.0439 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00115: val_mae did not improve from 0.04273\n",
      "Epoch 116/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 4.8694e-04 - mae: 0.0164 - mse: 4.8694e-04 - val_loss: 0.0044 - val_mae: 0.0435 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00116: val_mae did not improve from 0.04273\n",
      "Epoch 117/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 6.1675e-04 - mae: 0.0177 - mse: 6.1675e-04 - val_loss: 0.0044 - val_mae: 0.0430 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00117: val_mae did not improve from 0.04273\n",
      "Epoch 118/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 5.4655e-04 - mae: 0.0171 - mse: 5.4655e-04 - val_loss: 0.0047 - val_mae: 0.0447 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00118: val_mae did not improve from 0.04273\n",
      "Epoch 119/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 4.7477e-04 - mae: 0.0162 - mse: 4.7477e-04 - val_loss: 0.0044 - val_mae: 0.0434 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00119: val_mae did not improve from 0.04273\n",
      "Epoch 120/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 5.0293e-04 - mae: 0.0163 - mse: 5.0293e-04 - val_loss: 0.0042 - val_mae: 0.0421 - val_mse: 0.0042\n",
      "\n",
      "Epoch 00120: val_mae improved from 0.04273 to 0.04206, saving model to data/models/clean_o_outliers_jcw.h5\n",
      "Epoch 121/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 4.8728e-04 - mae: 0.0162 - mse: 4.8728e-04 - val_loss: 0.0045 - val_mae: 0.0433 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00121: val_mae did not improve from 0.04206\n",
      "Epoch 122/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 4.7518e-04 - mae: 0.0160 - mse: 4.7518e-04 - val_loss: 0.0045 - val_mae: 0.0432 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00122: val_mae did not improve from 0.04206\n",
      "Epoch 123/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 4.8779e-04 - mae: 0.0160 - mse: 4.8779e-04 - val_loss: 0.0043 - val_mae: 0.0428 - val_mse: 0.0043\n",
      "\n",
      "Epoch 00123: val_mae did not improve from 0.04206\n",
      "Epoch 124/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 4.8746e-04 - mae: 0.0159 - mse: 4.8746e-04 - val_loss: 0.0042 - val_mae: 0.0423 - val_mse: 0.0042\n",
      "\n",
      "Epoch 00124: val_mae did not improve from 0.04206\n",
      "Epoch 125/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 3s 19ms/step - loss: 4.4413e-04 - mae: 0.0153 - mse: 4.4413e-04 - val_loss: 0.0045 - val_mae: 0.0440 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00125: val_mae did not improve from 0.04206\n",
      "Epoch 126/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 4.5804e-04 - mae: 0.0154 - mse: 4.5804e-04 - val_loss: 0.0044 - val_mae: 0.0428 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00126: val_mae did not improve from 0.04206\n",
      "Epoch 127/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 4.2156e-04 - mae: 0.0151 - mse: 4.2156e-04 - val_loss: 0.0046 - val_mae: 0.0440 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00127: val_mae did not improve from 0.04206\n",
      "Epoch 128/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 4.7491e-04 - mae: 0.0160 - mse: 4.7491e-04 - val_loss: 0.0044 - val_mae: 0.0431 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00128: val_mae did not improve from 0.04206\n",
      "Epoch 129/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 4.5096e-04 - mae: 0.0158 - mse: 4.5096e-04 - val_loss: 0.0046 - val_mae: 0.0437 - val_mse: 0.0046\n",
      "\n",
      "Epoch 00129: val_mae did not improve from 0.04206\n",
      "Epoch 130/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 4.8036e-04 - mae: 0.0160 - mse: 4.8036e-04 - val_loss: 0.0044 - val_mae: 0.0428 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00130: val_mae did not improve from 0.04206\n",
      "Epoch 131/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 4.2194e-04 - mae: 0.0152 - mse: 4.2194e-04 - val_loss: 0.0045 - val_mae: 0.0438 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00131: val_mae did not improve from 0.04206\n",
      "Epoch 132/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 4.6600e-04 - mae: 0.0157 - mse: 4.6600e-04 - val_loss: 0.0045 - val_mae: 0.0432 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00132: val_mae did not improve from 0.04206\n",
      "Epoch 133/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 4.9427e-04 - mae: 0.0153 - mse: 4.9427e-04 - val_loss: 0.0044 - val_mae: 0.0426 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00133: val_mae did not improve from 0.04206\n",
      "Epoch 134/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 3.5728e-04 - mae: 0.0143 - mse: 3.5728e-04 - val_loss: 0.0044 - val_mae: 0.0428 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00134: val_mae did not improve from 0.04206\n",
      "Epoch 135/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 3.5643e-04 - mae: 0.0142 - mse: 3.5643e-04 - val_loss: 0.0043 - val_mae: 0.0422 - val_mse: 0.0043\n",
      "\n",
      "Epoch 00135: val_mae did not improve from 0.04206\n",
      "Epoch 136/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 4.6592e-04 - mae: 0.0153 - mse: 4.6592e-04 - val_loss: 0.0043 - val_mae: 0.0421 - val_mse: 0.0043\n",
      "\n",
      "Epoch 00136: val_mae did not improve from 0.04206\n",
      "Epoch 137/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 4.4433e-04 - mae: 0.0153 - mse: 4.4433e-04 - val_loss: 0.0045 - val_mae: 0.0437 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00137: val_mae did not improve from 0.04206\n",
      "Epoch 138/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 4.0413e-04 - mae: 0.0149 - mse: 4.0413e-04 - val_loss: 0.0044 - val_mae: 0.0428 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00138: val_mae did not improve from 0.04206\n",
      "Epoch 139/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 3.8819e-04 - mae: 0.0146 - mse: 3.8819e-04 - val_loss: 0.0043 - val_mae: 0.0421 - val_mse: 0.0043\n",
      "\n",
      "Epoch 00139: val_mae did not improve from 0.04206\n",
      "Epoch 140/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 3.5923e-04 - mae: 0.0141 - mse: 3.5923e-04 - val_loss: 0.0043 - val_mae: 0.0429 - val_mse: 0.0043\n",
      "\n",
      "Epoch 00140: val_mae did not improve from 0.04206\n",
      "Epoch 141/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 3.8636e-04 - mae: 0.0144 - mse: 3.8636e-04 - val_loss: 0.0043 - val_mae: 0.0423 - val_mse: 0.0043\n",
      "\n",
      "Epoch 00141: val_mae did not improve from 0.04206\n",
      "Epoch 142/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 3.7080e-04 - mae: 0.0142 - mse: 3.7080e-04 - val_loss: 0.0047 - val_mae: 0.0443 - val_mse: 0.0047\n",
      "\n",
      "Epoch 00142: val_mae did not improve from 0.04206\n",
      "Epoch 143/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 4.3183e-04 - mae: 0.0151 - mse: 4.3183e-04 - val_loss: 0.0044 - val_mae: 0.0430 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00143: val_mae did not improve from 0.04206\n",
      "Epoch 144/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 4.9179e-04 - mae: 0.0153 - mse: 4.9179e-04 - val_loss: 0.0045 - val_mae: 0.0433 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00144: val_mae did not improve from 0.04206\n",
      "Epoch 145/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 4.4171e-04 - mae: 0.0155 - mse: 4.4171e-04 - val_loss: 0.0044 - val_mae: 0.0432 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00145: val_mae did not improve from 0.04206\n",
      "Epoch 146/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 4.6398e-04 - mae: 0.0155 - mse: 4.6398e-04 - val_loss: 0.0044 - val_mae: 0.0427 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00146: val_mae did not improve from 0.04206\n",
      "Epoch 147/300\n",
      "175/175 [==============================] - 3s 20ms/step - loss: 5.5814e-04 - mae: 0.0169 - mse: 5.5814e-04 - val_loss: 0.0045 - val_mae: 0.0433 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00147: val_mae did not improve from 0.04206\n",
      "Epoch 148/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 4.1583e-04 - mae: 0.0149 - mse: 4.1583e-04 - val_loss: 0.0045 - val_mae: 0.0440 - val_mse: 0.0045\n",
      "\n",
      "Epoch 00148: val_mae did not improve from 0.04206\n",
      "Epoch 149/300\n",
      "175/175 [==============================] - 3s 19ms/step - loss: 4.2506e-04 - mae: 0.0152 - mse: 4.2506e-04 - val_loss: 0.0044 - val_mae: 0.0430 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00149: val_mae did not improve from 0.04206\n",
      "Epoch 150/300\n",
      "175/175 [==============================] - 4s 21ms/step - loss: 3.5017e-04 - mae: 0.0140 - mse: 3.5017e-04 - val_loss: 0.0043 - val_mae: 0.0424 - val_mse: 0.0043\n",
      "\n",
      "Epoch 00150: val_mae did not improve from 0.04206\n",
      "Epoch 151/300\n",
      "175/175 [==============================] - 4s 20ms/step - loss: 3.2471e-04 - mae: 0.0134 - mse: 3.2471e-04 - val_loss: 0.0044 - val_mae: 0.0428 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00151: val_mae did not improve from 0.04206\n",
      "Epoch 152/300\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 3.4500e-04 - mae: 0.0135 - mse: 3.4500e-04 - val_loss: 0.0044 - val_mae: 0.0426 - val_mse: 0.0044\n",
      "\n",
      "Epoch 00152: val_mae did not improve from 0.04206\n",
      "Epoch 153/300\n",
      "175/175 [==============================] - 4s 25ms/step - loss: 4.1201e-04 - mae: 0.0143 - mse: 4.1201e-04 - val_loss: 0.0042 - val_mae: 0.0416 - val_mse: 0.0042\n",
      "\n",
      "Epoch 00153: val_mae improved from 0.04206 to 0.04161, saving model to data/models/clean_o_outliers_jcw.h5\n",
      "Epoch 154/300\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 3.5159e-04 - mae: 0.0138 - mse: 3.5159e-04 - val_loss: 0.0043 - val_mae: 0.0430 - val_mse: 0.0043\n",
      "\n",
      "Epoch 00154: val_mae did not improve from 0.04161\n",
      "Epoch 00154: early stopping\n",
      "Done fitting\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_o_outliers_jcw model created and file saved for future use.\n",
      "End model and train\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "imp.reload(load_models)\n",
    "\n",
    "file_path = \"cleantrain/\"\n",
    "#files = os.listdir(\"../CleanTrain\")\n",
    "files = os.listdir(file_path)\n",
    "\n",
    "#For every version of a cleaned Train file in CleanTrain directory, create and save a model\n",
    "for filename in files: \n",
    "    print(\"Opening file: \", filename)\n",
    "    clean_file = \"\".join((file_path,filename))\n",
    "    print(clean_file)\n",
    "    train_data = pickle.load( open( clean_file, \"rb\" ) )\n",
    "    train_data = train_data.drop(['level_0', 'check_sum', 'index'], axis=1,errors='ignore')\n",
    "    print(\"Train Shape:\", train_data.shape)\n",
    "\n",
    "    filename = str(filename).replace('.p', '').strip()\n",
    "    print(\"Begin model and train:\")\n",
    "    model_name = \"\".join((filename,\"_jcw\"))\n",
    "    print(\"Model name:\", model_name)\n",
    "    #Run with separate = True to train on 8 columns of data\n",
    "    model, history = trainer.train_jcw(model_name, train_data,verbose = True, separate = True)\n",
    "    print(\"End model and train\")    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For every model file in a given path, predict using the model and save the predictions in CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model dir: data/models/\n",
      "Pickle dir: data/predictions/\n",
      "Working with:  clean_w_outliers_jcw\n",
      "Begin Predict\n",
      "Scaling 1783 images...\n",
      "Scaling of 1783 observations complete.\n",
      "Begining the split of Test\n",
      "got unique ids\n",
      "test subset shape: (1783, 4)\n",
      "End with the split of Test\n",
      "(27124, 4)\n",
      "before melt: (1783, 8)\n",
      "after melt: (14264, 3)\n",
      "after merge: (14250, 2)\n",
      "data/predictions/clean_w_outliers_jcwPred.csv\n",
      "Predictions written \n",
      "End model and train\n",
      "\n",
      "Working with:  clean_all_outliers_jcw\n",
      "Begin Predict\n",
      "Scaling 1783 images...\n",
      "Scaling of 1783 observations complete.\n",
      "Begining the split of Test\n",
      "got unique ids\n",
      "test subset shape: (1783, 4)\n",
      "End with the split of Test\n",
      "(27124, 4)\n",
      "before melt: (1783, 8)\n",
      "after melt: (14264, 3)\n",
      "after merge: (14250, 2)\n",
      "data/predictions/clean_all_outliers_jcwPred.csv\n",
      "Predictions written \n",
      "End model and train\n",
      "\n",
      "Working with:  clean_w_dups_jcw\n",
      "Begin Predict\n",
      "Scaling 1783 images...\n",
      "Scaling of 1783 observations complete.\n",
      "Begining the split of Test\n",
      "got unique ids\n",
      "test subset shape: (1783, 4)\n",
      "End with the split of Test\n",
      "(27124, 4)\n",
      "before melt: (1783, 8)\n",
      "after melt: (14264, 3)\n",
      "after merge: (14250, 2)\n",
      "data/predictions/clean_w_dups_jcwPred.csv\n",
      "Predictions written \n",
      "End model and train\n",
      "\n",
      "Working with:  clean_wo_dups_jcw\n",
      "Begin Predict\n",
      "Scaling 1783 images...\n",
      "Scaling of 1783 observations complete.\n",
      "Begining the split of Test\n",
      "got unique ids\n",
      "test subset shape: (1783, 4)\n",
      "End with the split of Test\n",
      "(27124, 4)\n",
      "before melt: (1783, 8)\n",
      "after melt: (14264, 3)\n",
      "after merge: (14250, 2)\n",
      "data/predictions/clean_wo_dups_jcwPred.csv\n",
      "Predictions written \n",
      "End model and train\n",
      "\n",
      "Working with:  clean_o_dups_jcw\n",
      "Begin Predict\n",
      "Scaling 1783 images...\n",
      "Scaling of 1783 observations complete.\n",
      "Begining the split of Test\n",
      "got unique ids\n",
      "test subset shape: (1783, 4)\n",
      "End with the split of Test\n",
      "(27124, 4)\n",
      "before melt: (1783, 8)\n",
      "after melt: (14264, 3)\n",
      "after merge: (14250, 2)\n",
      "data/predictions/clean_o_dups_jcwPred.csv\n",
      "Predictions written \n",
      "End model and train\n",
      "\n",
      "Working with:  clean_duplicates_jcw\n",
      "Begin Predict\n",
      "Scaling 1783 images...\n",
      "Scaling of 1783 observations complete.\n",
      "Begining the split of Test\n",
      "got unique ids\n",
      "test subset shape: (1783, 4)\n",
      "End with the split of Test\n",
      "(27124, 4)\n",
      "before melt: (1783, 8)\n",
      "after melt: (14264, 3)\n",
      "after merge: (14250, 2)\n",
      "data/predictions/clean_duplicates_jcwPred.csv\n",
      "Predictions written \n",
      "End model and train\n",
      "\n",
      "Working with:  clean_o_outliers_jcw\n",
      "Begin Predict\n",
      "Scaling 1783 images...\n",
      "Scaling of 1783 observations complete.\n",
      "Begining the split of Test\n",
      "got unique ids\n",
      "test subset shape: (1783, 4)\n",
      "End with the split of Test\n",
      "(27124, 4)\n",
      "before melt: (1783, 8)\n",
      "after melt: (14264, 3)\n",
      "after merge: (14250, 2)\n",
      "data/predictions/clean_o_outliers_jcwPred.csv\n",
      "Predictions written \n",
      "End model and train\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imp.reload(predict_models)\n",
    "imp.reload(transform_data)\n",
    "\n",
    "id_lookup = pickle.load( open( \"data/id_lookup.p\", \"rb\" ) )\n",
    "test = pickle.load( open( \"data/test.p\", \"rb\" ) )\n",
    "\n",
    "#Using local paths as this is way faster...\n",
    "file_path = \"data/models/\"\n",
    "pred_path = \"data/predictions/\"\n",
    "\n",
    "predictor = predict_models.PredictModels(file_path,pred_path , id_lookup)\n",
    "\n",
    "predictor.print_paths()\n",
    "\n",
    "files = os.listdir(file_path)\n",
    "#For every model in file_path, predict using the model and save the predictions in CSV file\n",
    "for filename in files:\n",
    "    if \".h5\" in filename:\n",
    "        base_name = filename[:-3]\n",
    "        model_json = ''.join((base_name,\".json\"))\n",
    "        print(\"Working with: \", base_name)\n",
    "        print(\"Begin Predict\")\n",
    "        Y= predictor.predict_jcw(base_name, filename, model_json, test)\n",
    "        print(\"End model and train\")    \n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From Sandip's models\n",
    "def regression_results(y_true, y_pred):\n",
    "\n",
    "    # Regression metrics\n",
    "    explained_variance = metrics.explained_variance_score(y_true, y_pred)\n",
    "    mean_absolute_error = metrics.mean_absolute_error(y_true, y_pred) \n",
    "    mse = metrics.mean_squared_error(y_true, y_pred) \n",
    "    #mean_squared_log_error=metrics.mean_squared_log_error(y_true, y_pred)\n",
    "    median_absolute_error = metrics.median_absolute_error(y_true, y_pred)\n",
    "    r2 = metrics.r2_score(y_true, y_pred)\n",
    "\n",
    "    print('explained_variance: ', round(explained_variance,4))    \n",
    "    #print('mean_squared_log_error: ', round(mean_squared_log_error,4))\n",
    "    print('r2: ', round(r2,4))\n",
    "    print('MAE: ', round(mean_absolute_error,4))\n",
    "    print('MSE: ', round(mse,4))\n",
    "    print('RMSE: ', round(np.sqrt(mse),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explorations on using different models for 8 vs. 30 predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.reload(predict_models)\n",
    "imp.reload(transform_data)\n",
    "\n",
    "id_lookup = pickle.load( open( \"data/id_lookup.p\", \"rb\" ) )\n",
    "test = pickle.load( open( \"data/test.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering to ids where image_id count == 8\n",
    "new_id = id_lookup.groupby(\"image_id\").agg('count')\n",
    "new_id_2 = new_id[new_id[ \"row_id\" ] <= 8]\n",
    "new_id_1 = new_id[new_id[ \"row_id\" ] > 8]\n",
    "print(new_id_2.index)\n",
    "print(new_id_1.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_lookup_1 = id_lookup[id_lookup['image_id']<=591]\n",
    "id_lookup_2 = id_lookup[id_lookup['image_id'] > 591]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = test[test['image_id']<=591]\n",
    "test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2 = test[test['image_id']>591]\n",
    "test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17592\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#Identify where in the id_lookup is the last output row\n",
    "print(np.max(id_lookup_1['row_id']))\n",
    "print(np.min(id_lookup_1['row_id']))\n",
    "\n",
    "max_row_full = np.max(id_lookup_1['row_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 591 rows of the id lookups require more than 8 keypoints. Afterwards the next 1192 rows only require 6 or 8 keypoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_lookup = id_lookup_2\n",
    "test = test_2\n",
    "pred_path = \"data/predictions/\"\n",
    "\n",
    "predictor = predict_models.PredictModels(file_path,pred_path , id_lookup)\n",
    "\n",
    "model_json = \"data/models/clean_w_outliers_jcw.json\"\n",
    "model_file = \"data/models/clean_w_outliers_jcw.h5\"\n",
    "json_file = open(model_json, \"r\")\n",
    "model_json_data = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(model_json_data)\n",
    "model.load_weights(model_file)\n",
    "base_name = \"clean_w_outliers_jcw\"\n",
    "filename = model_file\n",
    "Y= predictor.predict_jcw(base_name, filename, model_json, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/joanieweaver/Desktop/intro_ml/blackboxes\n"
     ]
    }
   ],
   "source": [
    "cd intro_ml/blackboxes/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in prediction csvs to combine to make final prediction file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data/predictions/\"\n",
    "files = os.listdir(file_path)\n",
    "\n",
    "for file in files:\n",
    "    predictions_separate= pd.read_csv(\"data/predictions/\"+file)\n",
    "    predictions_full = pd.read_csv(\"data/predictions_full/\"+file)\n",
    "    new_pred = predictions_separate[predictions_separate['RowId']>max_row_full].copy()\n",
    "    new_pred = new_pred.append(predictions_full[predictions_full['RowId']<=max_row_full].copy())\n",
    "    new_pred = new_pred.sort_values(by=['RowId'])\n",
    "    new_pred.to_csv(\"combined_\"+file,index=False)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
