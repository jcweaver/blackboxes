{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# W207 Final Project : Facial Keypoint Detection \n",
    "# Team: Joanie Weaver, Sandip Panesar, Jackie Nichols, Rakesh Walisheter\n",
    "W207 Tuesday @4pm\n",
    "\n",
    "ref: https://www.kaggle.com/c/facial-keypoints-detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Imports, reading in files, etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1615669714648
    }
   },
   "outputs": [],
   "source": [
    "#Set the utils path to point to the utils directory locally\n",
    "UTILS_PATH = \"c:/Users/mspuc/OneDrive/Berkeley/A - W207/Final/blackboxes/utils\"\n",
    "\n",
    "import os, sys\n",
    "sys.path.append(UTILS_PATH)\n",
    "from transform_data import TransformData\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "from tqdm import tqdm\n",
    "import zlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import rc\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import pickle\n",
    "import imp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### this is gold right here.\n",
    "imp.reload(transform_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_pickle():\n",
    "    train = pickle.load( open( \"../data/train.p\", \"rb\" ) )\n",
    "    train.rename(columns = {'level_0' : 'index'}, inplace = True)\n",
    "    return train\n",
    "\n",
    "def load_train_dup_pickle():\n",
    "    train_duplicates = pickle.load( open(\"../data/traindup.p\", \"rb\"))\n",
    "    train_duplicates.set_index('index', inplace=True, drop=False)\n",
    "    return train_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gather": {
     "logged": 1615679951578
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test shape is:  (1783, 4)\nTrain shape is:  (7049, 33)\nTest duplicates shape is:  (60, 3)\nTrain duplicates shape is:  (1098, 3)\n"
     ]
    }
   ],
   "source": [
    "#Load the pickle files\n",
    "\n",
    "train = pickle.load( open( \"../data/train.p\", \"rb\" ) )\n",
    "test = pickle.load( open(\"../data/test.p\", \"rb\"))\n",
    "\n",
    "train.rename(columns = {'level_0' : 'index'}, inplace = True)\n",
    "\n",
    "train_duplicates = pickle.load( open(\"../data/traindup.p\", \"rb\"))\n",
    "test_duplicates = pickle.load( open(\"../data/testdup.p\", \"rb\"))\n",
    "\n",
    "train_duplicates.set_index('index', inplace=True, drop=False)\n",
    "print(\"Test shape is: \", test.shape)\n",
    "print(\"Train shape is: \", train.shape)\n",
    "\n",
    "print(\"Test duplicates shape is: \", test_duplicates.shape)\n",
    "print(\"Train duplicates shape is: \", train_duplicates.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "gather": {
     "logged": 1615676047213
    }
   },
   "outputs": [],
   "source": [
    "#HELPER FUNCTIONS to reset the train and test dataframes\n",
    "\n",
    "def reset_train_df():\n",
    "    #train = df['train'].reset_index().copy()\n",
    "    new_train = train.reset_index().copy()\n",
    "    #Get the images and perform a checksum on every image in train: https://www.geeksforgeeks.org/zlib-adler32-in-python/\n",
    "    new_train['check_sum'] = train.image.map(lambda x: zlib.adler32(x))\n",
    "    new_train.pop('level_0')\n",
    "    return new_train\n",
    "\n",
    "def reset_test_df():\n",
    "    #test = df['test'].reset_index().copy()\n",
    "    new_test = test.reset_index().copy()\n",
    "    #Get the images and perform a checksum on every image in train: https://www.geeksforgeeks.org/zlib-adler32-in-python/\n",
    "    new_test['check_sum'] = test.image.map(lambda x: zlib.adler32(x))\n",
    "    new_test.pop('level_0')\n",
    "    return new_test\n",
    "\n",
    "def get_coordinate_columns():\n",
    "    coordinates = [c for c in train.columns if c.endswith('_x') | c.endswith('_y')]\n",
    "    return coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "gather": {
     "logged": 1615679957351
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      index  left_eye_center_x  left_eye_center_y  right_eye_center_x  \\\n",
       "0         0          66.033562          39.002274           30.227007   \n",
       "1         1          64.332939          34.970078           29.949276   \n",
       "2         2          65.057053          34.909641           30.903790   \n",
       "3         3          65.225739          37.261772           32.023094   \n",
       "4         4          66.725304          39.621262           32.244808   \n",
       "...     ...                ...                ...                 ...   \n",
       "7044   7044          67.402550          31.842550           29.746750   \n",
       "7045   7045          66.134399          38.365501           30.478626   \n",
       "7046   7046          66.690735          36.845222           31.666420   \n",
       "7047   7047          70.965080          39.853664           30.543285   \n",
       "7048   7048          66.938309          43.424511           31.096060   \n",
       "\n",
       "      right_eye_center_y  left_eye_inner_corner_x  left_eye_inner_corner_y  \\\n",
       "0              36.421677                59.582077                39.647423   \n",
       "1              33.448715                58.856171                35.274349   \n",
       "2              34.909641                59.411999                36.320969   \n",
       "3              37.261772                60.003338                39.127178   \n",
       "4              38.042030                58.565891                39.621262   \n",
       "...                  ...                      ...                      ...   \n",
       "7044           38.632942                      NaN                      NaN   \n",
       "7045           39.950199                      NaN                      NaN   \n",
       "7046           39.685043                      NaN                      NaN   \n",
       "7047           40.772339                      NaN                      NaN   \n",
       "7048           39.528603                      NaN                      NaN   \n",
       "\n",
       "      left_eye_outer_corner_x  left_eye_outer_corner_y  \\\n",
       "0                   73.130348                39.969997   \n",
       "1                   70.722725                36.187164   \n",
       "2                   70.984421                36.320969   \n",
       "3                   72.314713                38.380966   \n",
       "4                   72.515930                39.884468   \n",
       "...                       ...                      ...   \n",
       "7044                      NaN                      NaN   \n",
       "7045                      NaN                      NaN   \n",
       "7046                      NaN                      NaN   \n",
       "7047                      NaN                      NaN   \n",
       "7048                      NaN                      NaN   \n",
       "\n",
       "      right_eye_inner_corner_x  ...  mouth_left_corner_x  mouth_left_corner_y  \\\n",
       "0                    36.356571  ...            61.195309            79.970169   \n",
       "1                    36.034725  ...            56.421448            76.351997   \n",
       "2                    37.678104  ...            60.822948            73.014313   \n",
       "3                    37.618645  ...            65.598885            72.703720   \n",
       "4                    36.982380  ...            60.671410            77.523239   \n",
       "...                        ...  ...                  ...                  ...   \n",
       "7044                       NaN  ...                  NaN                  NaN   \n",
       "7045                       NaN  ...                  NaN                  NaN   \n",
       "7046                       NaN  ...                  NaN                  NaN   \n",
       "7047                       NaN  ...                  NaN                  NaN   \n",
       "7048                       NaN  ...                  NaN                  NaN   \n",
       "\n",
       "      mouth_right_corner_x  mouth_right_corner_y  mouth_center_top_lip_x  \\\n",
       "0                28.614496             77.388992               43.312603   \n",
       "1                35.122383             76.047661               46.684597   \n",
       "2                33.726315             72.732002               47.274948   \n",
       "3                37.245495             74.195480               50.303165   \n",
       "4                31.191755             76.997299               44.962749   \n",
       "...                    ...                   ...                     ...   \n",
       "7044                   NaN                   NaN                     NaN   \n",
       "7045                   NaN                   NaN                     NaN   \n",
       "7046                   NaN                   NaN                     NaN   \n",
       "7047                   NaN                   NaN                     NaN   \n",
       "7048                   NaN                   NaN                     NaN   \n",
       "\n",
       "      mouth_center_top_lip_y  mouth_center_bottom_lip_x  \\\n",
       "0                  72.935455                  43.130707   \n",
       "1                  70.266556                  45.467915   \n",
       "2                  70.191788                  47.274948   \n",
       "3                  70.091690                  51.561184   \n",
       "4                  73.707390                  44.227142   \n",
       "...                      ...                        ...   \n",
       "7044                     NaN                  50.426636   \n",
       "7045                     NaN                  50.287395   \n",
       "7046                     NaN                  49.462570   \n",
       "7047                     NaN                  50.065186   \n",
       "7048                     NaN                  45.900478   \n",
       "\n",
       "      mouth_center_bottom_lip_y  \\\n",
       "0                     84.485771   \n",
       "1                     85.480171   \n",
       "2                     78.659370   \n",
       "3                     78.268379   \n",
       "4                     86.871162   \n",
       "...                         ...   \n",
       "7044                  79.683922   \n",
       "7045                  77.983025   \n",
       "7046                  78.117119   \n",
       "7047                  79.586449   \n",
       "7048                  82.773094   \n",
       "\n",
       "                                                  image   check_sum  \n",
       "0     [238, 236, 237, 238, 240, 240, 239, 241, 241, ...  4142145667  \n",
       "1     [219, 215, 204, 196, 204, 211, 212, 200, 180, ...   679523243  \n",
       "2     [144, 142, 159, 180, 188, 188, 184, 180, 167, ...  1911173815  \n",
       "3     [193, 192, 193, 194, 194, 194, 193, 192, 168, ...  3647917018  \n",
       "4     [147, 148, 160, 196, 215, 214, 216, 217, 219, ...  1080989530  \n",
       "...                                                 ...         ...  \n",
       "7044  [71, 74, 85, 105, 116, 128, 139, 150, 170, 187...  2440007813  \n",
       "7045  [60, 60, 62, 57, 55, 51, 49, 48, 50, 53, 56, 5...    95927798  \n",
       "7046  [74, 74, 74, 78, 79, 79, 79, 81, 77, 78, 80, 7...  3665138388  \n",
       "7047  [254, 254, 254, 254, 254, 238, 193, 145, 121, ...  2277128216  \n",
       "7048  [53, 62, 67, 76, 86, 91, 97, 105, 105, 106, 10...  3658592976  \n",
       "\n",
       "[7049 rows x 33 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>left_eye_center_x</th>\n      <th>left_eye_center_y</th>\n      <th>right_eye_center_x</th>\n      <th>right_eye_center_y</th>\n      <th>left_eye_inner_corner_x</th>\n      <th>left_eye_inner_corner_y</th>\n      <th>left_eye_outer_corner_x</th>\n      <th>left_eye_outer_corner_y</th>\n      <th>right_eye_inner_corner_x</th>\n      <th>...</th>\n      <th>mouth_left_corner_x</th>\n      <th>mouth_left_corner_y</th>\n      <th>mouth_right_corner_x</th>\n      <th>mouth_right_corner_y</th>\n      <th>mouth_center_top_lip_x</th>\n      <th>mouth_center_top_lip_y</th>\n      <th>mouth_center_bottom_lip_x</th>\n      <th>mouth_center_bottom_lip_y</th>\n      <th>image</th>\n      <th>check_sum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>66.033562</td>\n      <td>39.002274</td>\n      <td>30.227007</td>\n      <td>36.421677</td>\n      <td>59.582077</td>\n      <td>39.647423</td>\n      <td>73.130348</td>\n      <td>39.969997</td>\n      <td>36.356571</td>\n      <td>...</td>\n      <td>61.195309</td>\n      <td>79.970169</td>\n      <td>28.614496</td>\n      <td>77.388992</td>\n      <td>43.312603</td>\n      <td>72.935455</td>\n      <td>43.130707</td>\n      <td>84.485771</td>\n      <td>[238, 236, 237, 238, 240, 240, 239, 241, 241, ...</td>\n      <td>4142145667</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>64.332939</td>\n      <td>34.970078</td>\n      <td>29.949276</td>\n      <td>33.448715</td>\n      <td>58.856171</td>\n      <td>35.274349</td>\n      <td>70.722725</td>\n      <td>36.187164</td>\n      <td>36.034725</td>\n      <td>...</td>\n      <td>56.421448</td>\n      <td>76.351997</td>\n      <td>35.122383</td>\n      <td>76.047661</td>\n      <td>46.684597</td>\n      <td>70.266556</td>\n      <td>45.467915</td>\n      <td>85.480171</td>\n      <td>[219, 215, 204, 196, 204, 211, 212, 200, 180, ...</td>\n      <td>679523243</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>65.057053</td>\n      <td>34.909641</td>\n      <td>30.903790</td>\n      <td>34.909641</td>\n      <td>59.411999</td>\n      <td>36.320969</td>\n      <td>70.984421</td>\n      <td>36.320969</td>\n      <td>37.678104</td>\n      <td>...</td>\n      <td>60.822948</td>\n      <td>73.014313</td>\n      <td>33.726315</td>\n      <td>72.732002</td>\n      <td>47.274948</td>\n      <td>70.191788</td>\n      <td>47.274948</td>\n      <td>78.659370</td>\n      <td>[144, 142, 159, 180, 188, 188, 184, 180, 167, ...</td>\n      <td>1911173815</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>65.225739</td>\n      <td>37.261772</td>\n      <td>32.023094</td>\n      <td>37.261772</td>\n      <td>60.003338</td>\n      <td>39.127178</td>\n      <td>72.314713</td>\n      <td>38.380966</td>\n      <td>37.618645</td>\n      <td>...</td>\n      <td>65.598885</td>\n      <td>72.703720</td>\n      <td>37.245495</td>\n      <td>74.195480</td>\n      <td>50.303165</td>\n      <td>70.091690</td>\n      <td>51.561184</td>\n      <td>78.268379</td>\n      <td>[193, 192, 193, 194, 194, 194, 193, 192, 168, ...</td>\n      <td>3647917018</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>66.725304</td>\n      <td>39.621262</td>\n      <td>32.244808</td>\n      <td>38.042030</td>\n      <td>58.565891</td>\n      <td>39.621262</td>\n      <td>72.515930</td>\n      <td>39.884468</td>\n      <td>36.982380</td>\n      <td>...</td>\n      <td>60.671410</td>\n      <td>77.523239</td>\n      <td>31.191755</td>\n      <td>76.997299</td>\n      <td>44.962749</td>\n      <td>73.707390</td>\n      <td>44.227142</td>\n      <td>86.871162</td>\n      <td>[147, 148, 160, 196, 215, 214, 216, 217, 219, ...</td>\n      <td>1080989530</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7044</th>\n      <td>7044</td>\n      <td>67.402550</td>\n      <td>31.842550</td>\n      <td>29.746750</td>\n      <td>38.632942</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>50.426636</td>\n      <td>79.683922</td>\n      <td>[71, 74, 85, 105, 116, 128, 139, 150, 170, 187...</td>\n      <td>2440007813</td>\n    </tr>\n    <tr>\n      <th>7045</th>\n      <td>7045</td>\n      <td>66.134399</td>\n      <td>38.365501</td>\n      <td>30.478626</td>\n      <td>39.950199</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>50.287395</td>\n      <td>77.983025</td>\n      <td>[60, 60, 62, 57, 55, 51, 49, 48, 50, 53, 56, 5...</td>\n      <td>95927798</td>\n    </tr>\n    <tr>\n      <th>7046</th>\n      <td>7046</td>\n      <td>66.690735</td>\n      <td>36.845222</td>\n      <td>31.666420</td>\n      <td>39.685043</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>49.462570</td>\n      <td>78.117119</td>\n      <td>[74, 74, 74, 78, 79, 79, 79, 81, 77, 78, 80, 7...</td>\n      <td>3665138388</td>\n    </tr>\n    <tr>\n      <th>7047</th>\n      <td>7047</td>\n      <td>70.965080</td>\n      <td>39.853664</td>\n      <td>30.543285</td>\n      <td>40.772339</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>50.065186</td>\n      <td>79.586449</td>\n      <td>[254, 254, 254, 254, 254, 238, 193, 145, 121, ...</td>\n      <td>2277128216</td>\n    </tr>\n    <tr>\n      <th>7048</th>\n      <td>7048</td>\n      <td>66.938309</td>\n      <td>43.424511</td>\n      <td>31.096060</td>\n      <td>39.528603</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>45.900478</td>\n      <td>82.773094</td>\n      <td>[53, 62, 67, 76, 86, 91, 97, 105, 105, 106, 10...</td>\n      <td>3658592976</td>\n    </tr>\n  </tbody>\n</table>\n<p>7049 rows Ã— 33 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "#Creating a copy of the train data in train_data in case you want to add columns back in from df[train]\n",
    "train_data=train.copy(deep=True)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Identification\n",
    "As we saw in the EDA, there are a variety of types of images with a variety of keypoints. Below, we will remove some of the images we saw as outliers in the EDA.\n",
    "\n",
    "Outlier types:\n",
    "- Mislabelled images\n",
    "- Weird/bad images\n",
    "- All outliers (i.e. images that contain keypoints that are greater than 3 standard deviations away from the mean for that keypoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "gather": {
     "logged": 1615675669204
    }
   },
   "outputs": [],
   "source": [
    "#CODE CELL FOR JOANIE\n",
    "\n",
    "#This block is identifying and counting all outliers\n",
    "#Outliers are images that contain keypoints > 3std from mean\n",
    "def find_outliers():\n",
    "    train=train_data.drop([\"image\"],axis=1)\n",
    "    described_train=train.describe().T\n",
    "    std=described_train[\"std\"]\n",
    "    mean=described_train[\"mean\"]\n",
    "    q1=described_train[\"25%\"]\n",
    "    q3=described_train[\"75%\"]\n",
    "    iqr=q3-q1\n",
    "\n",
    "    #If we define outliers using IQR\n",
    "    #outlier_low=q1-1.5*iqr\n",
    "    #outlier_high=q3+1.5*iqr\n",
    "\n",
    "    #If we define outliers using std\n",
    "    outlier_low=mean-3*std\n",
    "    outlier_high=mean+3*std\n",
    "\n",
    "\n",
    "\n",
    "    #Keep track of these images in a list\n",
    "    outlier_images=[]\n",
    "    outlier_dict={}\n",
    "\n",
    "    #Iterate through the data to find outliers based on whether they are lower/higher than defined outlier boundaries\n",
    "    for col in train.columns:\n",
    "        indices=list(np.where((train[col] < outlier_low[col]) | (train[col] > outlier_high[col]))[0])\n",
    "        outlier_images.extend(indices)\n",
    "        for i in indices:\n",
    "            temp=outlier_dict.get(i,[])\n",
    "            temp.append(col[:-1])\n",
    "            outlier_dict[i]=temp\n",
    "\n",
    "    #Only count each index once\n",
    "    outliers=np.unique(outlier_images)\n",
    "    outliers\n",
    "    print(\"Finding points 3 standard deviations away from the mean results in \",len(outliers),\n",
    "        \"images being classified as outliers\")\n",
    "    print(\"This represents\",len(outliers)/train.shape[0]*100,\"% of our total data\")\n",
    "\n",
    "    #print(train.shape)\n",
    "    \n",
    "    return outliers\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "gather": {
     "logged": 1615675673874
    }
   },
   "outputs": [],
   "source": [
    "#CODE CELL FOR JOANIE\n",
    "\n",
    "#This function is removing the worst outliers\n",
    "#The worst outliers are the mislabelled images and the weird/bad images\n",
    "def drop_worst_outliers():\n",
    "\n",
    "    print(\"Before dropping worst outliers train shape is: \", train.shape)\n",
    "    print(\"Before dropping worst outliers train duplicates shape is: \", train_duplicates.shape)\n",
    "    miss_labelled = [1747, 1877, 1907,2199] #These are the images with keypoints that are not right\n",
    "    bad_images = [6492,6493,2430,3697] #These are the two collages and the two cartoons\n",
    "\n",
    "    worst_outliers = miss_labelled + bad_images\n",
    "\n",
    "    #Drop with inplace drops inplace\n",
    "    #train_data.drop(index=worst_outliers,inplace=True)\n",
    "    train.drop(index=worst_outliers,inplace=True,errors='ignore')\n",
    "    train_duplicates.drop(index=worst_outliers,inplace=True,errors='ignore')\n",
    "    print(\"After dropping worst outliers train shape is: \", train.shape)\n",
    "    print(\"After dropping worst outliers train duplicates shape is: \", train_duplicates.shape)\n",
    "\n",
    "#This function is for removing all outliers as defined above\n",
    "def drop_all_outliers():\n",
    "    print(\"Before dropping all outliers train shape is: \", train.shape)\n",
    "    print(\"Before dropping all outliers train duplicates shape is: \", train_duplicates.shape)\n",
    "    \n",
    "    outliers = find_outliers()\n",
    "    overlap = [bad for bad in outliers if bad in train_duplicates.index]\n",
    "\n",
    "    train.drop(index=outliers,inplace=True, errors='ignore')\n",
    "    #Drop the overlap outliers and duplicates\n",
    "    train_duplicates.drop(index=overlap,inplace=True,errors='ignore')\n",
    "    print(\"After dropping all outliers train shape is: \", train.shape)\n",
    "    print(\"After dropping all outliers train duplicates shape is: \", train_duplicates.shape)\n",
    "\n",
    "def drop_overlap_outliers():\n",
    "    print(\"Before dropping overlap outliers train shape is: \", train.shape)\n",
    "    print(\"Before dropping overlap outliers train duplicates shape is: \", train_duplicates.shape)\n",
    "    \n",
    "    outliers = find_outliers()\n",
    "    overlap = [bad for bad in outliers if bad in train_duplicates.index]\n",
    "\n",
    "    print(\"There are\", len( overlap), \" images that are outliers that appear in train duplicates\")\n",
    "    \n",
    "    train.drop(index=overlap,inplace=True, errors='ignore')\n",
    "    #Drop the overlap outliers and duplicates\n",
    "    train_duplicates.drop(index=overlap,inplace=True,errors='ignore')\n",
    "    print(\"After dropping overlap outliers train shape is: \", train.shape)\n",
    "    print(\"After dropping overlap outliers train duplicates shape is: \", train_duplicates.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Code for Duplicate Data in Train and Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "gather": {
     "logged": 1615680029884
    }
   },
   "outputs": [],
   "source": [
    "#CODE CELL FOR JACKIE\n",
    "# Remove duplicates in the train dataset by taking the mean of all values for that image in each label \n",
    "def remove_train_duplicates( train_duplicates,verbose=True):\n",
    "    # First let's reset the index since we've been working on the df \n",
    "        \n",
    "    train = reset_train_df()\n",
    "    #train_duplicates.reset_index()\n",
    "\n",
    "    #Get all of the coordinates\n",
    "    coordinates = get_coordinate_columns()\n",
    "\n",
    "    #Create an empty df with the coordinate columns in place\n",
    "    final_images = train[(train.index == -1)][coordinates].copy()\n",
    "    final_check_sum = train_duplicates.check_sum.unique()\n",
    "\n",
    "    #For each unique check_sum in duplicates...\n",
    "    for check_sum in train_duplicates.check_sum.unique():\n",
    "        #Get all of the duplicates with the same check_sum\n",
    "        duplicates = train_duplicates[(train_duplicates.check_sum == check_sum)]['index'].values\n",
    "        \n",
    "        #Get the first image that appears in the train dataset with this check_sum\n",
    "        image = train[(train['index'].isin(duplicates))].image.values[0]\n",
    "        #Take the mean of all the coordinate columns - this is what we will use for the final single image\n",
    "        fixed = pd.DataFrame(pd.DataFrame(train[(train['index'].isin(duplicates))], columns=coordinates).mean(axis = 0)).T\n",
    "        #Make sure to include the actual image (lol)\n",
    "        fixed['image'] = [image]\n",
    "        fixed['check_sum'] = check_sum\n",
    "        fixed['index'] = duplicates[0] #take first index\n",
    "        \n",
    "        #Append it to the list of final_images\n",
    "        final_images = final_images.append(fixed, ignore_index = True)\n",
    "        \n",
    "            \n",
    "    #For reporting purposes: \n",
    "    if verbose: \n",
    "        print(\"=\"*13 + \"Train\" + \"=\"*13)\n",
    "    if verbose: \n",
    "        print(f\"Before delete:     {train.shape}\")\n",
    "\n",
    "    #Remove the duplicates from train - danger, danger, must replace them\n",
    "    train = train[~(train['index'].isin(train_duplicates['index'].values))]\n",
    "    if verbose: \n",
    "        print(f\"After  delete:     {train.shape}\")\n",
    "\n",
    "    #Dump the final images that were duplicates so we can take a look at them after the processing. \n",
    "    pickle.dump(final_check_sum, open( \"../data/final_check_sum.p\", \"wb\" ) )\n",
    " \n",
    "\n",
    "    #Replace removed duplicates with final_images\n",
    "    train = train.append(final_images, ignore_index = True).reset_index()\n",
    "    train['check_sum'] = train.image.map(lambda x: zlib.adler32(x))\n",
    "    #train.drop(columns=['index'], inplace = True)\n",
    "    if verbose: \n",
    "        print(f\"After  append:     {train.shape}\")\n",
    "    return train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "gather": {
     "logged": 1615674308590
    }
   },
   "outputs": [],
   "source": [
    "#CODE CELL FOR JACKIE\n",
    "##########Test Data set\n",
    "\n",
    "#Now do the same for test, this will be easier since we don't need\n",
    "#to deal with points and taking the mean\n",
    "def remove_test_duplicates(verbose=True):\n",
    "#We can do this differently since we don't need to take the mean. \n",
    "#Go through the test and only add items to the final test image if\n",
    "#we do not already have the check_sum. If we find the check_sum, don't\n",
    "#add it it's a duplicate. \n",
    "    test = reset_test_df()\n",
    "    if verbose: print(\"=\"*13 + \"Test=\" + \"=\"*13)\n",
    "    if verbose: print(f\"Before delete:     {test.shape}\")\n",
    "    test = reset_test_df()\n",
    "    #Create an empty df with the coordinate columns in place\n",
    "    final_test_images = test[(test.index == -1)]\n",
    "    \n",
    "    for test_index, check_sum in zip(test['index'], test.check_sum):\n",
    "        if not (check_sum in list(final_test_images.check_sum.values)):\n",
    "            final_test_images = final_test_images.append(test.loc[(test['index'] == test_index)], ignore_index = True)\n",
    "    \n",
    "    if verbose: print(f\"After  delete:     {final_test_images.shape}\")\n",
    "    return final_test_images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Flipped images into the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_horiz_flips(train):\n",
    "    data_transform = transform_data.TransformData(verbose=True)\n",
    "    flipped = data_transform.FlipHorizontal(train)\n",
    "    new_train = train.append(flipped)\n",
    "    return new_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_train_pickle()\n",
    "print(train.shape)\n",
    "train_with_flipped = add_horiz_flips(train)\n",
    "print(train_with_flipped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PICKLE DIFFERENT VERSIONS OF TRAIN CLEANED\n",
    "In order for this to work you will need to reload the orginal pickle files. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this if you would like to include horizontally flipped images with all the keypoints in the training set\n",
    "train = load_train_pickle()\n",
    "train_with_flipped = add_horiz_flips(train)\n",
    "train = train_with_flipped.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "gather": {
     "logged": 1615679966335
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Before dropping overlap outliers train shape is:  (7049, 33)\nBefore dropping overlap outliers train duplicates shape is:  (1098, 3)\nFinding points 3 standard deviations away from the mean results in  409 images being classified as outliers\nThis represents 5.802241452688325 % of our total data\nThere are 29  images that are outliers that appear in train duplicates\nAfter dropping overlap outliers train shape is:  (7020, 33)\nAfter dropping overlap outliers train duplicates shape is:  (1069, 3)\n"
     ]
    }
   ],
   "source": [
    "#PICKLE 1A: OVERLAP OUTLIERS\n",
    "#only drop the overlap outliers for now\n",
    "#use original train data\n",
    "train = load_train_pickle()\n",
    "train_data=train.copy(deep=True)\n",
    "drop_overlap_outliers()\n",
    "pickle.dump( train, open( \"../cleantrain/clean_o_outliers.p\", \"wb\" ) )\n",
    "\n",
    "train8 = train[(train.isnull().sum(axis=1) == 22)]\n",
    "train8_cols = train8.isnull().sum(axis=0).reset_index()[(train8.isnull().sum(axis=0).reset_index()[0] == 0)]['index'].values\n",
    "train8 = train8[train8_cols]\n",
    "\n",
    "pickle.dump( train8, open( \"../cleantrain_8/clean_o_outliers.p\", \"wb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Before dropping worst outliers train shape is:  (7049, 33)\nBefore dropping worst outliers train duplicates shape is:  (1069, 3)\nAfter dropping worst outliers train shape is:  (7041, 33)\nAfter dropping worst outliers train duplicates shape is:  (1069, 3)\n"
     ]
    }
   ],
   "source": [
    "#CODE CELL FOR JACKIE\n",
    "#PICKLE 2A: WORST OUTLIERS\n",
    "#use original train data\n",
    "train = load_train_pickle()\n",
    "train_data=train.copy(deep=True)\n",
    "drop_worst_outliers()\n",
    "#Pickle train so that we can jump in with cleaning this data\n",
    "pickle.dump( train, open( \"../cleantrain/clean_w_outliers.p\", \"wb\" ) )\n",
    "\n",
    "train8 = train[(train.isnull().sum(axis=1) == 22)]\n",
    "train8_cols = train8.isnull().sum(axis=0).reset_index()[(train8.isnull().sum(axis=0).reset_index()[0] == 0)]['index'].values\n",
    "train8 = train8[train8_cols]\n",
    "\n",
    "pickle.dump( train8, open( \"../cleantrain_8/clean_w_outliers.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Before dropping overlap outliers train shape is:  (7049, 33)\nBefore dropping overlap outliers train duplicates shape is:  (1069, 3)\nFinding points 3 standard deviations away from the mean results in  409 images being classified as outliers\nThis represents 5.802241452688325 % of our total data\nThere are 0  images that are outliers that appear in train duplicates\nAfter dropping overlap outliers train shape is:  (7049, 33)\nAfter dropping overlap outliers train duplicates shape is:  (1069, 3)\nBefore dropping worst outliers train shape is:  (7049, 33)\nBefore dropping worst outliers train duplicates shape is:  (1069, 3)\nAfter dropping worst outliers train shape is:  (7041, 33)\nAfter dropping worst outliers train duplicates shape is:  (1069, 3)\n"
     ]
    }
   ],
   "source": [
    "#PICKLE 3A: ALL OUTLIERS\n",
    "train = load_train_pickle()\n",
    "train_data=train.copy(deep=True)\n",
    "drop_overlap_outliers()\n",
    "drop_worst_outliers()\n",
    "pickle.dump( train, open( \"../cleantrain/clean_all_outliers.p\", \"wb\" ) )\n",
    "\n",
    "train8 = train[(train.isnull().sum(axis=1) == 22)]\n",
    "train8_cols = train8.isnull().sum(axis=0).reset_index()[(train8.isnull().sum(axis=0).reset_index()[0] == 0)]['index'].values\n",
    "train8 = train8[train8_cols]\n",
    "\n",
    "pickle.dump( train8, open( \"../cleantrain_8/clean_all_outliers.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MORE PICKLES WITH duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "gather": {
     "logged": 1615680001628
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Applying EDA fix for duplicates\n",
      "\n",
      "=============Train=============\n",
      "Before delete:     (7049, 33)\n",
      "After  delete:     (5951, 33)\n",
      "After  append:     (6494, 34)\n",
      "\n",
      "=============Test==============\n",
      "Before delete:     (1783, 4)\n",
      "After  delete:     (1752, 4)\n"
     ]
    }
   ],
   "source": [
    "#CODE CELL FOR JACKIE\n",
    "#PICKLE 4: DUPLICATES ONLY\n",
    "#Only run this cell to get clean_duplicates\n",
    "print(\"Applying EDA fix for duplicates\")\n",
    "print()\n",
    "train = load_train_pickle()\n",
    "train_duplicates = load_train_dup_pickle()\n",
    "train_data=train.copy(deep=True)\n",
    "train = remove_train_duplicates(train_duplicates)\n",
    "pickle.dump( train, open( \"../cleantrain/clean_duplicates.p\", \"wb\" ) )\n",
    "print()\n",
    "test = remove_test_duplicates()\n",
    "\n",
    "train8 = train[(train.isnull().sum(axis=1) == 22)]\n",
    "train8_cols = train8.isnull().sum(axis=0).reset_index()[(train8.isnull().sum(axis=0).reset_index()[0] == 0)]['index'].values\n",
    "train8 = train8[train8_cols]\n",
    "\n",
    "pickle.dump( train8, open( \"../cleantrain_8/clean_duplicates.p\", \"wb\" ) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Before dropping overlap outliers train shape is:  (7049, 33)\n",
      "Before dropping overlap outliers train duplicates shape is:  (1098, 3)\n",
      "Finding points 3 standard deviations away from the mean results in  409 images being classified as outliers\n",
      "This represents 5.802241452688325 % of our total data\n",
      "There are 29  images that are outliers that appear in train duplicates\n",
      "After dropping overlap outliers train shape is:  (7020, 33)\n",
      "After dropping overlap outliers train duplicates shape is:  (1069, 3)\n",
      "=============Train=============\n",
      "Before delete:     (7020, 33)\n",
      "After  delete:     (5951, 33)\n",
      "After  append:     (6483, 34)\n"
     ]
    }
   ],
   "source": [
    "#CODE CELL FOR JACKIE\n",
    "#PICKLE 5: OVERLAP OUTLIERS + DUPLICATES\n",
    "#Overlap outliers + duplicates\n",
    "train = load_train_pickle()\n",
    "train_duplicates = load_train_dup_pickle()\n",
    "train_data=train.copy(deep=True)\n",
    "drop_overlap_outliers()\n",
    "train = remove_train_duplicates(train_duplicates)\n",
    "pickle.dump( train, open( \"../cleantrain/clean_o_dups.p\", \"wb\" ) )\n",
    "\n",
    "train8 = train[(train.isnull().sum(axis=1) == 22)]\n",
    "train8_cols = train8.isnull().sum(axis=0).reset_index()[(train8.isnull().sum(axis=0).reset_index()[0] == 0)]['index'].values\n",
    "train8 = train8[train8_cols]\n",
    "\n",
    "pickle.dump( train8, open( \"../cleantrain_8/clean_o_dups.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Before dropping worst outliers train shape is:  (7049, 33)\n",
      "Before dropping worst outliers train duplicates shape is:  (1098, 3)\n",
      "After dropping worst outliers train shape is:  (7041, 33)\n",
      "After dropping worst outliers train duplicates shape is:  (1095, 3)\n",
      "=============Train=============\n",
      "Before delete:     (7041, 33)\n",
      "After  delete:     (5946, 33)\n",
      "After  append:     (6488, 34)\n"
     ]
    }
   ],
   "source": [
    "#PICKLE 6: WORST OUTLIERS + DUPLICATES\n",
    "# Worst + DUPS\n",
    "train = load_train_pickle()\n",
    "train_duplicates = load_train_dup_pickle()\n",
    "train_data=train.copy(deep=True)\n",
    "drop_worst_outliers()\n",
    "train = remove_train_duplicates(train_duplicates)\n",
    "pickle.dump( train, open( \"../cleantrain/clean_w_dups.p\", \"wb\" ) )\n",
    "\n",
    "train8 = train[(train.isnull().sum(axis=1) == 22)]\n",
    "train8_cols = train8.isnull().sum(axis=0).reset_index()[(train8.isnull().sum(axis=0).reset_index()[0] == 0)]['index'].values\n",
    "train8 = train8[train8_cols]\n",
    "\n",
    "pickle.dump( train8, open( \"../cleantrain_8/clean_w_dups.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Before dropping overlap outliers train shape is:  (7049, 33)\n",
      "Before dropping overlap outliers train duplicates shape is:  (1098, 3)\n",
      "Finding points 3 standard deviations away from the mean results in  409 images being classified as outliers\n",
      "This represents 5.802241452688325 % of our total data\n",
      "There are 29  images that are outliers that appear in train duplicates\n",
      "After dropping overlap outliers train shape is:  (7020, 33)\n",
      "After dropping overlap outliers train duplicates shape is:  (1069, 3)\n",
      "Before dropping worst outliers train shape is:  (7020, 33)\n",
      "Before dropping worst outliers train duplicates shape is:  (1069, 3)\n",
      "After dropping worst outliers train shape is:  (7015, 33)\n",
      "After dropping worst outliers train duplicates shape is:  (1069, 3)\n",
      "=============Train=============\n",
      "Before delete:     (7015, 33)\n",
      "After  delete:     (5946, 33)\n",
      "After  append:     (6478, 34)\n"
     ]
    }
   ],
   "source": [
    "#PICKLE 7: OVERLAP + WORST OUTLIERS + DUPLICATES\n",
    "#Overlap outliers + duplicates\n",
    "train = load_train_pickle()\n",
    "train_duplicates = load_train_dup_pickle()\n",
    "train_data=train.copy(deep=True)\n",
    "drop_overlap_outliers()\n",
    "drop_worst_outliers()\n",
    "train = remove_train_duplicates(train_duplicates)\n",
    "pickle.dump( train, open( \"../cleantrain/clean_wo_dups.p\", \"wb\" ) )\n",
    "\n",
    "train8 = train[(train.isnull().sum(axis=1) == 22)]\n",
    "train8_cols = train8.isnull().sum(axis=0).reset_index()[(train8.isnull().sum(axis=0).reset_index()[0] == 0)]['index'].values\n",
    "train8 = train8[train8_cols]\n",
    "\n",
    "pickle.dump( train8, open( \"../cleantrain_8/clean_wo_dups.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIEW SOME IMAGES WITH MEAN APPLIED AFTER DUPLICATE REMOVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1615680080619
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#Load the fixed images from the duplication process\n",
    "fixed_images = pickle.load( open( \"data/final_check_sum.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1615680087211
    }
   },
   "outputs": [],
   "source": [
    "#Print clean images:\n",
    "\n",
    "def show_fixed_images(fixed_images):\n",
    "    ## TRAIN \n",
    "    # Let's view some of these duplicated train images\n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    fig.suptitle('Sample of Cleaned Duplicate images from the Train dataset\\n n= 50', size = 20,  y = 1.04, weight = 'bold')\n",
    "    #Get the point coordinates for example: mouth_center_top_lip_x\n",
    "    coordinates = get_coordinate_columns()\n",
    "    #print(coordinates)\n",
    "    \n",
    "   \n",
    "    match_pts = pd.DataFrame(columns =['Points_Found', 'Count'])\n",
    "\n",
    "     #Loop through and plot each of the 50 images.  \n",
    "    for i, check_sum in enumerate (fixed_images):\n",
    "        if i == 50:\n",
    "            break\n",
    "        plt.subplot(10,5,i+1)\n",
    "        img = train[(train['check_sum'] == check_sum)].image.values[0].reshape(96,96)\n",
    "        #These are the points that have been identified on the images\n",
    "        points = train[(train['check_sum'] == check_sum)][coordinates].values[0]\n",
    "        idx = train[(train['check_sum'] == check_sum)]['index']\n",
    "        plt.imshow(img, cmap = 'gray')\n",
    "        plt.axis('off')\n",
    "        matching_pts = 0\n",
    "\n",
    "        for pts in range(0, 30, 2):\n",
    "            x_point, y_point = (points[pts], points[pts+1])\n",
    "            if not (np.isnan(x_point)) and not (np.isnan(y_point)):\n",
    "                matching_pts += 1\n",
    "                #Add the point to the plot\n",
    "                plt.plot(x_point, y_point, 'o', color = \"red\", markersize = 5)\n",
    "                \n",
    "\n",
    "        plt.title(\"Image #:[%d]\\n#Points:[%d]\" % (idx, matching_pts))\n",
    "        if matching_pts in match_pts[\"Points_Found\"].values:\n",
    "                match_pts.loc[match_pts['Points_Found'] == matching_pts, 'Count'] = match_pts.loc[match_pts['Points_Found'] == matching_pts, 'Count'] + 1\n",
    "        else:\n",
    "            match_pts = match_pts.append({'Points_Found':matching_pts,'Count': 1},ignore_index=True)\n",
    "\n",
    "\n",
    "    #We should save every image with a marker so we can look at them\n",
    "    #im = Image.fromarray(img)\n",
    "    #im.save(file_name)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1615680095849
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "show_fixed_images(fixed_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the IDLookup table and pickle it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_lookup = pd.read_csv(\"data/IdLookupTable.csv\", names = ['row_id', 'image_id', 'feature_name', 'location'], dtype = {'row_id':'uint16', 'image_id':'uint16', 'location':'float32'}, skiprows = 1)\n",
    "\n",
    "print(\"Creating lookup pickle file id_lookup.p\")\n",
    "pickle.dump(id_lookup, open(\"data/id_lookup.p\", \"wb\"))\n",
    "print(\"Pickle creation complete.\")"
   ]
  },
  {
   "source": [
    "### Save 8 key points in train"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_train_pickle()\n",
    "train8 = train[(train.isnull().sum(axis=1) == 22)]\n",
    "train8_cols = train8.isnull().sum(axis=0).reset_index()[(train8.isnull().sum(axis=0).reset_index()[0] == 0)]['index'].values\n",
    "train8 = train8[train8_cols]\n",
    "\n",
    "pickle.dump( train8, open( \"../cleantrain/train8.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "name": "python385jvsc74a57bd0d230cf8de72e867e5717d0f5cf531d71189c7e5bd77bc2a42cd05122b296a561",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}