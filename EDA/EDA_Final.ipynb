{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# W207 Final Project : Facial Keypoint Detection \n",
    "# Team: Joanie Weaver, Sandip Panesar, Jackie Nichols, Rakesh Walisheter\n",
    "W207 Tuesday @4pm\n",
    "\n",
    "ref: https://www.kaggle.com/c/facial-keypoints-detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1615677869226
    }
   },
   "outputs": [],
   "source": [
    "UTILS_PATH = \"utils/\"\n",
    "\n",
    "import os, sys\n",
    "sys.path.append(UTILS_PATH)\n",
    "from load_models import LoadTrainModels\n",
    "from predict_models import PredictModels\n",
    "from transform_data import TransformData\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from tqdm import tqdm\n",
    "import zlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import rc\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import altair as alt \n",
    "from  sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1614473347869
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "pd.show_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd utils/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# EDA\n",
    "\n",
    "For our EDA approach we will initially consider the following areas all of which are covered in this notebook: \n",
    "\n",
    "EDA\n",
    "\n",
    "1. LOAD DATA - load data and become familiar with the structure and contents\n",
    "2. DUPLICATES - identify, and potential approach for handling\n",
    "3. MISSING DATA -identify, and potential approach for handling\n",
    "4. OUTLIERS - identify, and potential approach for handling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LOAD DATA For EDA\n",
    "There are 4 files found in the data directory:\n",
    "\n",
    "- IdLookupTable - feature mapping to images\n",
    "- SampleSubmission - sample submission for the contest\n",
    "- test - test data of image\n",
    "- training - image training data with points \n",
    "\n",
    "We must load this data in order to perform EDA. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1615677903353
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#https://realpython.com/python-zip-function/#:~:text=%20Using%20the%20Python%20zip%20()%20Function%20for,zip%20()%20function%20works%20differently%20in...%20More\n",
    "\n",
    "df, git_path = {}, 'data/'\n",
    "for file_name, file_ref, n, t in zip(['test.csv', 'training.csv', 'IdLookupTable.csv', 'SampleSubmission.csv'],\n",
    "                        ['test', 'train', 'id_lookup', 'sample_submission', ],\n",
    "                        [   #test\n",
    "                            ['image_id', 'image'], \n",
    "                            #train\n",
    "                            ['left_eye_center_x', 'left_eye_center_y',  \n",
    "                            'right_eye_center_x', 'right_eye_center_y', \n",
    "                            'left_eye_inner_corner_x', 'left_eye_inner_corner_y', \n",
    "                            'left_eye_outer_corner_x', 'left_eye_outer_corner_y', \n",
    "                            'right_eye_inner_corner_x', 'right_eye_inner_corner_y', \n",
    "                            'right_eye_outer_corner_x', 'right_eye_outer_corner_y', \n",
    "                            'left_eyebrow_inner_end_x', 'left_eyebrow_inner_end_y', \n",
    "                            'left_eyebrow_outer_end_x', 'left_eyebrow_outer_end_y', \n",
    "                            'right_eyebrow_inner_end_x', 'right_eyebrow_inner_end_y', \n",
    "                            'right_eyebrow_outer_end_x', 'right_eyebrow_outer_end_y', \n",
    "                            'nose_tip_x', 'nose_tip_y', \n",
    "                            'mouth_left_corner_x', 'mouth_left_corner_y', \n",
    "                            'mouth_right_corner_x', 'mouth_right_corner_y', \n",
    "                            'mouth_center_top_lip_x', 'mouth_center_top_lip_y', \n",
    "                            'mouth_center_bottom_lip_x', 'mouth_center_bottom_lip_y', 'image'],\n",
    "                            #IdLookupTable\n",
    "                            ['row_id', 'image_id', 'feature_name', 'location'],\n",
    "                            #SampleSubmission\n",
    "                            ['row_id', 'location']\n",
    "                        ],\n",
    "\n",
    "                        [\n",
    "                             #test   \n",
    "                            {'image_id':'uint16', 'image':'object'},\n",
    "                            #train\n",
    "                            {'left_eye_center_x':'float32', 'left_eye_center_y':'float32', \n",
    "                            'right_eye_center_x':'float32', 'right_eye_center_y':'float32', \n",
    "                            'left_eye_inner_corner_x':'float32', 'left_eye_inner_corner_y':'float32', \n",
    "                            'left_eye_outer_corner_x':'float32', 'left_eye_outer_corner_y':'float32', \n",
    "                            'right_eye_inner_corner_x':'float32', 'right_eye_inner_corner_y':'float32',\n",
    "                            'right_eye_outer_corner_x':'float32', 'right_eye_outer_corner_y':'float32', \n",
    "                            'left_eyebrow_inner_end_x':'float32', 'left_eyebrow_inner_end_y':'float32',\n",
    "                            'left_eyebrow_outer_end_x':'float32', 'left_eyebrow_outer_end_y':'float32', \n",
    "                            'right_eyebrow_inner_end_x':'float32', 'right_eyebrow_inner_end_y':'float32',\n",
    "                            'right_eyebrow_outer_end_x':'float32', 'right_eyebrow_outer_end_y':'float32', \n",
    "                            'nose_tip_x':'float32', 'nose_tip_y':'float32', 'mouth_left_corner_x':'float32',\n",
    "                            'mouth_left_corner_y':'float32', 'mouth_right_corner_x':'float32', \n",
    "                            'mouth_right_corner_y':'float32', 'mouth_center_top_lip_x':'float32', \n",
    "                            'mouth_center_top_lip_y':'float32','mouth_center_bottom_lip_x':'float32', \n",
    "                            'mouth_center_bottom_lip_y':'float32', 'image':'object'},\n",
    "                             #IdLookupTable\n",
    "                            {'row_id':'uint16', 'image_id':'uint16', 'location':'float32'},\n",
    "                            #SampleSubmission\n",
    "                            {'row_id':'uint16', 'location':'float32'}\n",
    "                        ],\n",
    "                        ):\n",
    "    #This is the begining of the for loop for each file:\n",
    "    print(\"Load files.\")\n",
    "    print(\"Begin loading file '%s' \" % \"\".join( (git_path, file_name)))\n",
    "    #print(file_ref)\n",
    "    df[file_ref] = pd.read_csv(\"\".join( (git_path,file_name) ), names = n, dtype = t, skiprows = 1)\n",
    "    \n",
    "    #If the file contains an image column like in the case of test.csv store those images now. \n",
    "    if \"image\" in df[file_ref]:\n",
    "        print(\"\\tFound %d images. Processing. \" % df[file_ref].shape[0])\n",
    "        #Get the row with the image data and store it in the dataframe \n",
    "        df[file_ref]['image'] = df[file_ref][\"image\"].map(lambda x: np.array(list(map(int, x.split(\" \")))))\n",
    "    print(\"\\tFile\", file_ref, \" with shape:\", df[file_ref].shape, \" load complete\\n\")\n",
    "\n",
    "print(\"Load files complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1615677946322
    }
   },
   "outputs": [],
   "source": [
    "train, test = df['train'][['image']], df['test'][['image']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Plotting Code\n",
    "\n",
    "- print_train_stacked(text = True) - Plot the data that makes up the train dataset: duplicate + unique duplicate + remaing train dataset\n",
    "- print_test_stacked(text = True) - Plot the data that makes up the train dataset: duplicate + unique duplicate + remaing train dataset\n",
    "- print_duplicate_info(name) - Print out the duplicate % and plot for either name=='train' or name=='test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1615677952395
    }
   },
   "outputs": [],
   "source": [
    "def print_train_stacked():\n",
    "    train_size = train.shape[0] - train_duplicates.shape[0]\n",
    "    train_dup_unique = len(np.unique(train_duplicates.check_sum))\n",
    "    train_dup = train_duplicates.shape[0] - train_dup_unique\n",
    "\n",
    "    data = {'Size': [train_size, train_dup, train_dup_unique],\n",
    "            'Portion': [\"Train\", \"Duplicates\", \"Unique Duplicates\"] }\n",
    "    mydf = pd.DataFrame(data, columns = [\"Size\", \"Portion\"])\n",
    "\n",
    "\n",
    "    bars = alt.Chart(mydf).mark_bar().encode(\n",
    "        x=alt.X('Size:Q', axis=alt.Axis(title='Count')),\n",
    "        y=alt.Y('Portion:N', axis=alt.Axis(title='Portion of DS')),\n",
    "        detail='Portion:N',\n",
    "        color=alt.Color('Portion', legend=None)\n",
    "    ).properties(width=500, height=100)\\\n",
    "    .properties(title = 'Train Dataset Broken Down into Buckets')\n",
    "    \n",
    "\n",
    "    text = alt.Chart(mydf).mark_text(dx=20, dy=3, color='black').encode(\n",
    "    x=alt.X('sum(Size):Q', stack='zero'),\n",
    "        y=alt.Y('Portion:N'),\n",
    "        detail='Portion:N',\n",
    "        text=alt.Text('sum(Size):Q', format='.1f')\n",
    "    )\n",
    "\n",
    "    return bars + text\n",
    "\n",
    "def print_test_stacked():\n",
    "    test_size = test.shape[0] - test_duplicates.shape[0]\n",
    "    test_dup_unique = len(np.unique(test_duplicates.check_sum))\n",
    "    test_dup = test_duplicates.shape[0] - test_dup_unique\n",
    "\n",
    "    data = {'Size': [test_size, test_dup, test_dup_unique],\n",
    "            'Portion': [\"Test\", \"Duplicates\", \"Unique Duplicates\"] }\n",
    "    mydf = pd.DataFrame(data, columns = [\"Size\", \"Portion\"])\n",
    "\n",
    "\n",
    "    bars2 = alt.Chart(mydf).mark_bar().encode(\n",
    "        x=alt.X('Size:Q', axis=alt.Axis(title=\"Count\")),\n",
    "        y=alt.Y('Portion:N', axis=alt.Axis(title=\"Portion of DS\")),\n",
    "        detail='Portion:N',\n",
    "        color=alt.Color('Portion', legend=None)\n",
    "    ).properties(width=500, height=100)\\\n",
    "    .properties(title = 'Test Dataset Broken Down into Buckets')\n",
    "    \n",
    "\n",
    "    text2 = alt.Chart(mydf).mark_text(dx=20, dy=3, color='black').encode(\n",
    "    x=alt.X('sum(Size):Q', stack='zero'),\n",
    "        y=alt.Y('Portion:N'),\n",
    "        detail='Portion:N',\n",
    "        text=alt.Text('sum(Size):Q', format='.1f')\n",
    "    )\n",
    "\n",
    "    return bars2 + text2\n",
    "\n",
    "\n",
    "def print_duplicate_info(name):\n",
    "    if name == 'test':\n",
    "        mydf = reset_test_df()\n",
    "        print(f\"{test.shape[0]/test_duplicates.shape[0]:.2f} % of test data is duplicates\")\n",
    "        return print_test_stacked()\n",
    "    else:\n",
    "        mydf = reset_test_df()\n",
    "        print(f\"{train.shape[0]/train_duplicates.shape[0]:.2f} % of train data is duplicates\")\n",
    "        return print_train_stacked()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Code for DFs\n",
    "\n",
    "- reset_train_df() - reset the train ds index\n",
    "- reset_test_df() - reset the test ds index\n",
    "- get_coordiante_columns() - return a list of columns that end in _x, or _y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1615677955623
    }
   },
   "outputs": [],
   "source": [
    "#HELPER FUNCTIONS to reset the train and test dataframes\n",
    "\n",
    "def reset_train_df():\n",
    "    train = df['train'].reset_index().copy()\n",
    "    #Get the images and perform a checksum on every image in train: https://www.geeksforgeeks.org/zlib-adler32-in-python/\n",
    "    train['check_sum'] = train.image.map(lambda x: zlib.adler32(x))\n",
    "\n",
    "    return train\n",
    "\n",
    "def reset_test_df():\n",
    "    test = df['test'].reset_index().copy()\n",
    "    #Get the images and perform a checksum on every image in train: https://www.geeksforgeeks.org/zlib-adler32-in-python/\n",
    "    test['check_sum'] = test.image.map(lambda x: zlib.adler32(x))\n",
    "\n",
    "    return test\n",
    "\n",
    "def get_coordinate_columns():\n",
    "    coordinates = [c for c in train.columns if c.endswith('_x') | c.endswith('_y')]\n",
    "    return coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. DUPLICATES\n",
    "## Check Train and Test DS for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1615677962112
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Check for duplicate train images\n",
    "\n",
    "#Get the reset train df\n",
    "train = reset_train_df()\n",
    "#Create a DF to store duplicates, grouping them together and sorting them\n",
    "train_duplicates = pd.DataFrame(train.groupby(by='check_sum').index.count().sort_values()).reset_index()\n",
    "#Add a column to keep track of how many of each check sum there are\n",
    "train_duplicates.columns = ['check_sum', 'number_found']\n",
    "#Keep the ones where we have > 1 number_found\n",
    "train_duplicates = train_duplicates[(train_duplicates.number_found > 1)]\n",
    "#Now do a left outer join back to train_duplicates.  This should only keep the duplicates \n",
    "# https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html#:~:text=merge%20is%20a%20function%20in%20the%20pandas%20namespace,,the%20index-on-index%20(by%20default)%20and%20column%20(s)-on-index%20join.\n",
    "train_duplicates = pd.merge(train_duplicates, train[['index', 'check_sum']],  how = 'left', on=['check_sum']).sort_values(by=['number_found', 'check_sum'], ascending = False)\n",
    "\n",
    "\n",
    "#Now do the same for test:\n",
    "# Check for duplicate train images\n",
    "test = reset_test_df()\n",
    "#Create a DF to store duplicates, grouping them together and sorting them\n",
    "test_duplicates = pd.DataFrame(test.groupby(by='check_sum').index.count().sort_values()).reset_index()\n",
    "#Add a column to keep track of how many of each check sum there are\n",
    "test_duplicates.columns = ['check_sum', 'number_found']\n",
    "#Keep the ones where we have > 1 number_found\n",
    "test_duplicates = test_duplicates[(test_duplicates.number_found > 1)]\n",
    "#Now do a left outer join back to train_duplicates.  This should only keep the duplicates \n",
    "# https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html#:~:text=merge%20is%20a%20function%20in%20the%20pandas%20namespace,,the%20index-on-index%20(by%20default)%20and%20column%20(s)-on-index%20join.\n",
    "test_duplicates = pd.merge(test_duplicates, test[['index', 'check_sum']],  how = 'left', on=['check_sum']).sort_values(by=['number_found', 'check_sum'], ascending = False)\n",
    "\n",
    "print(\"EDA on duplicate data in train and test datasets: \")\n",
    "print(\"The train dataset has %d unique images out of the %d duplicate images from the total of %d images\" % (len(np.unique(train_duplicates.check_sum)), train_duplicates.shape[0], train.shape[0]))\n",
    "print(\"The test dataset has %d unique images out of %d duplicate images from the total of %d images\" % (len(np.unique(test_duplicates.check_sum)),test_duplicates.shape[0], test.shape[0]))\n",
    "\n",
    "#Clean up:\n",
    "#We don't really need the check_sum column anymore...so drop it\n",
    "train.drop(columns=['check_sum'], inplace=True)\n",
    "test.drop(columns=['check_sum'], inplace=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1615677970652
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "print_duplicate_info('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1615677976679
    }
   },
   "outputs": [],
   "source": [
    "print_duplicate_info('train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have found duplicates in both the test and train datasets.  We will first investigate the train ds followed by the test ds\n",
    "\n",
    "## Train Dataset and Duplicates\n",
    "\n",
    "- Show some samples of Duplicates\n",
    "- How many labels are on the duplicates?\n",
    "- Show some data wtih missing labels?\n",
    "- Test an approach to determine what to do if we drop the duplicates.  Which labels do we keep?\n",
    "\n",
    "### Show Some Sample Duplicates from Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1615677985449
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def show_duplicate_train():\n",
    "    ## TRAIN \n",
    "    # Let's view some of these duplicated train images\n",
    "    fig = plt.figure(figsize=(18,18))\n",
    "    fig.suptitle('Sample of duplicate images from the Train dataset\\n n= 35', size = 20,  y = 1.04, weight = 'bold')\n",
    "    #Get the point coordinates for example: mouth_center_top_lip_x\n",
    "    coordinates = get_coordinate_columns()\n",
    "    #print(coordinates)\n",
    "    #Get the top 35 duplicate images\n",
    "    idx = train_duplicates.head(35)['index'].values\n",
    "    #For testing, these are the duplicate ID's\n",
    "    #print(idx)\n",
    "\n",
    "    match_pts = pd.DataFrame(columns =['Points_Found', 'Count'])\n",
    "\n",
    "    #Loop through and plot each of the 35 images.  \n",
    "    for i, idx in enumerate(idx):\n",
    "        plt.subplot(7,5,i+1)\n",
    "        img = train[(train['index'] == idx)].image.values[0].reshape(96,96)\n",
    "        #These are the points that have been identified on the images\n",
    "        points = train[(train['index'] == idx)][coordinates].values[0]\n",
    "        plt.imshow(img, cmap = 'gray')\n",
    "        plt.axis('off')\n",
    "        matching_pts = 0\n",
    "\n",
    "        for pts in range(0, 30, 2):\n",
    "            x_point, y_point = (points[pts], points[pts+1])\n",
    "            if not (np.isnan(x_point)) and not (np.isnan(y_point)):\n",
    "                matching_pts += 1\n",
    "                #Add the point to the plot\n",
    "                plt.plot(x_point, y_point, 'o', color = \"red\", markersize = 5)\n",
    "\n",
    "        plt.title(\"Image #:[%d]\\n#Points:[%d]\" % (idx, matching_pts))\n",
    "        if matching_pts in match_pts[\"Points_Found\"].values:\n",
    "                match_pts.loc[match_pts['Points_Found'] == matching_pts, 'Count'] = match_pts.loc[match_pts['Points_Found'] == matching_pts, 'Count'] + 1\n",
    "        else:\n",
    "            match_pts = match_pts.append({'Points_Found':matching_pts,'Count': 1},ignore_index=True)\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1615677991293
    }
   },
   "outputs": [],
   "source": [
    "show_duplicate_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Many Labels are on the Duplicates from Test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1615316956666
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_npoints_duplicates():\n",
    "    idx = train_duplicates['index'].values\n",
    "    #For testing, these are the duplicate ID's\n",
    "    \n",
    "    match_pts = pd.DataFrame(columns =['Points_Found', 'Count'])\n",
    "    coordinates = get_coordinate_columns()\n",
    "    #Loop through and plot each of the 35 images.  \n",
    "    for i, idx in enumerate(idx):\n",
    "        img = train[(train['index'] == idx)].image.values[0].reshape(96,96)\n",
    "        #These are the points that have been identified on the images\n",
    "        points = train[(train['index'] == idx)][coordinates].values[0]\n",
    "        matching_pts = 0\n",
    "\n",
    "        for pts in range(0, 30, 2):\n",
    "            x_point, y_point = (points[pts], points[pts+1])\n",
    "            if not (np.isnan(x_point)) and not (np.isnan(y_point)):\n",
    "                matching_pts += 1\n",
    "                \n",
    "        if matching_pts in match_pts[\"Points_Found\"].values:\n",
    "                match_pts.loc[match_pts['Points_Found'] == matching_pts, 'Count'] = match_pts.loc[match_pts['Points_Found'] == matching_pts, 'Count'] + 1\n",
    "                \n",
    "        else:\n",
    "            match_pts = match_pts.append({'Points_Found': matching_pts,'Count': 1},ignore_index=True)\n",
    "            \n",
    "    #print(match_pts)\n",
    "\n",
    "    bars2 = alt.Chart(match_pts).mark_bar().encode(\n",
    "    x=alt.X('Count:Q',axis=alt.Axis(title='Number of Occurrences')),\n",
    "    y=alt.Y('Points_Found:N', axis=alt.Axis(title='Number of Points')),\n",
    "    detail='Points_Found:N',\n",
    "    color=alt.Color('Points_Found', legend=None)\n",
    "    ).properties(width=500, height=100)\\\n",
    "    .properties(title = 'Test Dataset Broken Down into Buckets')\n",
    "\n",
    "\n",
    "    text2 = alt.Chart(match_pts).mark_text(dx=20, dy=3, color='black').encode(\n",
    "    x=alt.X('sum(Count):Q', stack='zero'),\n",
    "        y=alt.Y('Points_Found:N'),\n",
    "        detail='Points_Found:N',\n",
    "        text=alt.Text('sum(Count):Q', format='.1f')\n",
    "    )\n",
    "\n",
    "    return bars2 + text2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1615316963458
    }
   },
   "outputs": [],
   "source": [
    "show_npoints_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example of the Labels in Duplicates from Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1615316969958
    }
   },
   "outputs": [],
   "source": [
    "def test_duplicate_labels():\n",
    "    #Do the duplicate Train images have the same labels? Let's test one out. \n",
    "\n",
    "    #Get only the first images checksum from duplicate train and then get the images that match the check_sum\n",
    "    duplicate_image_chksum = train_duplicates.iloc[0, train_duplicates.columns.get_loc('check_sum')] \n",
    "\n",
    "    duplicate_image_index = train_duplicates.loc[(train_duplicates.check_sum == duplicate_image_chksum)]['index'].values\n",
    "\n",
    "    #Create an array of all of the coumns with x,y in them\n",
    "    coordinate_columns = get_coordinate_columns()\n",
    "\n",
    "    #Get the df so we can display something meaningful\n",
    "    duplicate_image_df = train.loc[(train['index'].isin(duplicate_image_index))][coordinate_columns]\n",
    "\n",
    "    #https://mode.com/example-gallery/python_dataframe_styling/\n",
    "    return duplicate_image_df.style\\\n",
    "        .highlight_max(subset=coordinate_columns,color='green')\\\n",
    "        .set_na_rep(\"N/A\").format(None, na_rep=\"Missing\")\\\n",
    "        .highlight_null('yellow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1615316973459
    }
   },
   "outputs": [],
   "source": [
    "test_duplicate_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test an Approach for Adjusting Labels After Removing Duplicates from Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1615316978836
    }
   },
   "outputs": [],
   "source": [
    "def test_adjust_labels():\n",
    "\n",
    "    #The lables do not match exactly in the duplicate Train images.  The challenge would be to determine which of the images to keep if we      remove all but one of the duplicate images. We have two options:\n",
    "\n",
    "    #1 - Keep the first duplicate and disregard the others - Easy to do, low cost but we risk losing data.\n",
    "    #2 - Take the average for all coordiantes across the duplicate image and apply those coordinates moving forward. A little more work         invovled and risk of introducing more errors to the lables. \n",
    "    duplicate_image_chksum = train_duplicates.iloc[0, train_duplicates.columns.get_loc('check_sum')] \n",
    "\n",
    "    duplicate_image_index = train_duplicates.loc[(train_duplicates.check_sum == duplicate_image_chksum)]['index'].values\n",
    "\n",
    "    #Create an array of all of the coumns with x,y in them\n",
    "    coordinate_columns = get_coordinate_columns()\n",
    "    #If we were to do #2 this is how the above image would reconcile:\n",
    "    #Take the mean of the columns and create a new DF\n",
    "    duplicate_image_df = pd.DataFrame(train.loc[(train['index'].isin(duplicate_image_index))][coordinate_columns].mean())\n",
    "\n",
    "    #Display results\n",
    "    return duplicate_image_df.T.style\\\n",
    "        .set_na_rep(\"N/A\").format(None, na_rep=\"Missing\")\\\n",
    "        .highlight_null('yellow')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1615316982877
    }
   },
   "outputs": [],
   "source": [
    "test_adjust_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dataset Duplicate Data\n",
    "\n",
    "- Show breakdown of data in Test\n",
    "- Show sample duplicate images from Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1615316988915
    }
   },
   "outputs": [],
   "source": [
    "print_duplicate_info('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Sample Duplicate Images from Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1615316999167
    }
   },
   "outputs": [],
   "source": [
    "def show_duplicate_test():\n",
    "    ## TEST \n",
    "    # Let's view some of these duplicated train images\n",
    "    fig = plt.figure(figsize=(18,18))\n",
    "    fig.suptitle('Sample of duplicate images from the Test dataset\\n n= 35', size = 20,  y = 1.04, weight = 'bold')\n",
    "\n",
    "\n",
    "    #Get the top 35 duplicate images\n",
    "    idx = test_duplicates.head(35)['index'].values\n",
    "    #For testing, these are the duplicate ID's\n",
    "    #print(idx)\n",
    "\n",
    "    #Loop through and plot each of the 35 images.  \n",
    "    for i, idx in enumerate(idx):\n",
    "        plt.subplot(7,5,i+1)\n",
    "        img = test[(test['index'] == idx)].image.values[0].reshape(96,96)\n",
    "        plt.imshow(img, cmap = 'gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Image #:[%d]\" % (idx))\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1615317003198
    }
   },
   "outputs": [],
   "source": [
    "show_duplicate_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplication Conclusions -EDA on duplicate data in train and test datasets:\n",
    "Train:\n",
    "\n",
    "1. The train dataset has 543 unique images out of the 1098 duplicate images from the total of 7049 images\n",
    "\n",
    "2. Of the 1098 duplicate images:\n",
    "    - 1096 of them had 4 points\n",
    "    - 1 had  13 points\n",
    "    - 1 had 15 points\n",
    "\n",
    "Test:\n",
    "\n",
    "1. The test dataset has 29 unique images out of 60 duplicate images from the total of 1783 images\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1615317008640
    }
   },
   "outputs": [],
   "source": [
    "print(\"Test shape is: \", test.shape)\n",
    "print(\"Train shape is: \", train.shape)\n",
    "\n",
    "print(\"Test duplicates shape is: \", test_duplicates.shape)\n",
    "print(\"Train duplicates shape is: \", train_duplicates.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_train_stacked()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_test_stacked()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Train, Test, and duplicate files in Pickle files for easy access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1615317023742
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#CODE CELL FOR JACKIE\n",
    "# Pickle the dupicates datasets so we can work with them in other files. \n",
    "pickle.dump( train_duplicates, open( \"data/traindup.p\", \"wb\" ) )\n",
    "pickle.dump(test_duplicates, open( \"data/testdup.p\", \"wb\" ))\n",
    "\n",
    "train = reset_train_df()\n",
    "test = reset_test_df()\n",
    "\n",
    "#Pickle train and test so that we can jump in with cleaning this data\n",
    "pickle.dump( train, open( \"data/train.p\", \"wb\" ) )\n",
    "pickle.dump(test, open( \"data/test.p\", \"wb\" ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. MISSING DATA\n",
    "\n",
    "## Detecting missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of the data contains missing values for the keypoints columns. Let's explore how much of which columns are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1615265886191
    }
   },
   "outputs": [],
   "source": [
    "#CODE CELL FOR JOANIE\n",
    "#Renaming just the training data for easy use below\n",
    "train_data = df['train'].copy(deep=True)\n",
    "\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1615265890882
    }
   },
   "outputs": [],
   "source": [
    "#CODE CELL FOR JOANIE\n",
    "#Creating a nicely formatted table with percentage of values missing, average value, total number missing\n",
    "\n",
    "def print_nice_table():\n",
    "    train=train_data.drop([\"image\"],axis=1)\n",
    "    total=train.shape[0]\n",
    "\n",
    "    nice_df=train.describe().T\n",
    "    nice_df=nice_df.drop([\"std\",\"25%\",\"50%\",\"75%\"],axis=1)\n",
    "    nice_df[\"range\"]=nice_df[\"max\"]-nice_df[\"min\"]\n",
    "    nice_df[\"mean\"]\n",
    "    nice_df[\"percent_available\"]=nice_df[\"count\"]/total*100\n",
    "    nice_df=nice_df.drop([\"max\",\"min\"],axis=1)\n",
    "    return nice_df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1615266921951
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def print_nice_plot():\n",
    "    mydf = print_nice_table()\n",
    "\n",
    "    mydf['labels'] = get_coordinate_columns()\n",
    "    bars2 = alt.Chart(mydf).mark_bar().encode(\n",
    "        x=alt.X('count:Q',axis=alt.Axis(title='Number of Occurrences')),\n",
    "        y=alt.Y('labels:N', axis=alt.Axis(title='Labels')),\n",
    "        detail='labels:N',\n",
    "        color=alt.Color('labels:N', legend=None)\n",
    "        ).properties(width=500, height=500)\\\n",
    "        .properties(title = 'Label Buckets')\n",
    "\n",
    "\n",
    "    text2 = alt.Chart(mydf).mark_text(dx=20, dy=3, color='black').encode(\n",
    "    x=alt.X('count:Q', stack='zero'),\n",
    "        y=alt.Y('labels:N'),\n",
    "        detail='labels:N',\n",
    "        text=alt.Text('percent_available:Q', format='.1f')\n",
    "    )\n",
    "\n",
    "    return bars2 + text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1615265279406
    }
   },
   "outputs": [],
   "source": [
    "print_nice_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1615266939204
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "print_nice_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CELL FOR JOANIE\n",
    "#How many images are missing\n",
    "print(\"image\",\"has\",sum(train_data[\"image\"].isna()),\"missing values\")\n",
    "print(\"image\",\"has\",sum(train_data[\"image\"].isna())/(len(train_data[\"image\"]))*100,\" % of values are missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Data Conclusions\n",
    "All rows have an Image. \n",
    "\n",
    "Most rows have a:\n",
    "\n",
    "* nose_tip (x, y)\n",
    "* left_eye_center (x,y)\n",
    "* right_eye_center (x,y)\n",
    "* mouth_center_bottom_lip (x,y)\n",
    "\n",
    "Most other features are missing from a majority of the datapoints. Some of these features are only present in ~32% of the data.\n",
    "\n",
    "Thus, we will need to identify an approach on what to do with all of this missing data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe for test predictions\n",
    "#Each row contains an image_id and feature_name to predict\n",
    "df['id_lookup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouped by image_id, we can see how many images require how many features to be predicted\n",
    "grouped = df['id_lookup'].groupby(\"image_id\")['feature_name'].agg('count')\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can print the counts to see that most images in the test only require 8 keypoints to predict\n",
    "temp = pd.DataFrame(grouped.value_counts()).rename(columns={'feature_name':'count'})\n",
    "temp.index.name = 'num_features'\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can print the number of images in test that require each feature to be predicted\n",
    "groupby_features = df['id_lookup'].groupby('feature_name')['image_id'].agg('count')\n",
    "new_df = pd.DataFrame(groupby_features).reset_index()\n",
    "new_df = new_df.rename(columns={'image_id':'count'})\n",
    "new_df[\"percent_available\"]=new_df[\"count\"]/np.max(new_df['count'])*100\n",
    "new_df=np.round(new_df,2)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_nice_plot():\n",
    "    mydf = new_df\n",
    "\n",
    "    mydf['labels'] = list(new_df['feature_name'])\n",
    "    bars2 = alt.Chart(mydf).mark_bar().encode(\n",
    "        x=alt.X('count:Q',axis=alt.Axis(title='Number of Occurrences')),\n",
    "        y=alt.Y('labels:N', axis=alt.Axis(title='Labels')),\n",
    "        detail='labels:N',\n",
    "        color=alt.Color('labels:N', legend=None)\n",
    "        ).properties(width=500, height=500)\\\n",
    "        .properties(title = 'Label Buckets')\n",
    "\n",
    "\n",
    "    text2 = alt.Chart(mydf).mark_text(dx=20, dy=3, color='black').encode(\n",
    "    x=alt.X('count:Q', stack='zero'),\n",
    "        y=alt.Y('labels:N'),\n",
    "        detail='labels:N',\n",
    "        text=alt.Text('percent_available:Q', format='.1f')\n",
    "    )\n",
    "\n",
    "    return bars2 + text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(new_df['feature_name'])\n",
    "print_nice_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Potential Approach for missing data\n",
    "# Filling In Missing Data Using Linear-Models\n",
    "\n",
    "Notes:\n",
    "\n",
    "* 'y' : An incomplete feature in the data set which is being augmented\n",
    "\n",
    "* 'X' : a collection of features which are dense in data and are highly-correlated to 'y'.\n",
    "\n",
    "* Features which have no more than 50-missing data-points are considered `Dense`. Features which have no missing-data-points are considered `full`.\n",
    "\n",
    "* Augmentation considers atleast 2-reference points which are `significantly correlated` to augment any feature; this is to have a `triangulation` in the image rather than just depend on one point.\n",
    "\n",
    "* Correlations of more than 0.5 are considered as `significant correlations`. The corresponding-features are earmarked to be used to triangulate a predicted location.\n",
    "\n",
    "* Data-points which are full in ('X' and 'y') are used to train the corresponding linear-model.\n",
    "\n",
    "* Data-points which are full in 'X' but empty in 'y' are augmented by this model.\n",
    "\n",
    "* This augmentation was possible by setting the acceptable accuracy (R^2) of the linear-models generated to a minimum-acceptable-score of 45% accurate.. any higher than this and the augmentation does not converge; for a few features, the models that came up were less than 50% accurate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1615267939208
    }
   },
   "outputs": [],
   "source": [
    "#CODE CELL FOR RAKESH\n",
    "\n",
    "\n",
    "\n",
    "# Fetch the most significantly-correlated features for each feature in the `data_under_cleansing` set.\n",
    "def get_feature_correlations(data_under_cleansing):\n",
    "    correlations = data_under_cleansing.corr()\n",
    "    max_correlations = correlations[(correlations>0.5) & (correlations<1)]\n",
    "    feature_corrs = {}\n",
    "    for column in max_correlations:\n",
    "        corr_scores = max_correlations[column]\n",
    "        significant_correlations = corr_scores.dropna()\n",
    "        feature_corrs[significant_correlations.name]=significant_correlations\n",
    "    return feature_corrs\n",
    "\n",
    "\n",
    "# In the data set `data_under_cleaning`, this method looks for features which do not have more than 50 missing data-values.\n",
    "# returns a bool-mask representing : <feature> :: <bool? is data dense>\n",
    "def get_data_density_mask(data_under_cleansing):\n",
    "    features = data_under_cleansing.columns\n",
    "    data_under_cleansing_mask = {}\n",
    "    for i in features:\n",
    "        missing_count = sum(data_under_cleansing[i].isna())\n",
    "        data_under_cleansing_mask[i] = missing_count<50\n",
    "    return data_under_cleansing_mask\n",
    "\n",
    "# Method to run the augmentation on given data.\n",
    "def do_augment_missing_data(data_under_cleansing, density_mask, plot_correlations):\n",
    "    feat_corrs = get_feature_correlations(data_under_cleansing)\n",
    "    print(\"Complete Features: \", len([key for key in density_mask.keys() if density_mask[key]]))\n",
    "\n",
    "    #all feature-correlations for features which are reported as not dense\n",
    "    all_features_to_augment = [feat_corrs[feature] for feature in density_mask if not density_mask[feature]]\n",
    "\n",
    "    for feature_data in all_features_to_augment:\n",
    "        # Do this for each feature that needs to be augmented due to large missing values\n",
    "        feat_to_be_augmented = feature_data.name\n",
    "        \n",
    "        high_corr_full_features = [feat for feat in feature_data.index.tolist() if density_mask[feat]]\n",
    "        if len(high_corr_full_features) < 2:\n",
    "            # a feature_threshold to identify how many features are to be used to model \n",
    "            # feature being augmented. Minimum is 2.\n",
    "            continue\n",
    "        \n",
    "        print(\"\\nfeat ..\", feat_to_be_augmented)\n",
    "        print(\"corr ..\", high_corr_full_features)\n",
    "\n",
    "        #\"filtering train-data set where all high-corr-features and feat-to-be-augmented are not-NA\"\n",
    "        query_str_train = ' & '.join(['~{}.isna()'.format(k) for k in high_corr_full_features])\n",
    "        query_str_train = ' & '.join([query_str_train, '~{}.isna()'.format(feat_to_be_augmented)])\n",
    "        #print(query_str_train)\n",
    "        tmp_train_data  = data_under_cleansing.query(query_str_train,engine=\"python\")\n",
    "        tmp_train_X = tmp_train_data[high_corr_full_features]\n",
    "        tmp_train_y = tmp_train_data[feat_to_be_augmented]\n",
    "        \n",
    "        if plot_correlations:\n",
    "            print(\"Plotting y against each X.... \\n\\n \")\n",
    "            for x in high_corr_full_features:\n",
    "                tmp_train_data.plot(x=x, y=feat_to_be_augmented, style='o')\n",
    "                plt.show()\n",
    "\n",
    "        #\"filtering predict-data set where all high-corr-features are not-NA and feat-to-be-augmented are NA\"\n",
    "        query_str_predict = ' & '.join(['~{}.isna()'.format(k) for k in high_corr_full_features])\n",
    "        query_str_predict = ' & '.join([query_str_predict, '{}.isna()'.format(feat_to_be_augmented)])\n",
    "        \n",
    "    \n",
    "        tmp_predict_data  = data_under_cleansing.query(query_str_predict,engine=\"python\")\n",
    "        tmp_predict_X = tmp_predict_data[high_corr_full_features]\n",
    "\n",
    "        lm = LinearRegression().fit(tmp_train_X, tmp_train_y)\n",
    "        model_score =  lm.score(tmp_train_X, tmp_train_y)\n",
    "        print(\"Model score: \", model_score)\n",
    "        if model_score < 0.45:\n",
    "            # do not use a model to augment data when model is less than 45% accurate. Shifting this threshold to 50% leads to NON-CONVERGENCE\n",
    "            print(\"aborting augmenting..\")\n",
    "            continue\n",
    "\n",
    "        print(\"Model coef: \" , lm.coef_)\n",
    "        tmp_predict_y = list(lm.predict(tmp_predict_X))\n",
    "        feat_column_index = data_under_cleansing.columns.get_loc(feat_to_be_augmented)\n",
    "        index_list = tmp_predict_data.index.tolist()\n",
    "\n",
    "        for i, index in enumerate(index_list):\n",
    "            data_under_cleansing.iloc[index][feat_column_index] = tmp_predict_y[i]\n",
    "\n",
    "    return data_under_cleansing\n",
    "\n",
    "\n",
    "def augment_missing_data(given_dataset, plot_correlations=False):\n",
    "    '''\n",
    "    Utility Method which takes a data set of size `n` with `m`-features and augments \n",
    "    features which are missing using linear-regression models. There is not guarantee that \n",
    "    this augmentation process will converge for all data-sets. But it is known to work for the train-data\n",
    "    from this project.\n",
    "    '''\n",
    "    data_to_be_cleansed = given_dataset.loc[:, given_dataset.columns != 'Image']\n",
    "    \n",
    "    while True:\n",
    "        print(\"\\n\\n==========================================================\")\n",
    "        data_density_mask = get_data_density_mask(data_to_be_cleansed)\n",
    "        incomplete_features = [key for key in data_density_mask.keys() if not data_density_mask[key]]\n",
    "        print(\"Incomplete Features: \", len(incomplete_features))\n",
    "        if len(incomplete_features) > 0:\n",
    "            data_to_be_cleansed = do_augment_missing_data(data_to_be_cleansed, data_density_mask, plot_correlations)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return data_to_be_cleansed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heat Maps for Augmented Train-Data\n",
    "\n",
    "Notes:\n",
    "* These are the heat-maps of correlation before and after augmentation\n",
    "\n",
    "* From the heat map it looks like the augmentation did not do anything drastic to the data.\n",
    "\n",
    "* Linear Modelling Augmentation seemed to have boosted correlations of features, already correlated features became more correlated and feature-pairs which werent highly correlated seemed to not have changed much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CELL FOR RAKESH\n",
    "\n",
    "## Pass in the right data-set to augment and get the augmented data back (filtering 'image' column here)\n",
    "augmented_data = augment_missing_data(train_data.loc[:, train_data.columns != 'image'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CELL FOR RAKESH\n",
    "## Plot correlation-map of pre-augmentation data.\n",
    "fig1, ax1 = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(train_data.corr(),ax=ax1)\n",
    "\n",
    "## Plot correlation-map of post-augmentation data.\n",
    "fig2, ax2 = plt.subplots(figsize=(10,10))         # Sample figsize in inches\n",
    "sns.heatmap(augmented_data.corr(),ax=ax2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. OUTLIERS\n",
    "\n",
    "\n",
    "## Evaluating the data we do have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what happens if we plot all of a single keypoint values on a single image. Will they fall in the same place? Since most rows have these 4 columns, we will plot these only: nose_tip (x, y) left_eye_center (x,y) right_eye_center (x,y) mouth_center_bottom_lip (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CELL FOR JOANIE\n",
    "\n",
    "#copy of data\n",
    "train_copy=train_data.copy(deep=True)\n",
    "train=train_data.drop([\"image\"],axis=1).copy()\n",
    "\n",
    "#function that takes an index and returns the nicely formatted image\n",
    "def fix_image(image_index, train_copy = train_copy):    \n",
    "    return np.array(train_copy['image'][image_index],dtype=\"int\").reshape(96,96)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CELL FOR JOANIE\n",
    "\n",
    "def plot_left_eye(first_image):\n",
    "    fig, ax = plt.subplots(figsize=(7,7)) \n",
    "    plt.imshow(first_image, cmap = 'gray')\n",
    "    plt.scatter(x=train_data[\"left_eye_center_x\"],y=train_data[\"left_eye_center_y\"],color=\"red\",marker=\"+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_left_eye(fix_image(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CELL FOR JOANIE\n",
    "\n",
    "def plot_right_eye(first_image):\n",
    "    fig, ax = plt.subplots(figsize=(7,7)) \n",
    "    plt.imshow(first_image.reshape(96,96), cmap = 'gray')\n",
    "    plt.scatter(x=train_data[\"right_eye_center_x\"],y=train_data[\"right_eye_center_y\"],color=\"blue\",marker=\"+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_right_eye(fix_image(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "We can see that with both of the left and right eye center keypoints, most of the data falls in a big cluster around where the guy above's eyes are, or where we'd expect most of the data to fall. It is a little troubling to see some eye centers in the corners or where the guy above's mouth is. These could be outliers we want to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CELL FOR JOANIE\n",
    "def plot_nose(first_image):\n",
    "    fig, ax = plt.subplots(figsize=(7,7)) \n",
    "    plt.imshow(first_image.reshape(96,96), cmap = 'gray')\n",
    "    plt.scatter(x=train_data[\"nose_tip_x\"],y=train_data[\"nose_tip_y\"],color=\"green\",marker=\"+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nose(fix_image(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CELL FOR JOANIE\n",
    "def plot_mouth(first_image):\n",
    "    fig, ax = plt.subplots(figsize=(7,7)) \n",
    "    plt.imshow(first_image.reshape(96,96), cmap = 'gray')\n",
    "    plt.scatter(x=train_data[\"mouth_center_bottom_lip_x\"],y=train_data[\"mouth_center_bottom_lip_y\"],color=\"purple\",marker=\"+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mouth(fix_image(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "We can see that for the nose tip and mouth center, most of the data falls in a cluster around the guy's nose and mouth but there are several points that appear in weird positions: unexpectedly high up, in the corners, at the border of the image, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating some of these outliers\n",
    "First, we'll draw some images with the left eye is much lower than average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CELL FOR JOANIE\n",
    "\n",
    "#These are images where the left eye was much lower than average\n",
    "indices=np.where((train_data[\"left_eye_center_y\"]>60) | (train_data[\"left_eye_center_y\"]>60))[0]\n",
    "fig, axs = plt.subplots(3,3,figsize=(16,16)) \n",
    "index=1\n",
    "axes=axs.flatten()\n",
    "for i in indices:\n",
    "    ax=axes[index-1]\n",
    "    ax.axis('off')\n",
    "    ax.imshow(fix_image(i).reshape(96,96), cmap = 'gray')\n",
    "    ax.scatter(train_data[\"left_eye_center_x\"][i],train_data[\"left_eye_center_y\"][i],color=\"red\",marker=\"+\")\n",
    "    ax.set_title(\"Image \"+str(i))\n",
    "    index+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the reason some of the eyes are so low is that the faces are positioned low on screen. We can also see one image is mislabelled and one is a collage of images on the wall.\n",
    "\n",
    "## Systematic Identification of Outliers\n",
    "It will be tedious to manually look through all of the images so let's just look at images we consider outliers. Here we will consider outliers images that have a keypoint greater than 3 times the standard deviation away from the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CELL FOR JOANIE\n",
    "\n",
    "#This block is identifying and counting all outliers\n",
    "#Outliers are images that contain keypoints > 3std from mean\n",
    "def find_outliers():\n",
    "    #train=train_data.drop([\"image\"],axis=1).copy()\n",
    "    described_train=train.describe().T\n",
    "    std=described_train[\"std\"]\n",
    "    mean=described_train[\"mean\"]\n",
    "    q1=described_train[\"25%\"]\n",
    "    q3=described_train[\"75%\"]\n",
    "    iqr=q3-q1\n",
    "\n",
    "    #If we define outliers using IQR\n",
    "    #outlier_low=q1-1.5*iqr\n",
    "    #outlier_high=q3+1.5*iqr\n",
    "\n",
    "    #If we define outliers using std\n",
    "    outlier_low=mean-3*std\n",
    "    outlier_high=mean+3*std\n",
    "\n",
    "\n",
    "\n",
    "    #Keep track of these images in a list\n",
    "    outlier_images=[]\n",
    "    outlier_dict={}\n",
    "\n",
    "    #Iterate through the data to find outliers based on whether they are lower/higher than defined outlier boundaries\n",
    "    for col in train.columns:\n",
    "        indices=list(np.where((train[col] < outlier_low[col]) | (train[col] > outlier_high[col]))[0])\n",
    "        outlier_images.extend(indices)\n",
    "        for i in indices:\n",
    "            temp=outlier_dict.get(i,[])\n",
    "            temp.append(col[:-1])\n",
    "            outlier_dict[i]=temp\n",
    "\n",
    "    #Only count each index once\n",
    "    outliers=np.unique(outlier_images)\n",
    "    outliers\n",
    "    print(\"Finding points 3 standard deviations away from the mean results in \",len(outliers),\n",
    "        \"images being classified as outliers\")\n",
    "    print(\"This represents\",len(outliers)/train.shape[0]*100,\"% of our total data\")\n",
    "\n",
    "    print(train.shape)\n",
    "    \n",
    "    return outliers,outlier_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CELL FOR JOANIE\n",
    "outliers, outlier_dict = find_outliers()\n",
    "print(\"Finding points 3 standard deviations away from the mean results in \",len(outliers),\n",
    "      \"images being classified as outliers\")\n",
    "print(\"This represents\",len(outliers)/train.shape[0]*100,\"% of our total data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CELL FOR JOANIE\n",
    "#Finding the unique column name strings without the x/y coords at the end\n",
    "def get_unique_columns():\n",
    "    column_strings=[i[:-1] for i in train.columns]\n",
    "    unique_columns=np.unique(column_strings)\n",
    "    return unique_columns\n",
    "\n",
    "unique_columns = get_unique_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CELL FOR JOANIE\n",
    "#Plot the outliers from above\n",
    "def plot_outliers(outliers,outlier_dict):\n",
    "    fig, axs = plt.subplots(round(len(outliers)/3)+1,3,figsize=(20,400)) \n",
    "    index=1\n",
    "    axes=axs.flatten()\n",
    "    for i in outliers:\n",
    "        ax=axes[index-1]\n",
    "        ax.axis('off')\n",
    "        ax.imshow(fix_image(i).reshape(96,96), cmap = 'gray')\n",
    "\n",
    "        for column_string in unique_columns:\n",
    "            x=column_string+\"x\"\n",
    "            y=column_string+\"y\"\n",
    "            #Color facepoints red if outlier\n",
    "            if column_string in outlier_dict[i]:\n",
    "                ax.scatter(train_data[x][i],train_data[y][i],color=\"red\",marker=\"+\")\n",
    "            #Otherwise color blue\n",
    "            else:\n",
    "                ax.scatter(train_data[x][i],train_data[y][i],color=\"blue\",marker=\"+\")\n",
    "        ax.set_title(\"Image \"+str(i))\n",
    "        index+=1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_outliers(outliers,outlier_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "* As we identified earlier, there are duplicates but also the same person is duplicated with slightly different facial expressions, zoom-ins, or camera angles.\n",
    "* There are distracting things in the images such as: sunglasses or glasses, hats, moustaches, eyes closed/squinting, face cut off from one side, mouth really close to/at edge, faces are angled, sometimes so much that you are missing an eye due to the angle. Some are blurry/grainy photos. \n",
    "* Some photos are cartoons. Some photos are babies.\n",
    "* Image 1620 is missing an eye/super angled\n",
    "* Image 2075 is a zoomed version of 2063\n",
    "* These images look mislabelled: 1747, 1877, 1907, 2175, 2199,\n",
    "* Image 2430, 3697 is a cartoon/artwork\n",
    "* Image 2462, 2831 is a baby\n",
    "* 6492 and 6493 are duplicates but with different labels\n",
    "* Image 92, 109, 113, 143, 178, 272, 309, 329, 368, 384, 430, 434, 466, 488, 493, 503, 529, 530, 583, 625, 648, 759, 829, 907, 911, 1068 are the same person\n",
    "* Image 2482, 2438, 2372, 3938, 4315 are really blurry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CELL FOR JOANIE\n",
    "#Plotting some interesting photos\n",
    "\n",
    "def plot_interesting(photo_ids):\n",
    "    fig, axs = plt.subplots(3,3,figsize=(15,15)) \n",
    "    index=1\n",
    "    axes=axs.flatten()\n",
    "    for i in photo_ids:\n",
    "        ax=axes[index-1]\n",
    "        ax.axis('off')\n",
    "        ax.imshow(fix_image(i).reshape(96,96), cmap = 'gray')\n",
    "\n",
    "        for column_string in unique_columns:\n",
    "            x=column_string+\"x\"\n",
    "            y=column_string+\"y\"\n",
    "            #Color facepoints blue\n",
    "            ax.scatter(train[x][i],train[y][i],color=\"blue\",marker=\"+\")\n",
    "        ax.set_title(\"Image \"+str(i))\n",
    "        index+=1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_ids=[1620,2075,2063,2430,3697,2462,2831,6492,6493]\n",
    "plot_interesting(photo_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CELL FOR JOANIE\n",
    "#Some of the images are the same person with different expressions or lighting\n",
    "# There are other images that meet this bucket but not as many of the same person\n",
    "def plot_same(same):\n",
    "    fig, axs = plt.subplots(7,4,figsize=(20,20)) \n",
    "    index=1\n",
    "    axes=axs.flatten()\n",
    "    for i in same:\n",
    "        ax=axes[index-1]\n",
    "        ax.axis('off')\n",
    "        ax.imshow(fix_image(i).reshape(96,96), cmap = 'gray')\n",
    "\n",
    "        for column_string in unique_columns:\n",
    "            x=column_string+\"x\"\n",
    "            y=column_string+\"y\"\n",
    "            #Color facepoints blue\n",
    "            ax.scatter(train[x][i],train[y][i],color=\"blue\",marker=\"+\")\n",
    "        ax.set_title(\"Image \"+str(i))\n",
    "        index+=1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same = [92, 109, 113, 143, 178, 272, 309, 329, 368, 384, 430, 434, 466, 488, 493, 503,\n",
    "        529, 530, 583, 625, 648, 759, 829, 907, 911, 1068]\n",
    "print(len(same))\n",
    "plot_same(same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CELL FOR JOANIE\n",
    "#These images looks mislabelled\n",
    "miss=[1747, 1877, 1907,2199]\n",
    "\n",
    "def plot_mislabelled(miss):\n",
    "    fig, axs = plt.subplots(2,2,figsize=(12,12)) \n",
    "    index=1\n",
    "    axes=axs.flatten()\n",
    "    for i in miss:\n",
    "        ax=axes[index-1]\n",
    "        ax.axis('off')\n",
    "        ax.imshow(fix_image(i).reshape(96,96), cmap = 'gray')\n",
    "\n",
    "        for column_string in unique_columns:\n",
    "            x=column_string+\"x\"\n",
    "            y=column_string+\"y\"\n",
    "            #Color facepoints blue\n",
    "            ax.scatter(train[x][i],train[y][i],color=\"blue\",marker=\"+\")\n",
    "        ax.set_title(\"Image \"+str(i))\n",
    "        index+=1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mislabelled(miss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "We definitely want to remove these mislabelled images and may want to remove some or all of the other outliers. Especially the cartoons or the collage images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Potential Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may be able to improve our data set with additional transformations. For example, we could flip the images and include them in our set.\n",
    "\n",
    "Below, we will explore potential transformations we could take on our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = df['train'].copy()\n",
    "train_2 = train_1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_data = TransformData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Horizontal Flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped = transform_data.FlipHorizontal(train_2,verbose=True)\n",
    "flipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped.describe()\n",
    "#Only 2140 for each point because flipped only works on the good data (i.e. no NAs per row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_transform_eyes(train1, train2):\n",
    "    indices=range(0,5)\n",
    "    fig, axs = plt.subplots(5,2,figsize=(10,20)) \n",
    "    index=1\n",
    "    axes=axs.flatten()\n",
    "    for i in indices:\n",
    "        ax=axes[index-1]\n",
    "        ax.axis('off')\n",
    "        ax.imshow(fix_image(i,train1).reshape(96,96), cmap = 'gray')\n",
    "        ax.scatter(x=train1[\"left_eye_center_x\"][i],y=train1[\"left_eye_center_y\"][i],color=\"red\",marker=\"+\")\n",
    "        ax.scatter(x=train1[\"right_eye_center_x\"][i],y=train1[\"right_eye_center_y\"][i],color=\"blue\",marker=\"+\")\n",
    "        ax.set_title(\"Image \"+str(i))\n",
    "        index+=1\n",
    "        ax=axes[index-1]\n",
    "        ax.axis('off')\n",
    "        ax.imshow(fix_image(i,train2).reshape(96,96), cmap = 'gray')\n",
    "        ax.scatter(x=train2[\"left_eye_center_x\"][i],y=train2[\"left_eye_center_y\"][i],color=\"red\",marker=\"+\")\n",
    "        ax.scatter(x=train2[\"right_eye_center_x\"][i],y=train2[\"right_eye_center_y\"][i],color=\"blue\",marker=\"+\")\n",
    "        ax.set_title(\"Image \"+str(i))\n",
    "        index+=1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_transform_all(train1, train2):\n",
    "    indices=range(0,5)\n",
    "    fig, axs = plt.subplots(5,2,figsize=(10,20)) \n",
    "    index=1\n",
    "    axes=axs.flatten()\n",
    "    for i in indices:\n",
    "        ax=axes[index-1]\n",
    "        ax.axis('off')\n",
    "        ax.imshow(fix_image(i,train1).reshape(96,96), cmap = 'gray')\n",
    "        for column_string in unique_columns:\n",
    "            x=column_string+\"x\"\n",
    "            y=column_string+\"y\"\n",
    "            ax.scatter(train1[x][i],train1[y][i],color=\"red\",marker=\"+\")\n",
    "        ax.set_title(\"Image \"+str(i))\n",
    "        index+=1\n",
    "        ax=axes[index-1]\n",
    "        ax.axis('off')\n",
    "        ax.imshow(fix_image(i,train2).reshape(96,96), cmap = 'gray')\n",
    "        for column_string in unique_columns:\n",
    "            x=column_string+\"x\"\n",
    "            y=column_string+\"y\"\n",
    "            ax.scatter(train2[x][i],train2[y][i],color=\"red\",marker=\"+\")\n",
    "        ax.set_title(\"Image \"+str(i))\n",
    "        index+=1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting flipped images\n",
    "plot_transform_eyes(train_1,flipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting flipped images\n",
    "plot_transform_all(train_1,flipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bright Dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bright = transform_data.Bright_Dim(train_2,level_of_brightness = .01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = transform_data.Bright_Dim(train_2,level_to_dim=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim.iloc[7049:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting bright/dim images\n",
    "#Dimmed images get appended to the end\n",
    "plot_transform_eyes(train_1,dim.iloc[7049:,:].reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting bright/dim images\n",
    "plot_transform_eyes(train_1,bright)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CELL FOR RAKESH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CELL FOR RAKESH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CELL FOR RAKESH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CELL FOR RAKESH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CELL FOR RAKESH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CELL FOR RAKESH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CELL FOR RAKESH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CELL FOR SANDIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CELL FOR SANDIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CELL FOR SANDIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CELL FOR SANDIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CELL FOR SANDIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CELL FOR SANDIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CELL FOR SANDIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CELL FOR SANDIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CELL FOR SANDIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CELL FOR SANDIP"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
