{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Imports, reading in files, etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "from tqdm import tqdm\n",
    "import zlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import rc\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape is:  (1783, 4)\n",
      "Train shape is:  (7049, 33)\n",
      "Test duplicates shape is:  (60, 3)\n",
      "Train duplicates shape is:  (1098, 3)\n"
     ]
    }
   ],
   "source": [
    "#Load the pickle files\n",
    "\n",
    "train = pickle.load( open( \"data/train.p\", \"rb\" ) )\n",
    "test = pickle.load( open(\"data/test.p\", \"rb\"))\n",
    "\n",
    "train.rename(columns = {'level_0' : 'index'}, inplace = True)\n",
    "\n",
    "train_duplicates = pickle.load( open(\"data/traindup.p\", \"rb\"))\n",
    "test_duplicates = pickle.load( open(\"data/testdup.p\", \"rb\"))\n",
    "\n",
    "train_duplicates.set_index('index', inplace=True, drop=False)\n",
    "print(\"Test shape is: \", test.shape)\n",
    "print(\"Train shape is: \", train.shape)\n",
    "\n",
    "print(\"Test duplicates shape is: \", test_duplicates.shape)\n",
    "print(\"Train duplicates shape is: \", train_duplicates.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HELPER FUNCTIONS to reset the train and test dataframes\n",
    "\n",
    "def reset_train_df():\n",
    "    #train = df['train'].reset_index().copy()\n",
    "    new_train = train.reset_index().copy()\n",
    "    #Get the images and perform a checksum on every image in train: https://www.geeksforgeeks.org/zlib-adler32-in-python/\n",
    "    new_train['check_sum'] = train.image.map(lambda x: zlib.adler32(x))\n",
    "    new_train.pop('level_0')\n",
    "    return new_train\n",
    "\n",
    "def reset_test_df():\n",
    "    #test = df['test'].reset_index().copy()\n",
    "    new_test = test.reset_index().copy()\n",
    "    #Get the images and perform a checksum on every image in train: https://www.geeksforgeeks.org/zlib-adler32-in-python/\n",
    "    new_test['check_sum'] = test.image.map(lambda x: zlib.adler32(x))\n",
    "    new_test.pop('level_0')\n",
    "    return new_test\n",
    "\n",
    "def get_coordinate_columns():\n",
    "    coordinates = [c for c in train.columns if c.endswith('_x') | c.endswith('_y')]\n",
    "    return coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>left_eye_center_x</th>\n",
       "      <th>left_eye_center_y</th>\n",
       "      <th>right_eye_center_x</th>\n",
       "      <th>right_eye_center_y</th>\n",
       "      <th>left_eye_inner_corner_x</th>\n",
       "      <th>left_eye_inner_corner_y</th>\n",
       "      <th>left_eye_outer_corner_x</th>\n",
       "      <th>left_eye_outer_corner_y</th>\n",
       "      <th>right_eye_inner_corner_x</th>\n",
       "      <th>...</th>\n",
       "      <th>mouth_left_corner_x</th>\n",
       "      <th>mouth_left_corner_y</th>\n",
       "      <th>mouth_right_corner_x</th>\n",
       "      <th>mouth_right_corner_y</th>\n",
       "      <th>mouth_center_top_lip_x</th>\n",
       "      <th>mouth_center_top_lip_y</th>\n",
       "      <th>mouth_center_bottom_lip_x</th>\n",
       "      <th>mouth_center_bottom_lip_y</th>\n",
       "      <th>image</th>\n",
       "      <th>check_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>66.033562</td>\n",
       "      <td>39.002274</td>\n",
       "      <td>30.227007</td>\n",
       "      <td>36.421677</td>\n",
       "      <td>59.582077</td>\n",
       "      <td>39.647423</td>\n",
       "      <td>73.130348</td>\n",
       "      <td>39.969997</td>\n",
       "      <td>36.356571</td>\n",
       "      <td>...</td>\n",
       "      <td>61.195309</td>\n",
       "      <td>79.970169</td>\n",
       "      <td>28.614496</td>\n",
       "      <td>77.388992</td>\n",
       "      <td>43.312603</td>\n",
       "      <td>72.935455</td>\n",
       "      <td>43.130707</td>\n",
       "      <td>84.485771</td>\n",
       "      <td>[238, 236, 237, 238, 240, 240, 239, 241, 241, ...</td>\n",
       "      <td>3990298755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>64.332939</td>\n",
       "      <td>34.970078</td>\n",
       "      <td>29.949276</td>\n",
       "      <td>33.448715</td>\n",
       "      <td>58.856171</td>\n",
       "      <td>35.274349</td>\n",
       "      <td>70.722725</td>\n",
       "      <td>36.187164</td>\n",
       "      <td>36.034725</td>\n",
       "      <td>...</td>\n",
       "      <td>56.421448</td>\n",
       "      <td>76.351997</td>\n",
       "      <td>35.122383</td>\n",
       "      <td>76.047661</td>\n",
       "      <td>46.684597</td>\n",
       "      <td>70.266556</td>\n",
       "      <td>45.467915</td>\n",
       "      <td>85.480171</td>\n",
       "      <td>[219, 215, 204, 196, 204, 211, 212, 200, 180, ...</td>\n",
       "      <td>1359000491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>65.057053</td>\n",
       "      <td>34.909641</td>\n",
       "      <td>30.903790</td>\n",
       "      <td>34.909641</td>\n",
       "      <td>59.411999</td>\n",
       "      <td>36.320969</td>\n",
       "      <td>70.984421</td>\n",
       "      <td>36.320969</td>\n",
       "      <td>37.678104</td>\n",
       "      <td>...</td>\n",
       "      <td>60.822948</td>\n",
       "      <td>73.014313</td>\n",
       "      <td>33.726315</td>\n",
       "      <td>72.732002</td>\n",
       "      <td>47.274948</td>\n",
       "      <td>70.191788</td>\n",
       "      <td>47.274948</td>\n",
       "      <td>78.659370</td>\n",
       "      <td>[144, 142, 159, 180, 188, 188, 184, 180, 167, ...</td>\n",
       "      <td>3822334647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>65.225739</td>\n",
       "      <td>37.261772</td>\n",
       "      <td>32.023094</td>\n",
       "      <td>37.261772</td>\n",
       "      <td>60.003338</td>\n",
       "      <td>39.127178</td>\n",
       "      <td>72.314713</td>\n",
       "      <td>38.380966</td>\n",
       "      <td>37.618645</td>\n",
       "      <td>...</td>\n",
       "      <td>65.598885</td>\n",
       "      <td>72.703720</td>\n",
       "      <td>37.245495</td>\n",
       "      <td>74.195480</td>\n",
       "      <td>50.303165</td>\n",
       "      <td>70.091690</td>\n",
       "      <td>51.561184</td>\n",
       "      <td>78.268379</td>\n",
       "      <td>[193, 192, 193, 194, 194, 194, 193, 192, 168, ...</td>\n",
       "      <td>3001797594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>66.725304</td>\n",
       "      <td>39.621262</td>\n",
       "      <td>32.244808</td>\n",
       "      <td>38.042030</td>\n",
       "      <td>58.565891</td>\n",
       "      <td>39.621262</td>\n",
       "      <td>72.515930</td>\n",
       "      <td>39.884468</td>\n",
       "      <td>36.982380</td>\n",
       "      <td>...</td>\n",
       "      <td>60.671410</td>\n",
       "      <td>77.523239</td>\n",
       "      <td>31.191755</td>\n",
       "      <td>76.997299</td>\n",
       "      <td>44.962749</td>\n",
       "      <td>73.707390</td>\n",
       "      <td>44.227142</td>\n",
       "      <td>86.871162</td>\n",
       "      <td>[147, 148, 160, 196, 215, 214, 216, 217, 219, ...</td>\n",
       "      <td>2161940314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7044</th>\n",
       "      <td>7044</td>\n",
       "      <td>67.402550</td>\n",
       "      <td>31.842550</td>\n",
       "      <td>29.746750</td>\n",
       "      <td>38.632942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.426636</td>\n",
       "      <td>79.683922</td>\n",
       "      <td>[71, 74, 85, 105, 116, 128, 139, 150, 170, 187...</td>\n",
       "      <td>585994373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7045</th>\n",
       "      <td>7045</td>\n",
       "      <td>66.134399</td>\n",
       "      <td>38.365501</td>\n",
       "      <td>30.478626</td>\n",
       "      <td>39.950199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.287395</td>\n",
       "      <td>77.983025</td>\n",
       "      <td>[60, 60, 62, 57, 55, 51, 49, 48, 50, 53, 56, 5...</td>\n",
       "      <td>191806966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7046</th>\n",
       "      <td>7046</td>\n",
       "      <td>66.690735</td>\n",
       "      <td>36.845222</td>\n",
       "      <td>31.666420</td>\n",
       "      <td>39.685043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.462570</td>\n",
       "      <td>78.117119</td>\n",
       "      <td>[74, 74, 74, 78, 79, 79, 79, 81, 77, 78, 80, 7...</td>\n",
       "      <td>3036254932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7047</th>\n",
       "      <td>7047</td>\n",
       "      <td>70.965080</td>\n",
       "      <td>39.853664</td>\n",
       "      <td>30.543285</td>\n",
       "      <td>40.772339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.065186</td>\n",
       "      <td>79.586449</td>\n",
       "      <td>[254, 254, 254, 254, 254, 238, 193, 145, 121, ...</td>\n",
       "      <td>260257816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7048</th>\n",
       "      <td>7048</td>\n",
       "      <td>66.938309</td>\n",
       "      <td>43.424511</td>\n",
       "      <td>31.096060</td>\n",
       "      <td>39.528603</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.900478</td>\n",
       "      <td>82.773094</td>\n",
       "      <td>[53, 62, 67, 76, 86, 91, 97, 105, 105, 106, 10...</td>\n",
       "      <td>3023155920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7049 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  left_eye_center_x  left_eye_center_y  right_eye_center_x  \\\n",
       "0         0          66.033562          39.002274           30.227007   \n",
       "1         1          64.332939          34.970078           29.949276   \n",
       "2         2          65.057053          34.909641           30.903790   \n",
       "3         3          65.225739          37.261772           32.023094   \n",
       "4         4          66.725304          39.621262           32.244808   \n",
       "...     ...                ...                ...                 ...   \n",
       "7044   7044          67.402550          31.842550           29.746750   \n",
       "7045   7045          66.134399          38.365501           30.478626   \n",
       "7046   7046          66.690735          36.845222           31.666420   \n",
       "7047   7047          70.965080          39.853664           30.543285   \n",
       "7048   7048          66.938309          43.424511           31.096060   \n",
       "\n",
       "      right_eye_center_y  left_eye_inner_corner_x  left_eye_inner_corner_y  \\\n",
       "0              36.421677                59.582077                39.647423   \n",
       "1              33.448715                58.856171                35.274349   \n",
       "2              34.909641                59.411999                36.320969   \n",
       "3              37.261772                60.003338                39.127178   \n",
       "4              38.042030                58.565891                39.621262   \n",
       "...                  ...                      ...                      ...   \n",
       "7044           38.632942                      NaN                      NaN   \n",
       "7045           39.950199                      NaN                      NaN   \n",
       "7046           39.685043                      NaN                      NaN   \n",
       "7047           40.772339                      NaN                      NaN   \n",
       "7048           39.528603                      NaN                      NaN   \n",
       "\n",
       "      left_eye_outer_corner_x  left_eye_outer_corner_y  \\\n",
       "0                   73.130348                39.969997   \n",
       "1                   70.722725                36.187164   \n",
       "2                   70.984421                36.320969   \n",
       "3                   72.314713                38.380966   \n",
       "4                   72.515930                39.884468   \n",
       "...                       ...                      ...   \n",
       "7044                      NaN                      NaN   \n",
       "7045                      NaN                      NaN   \n",
       "7046                      NaN                      NaN   \n",
       "7047                      NaN                      NaN   \n",
       "7048                      NaN                      NaN   \n",
       "\n",
       "      right_eye_inner_corner_x  ...  mouth_left_corner_x  mouth_left_corner_y  \\\n",
       "0                    36.356571  ...            61.195309            79.970169   \n",
       "1                    36.034725  ...            56.421448            76.351997   \n",
       "2                    37.678104  ...            60.822948            73.014313   \n",
       "3                    37.618645  ...            65.598885            72.703720   \n",
       "4                    36.982380  ...            60.671410            77.523239   \n",
       "...                        ...  ...                  ...                  ...   \n",
       "7044                       NaN  ...                  NaN                  NaN   \n",
       "7045                       NaN  ...                  NaN                  NaN   \n",
       "7046                       NaN  ...                  NaN                  NaN   \n",
       "7047                       NaN  ...                  NaN                  NaN   \n",
       "7048                       NaN  ...                  NaN                  NaN   \n",
       "\n",
       "      mouth_right_corner_x  mouth_right_corner_y  mouth_center_top_lip_x  \\\n",
       "0                28.614496             77.388992               43.312603   \n",
       "1                35.122383             76.047661               46.684597   \n",
       "2                33.726315             72.732002               47.274948   \n",
       "3                37.245495             74.195480               50.303165   \n",
       "4                31.191755             76.997299               44.962749   \n",
       "...                    ...                   ...                     ...   \n",
       "7044                   NaN                   NaN                     NaN   \n",
       "7045                   NaN                   NaN                     NaN   \n",
       "7046                   NaN                   NaN                     NaN   \n",
       "7047                   NaN                   NaN                     NaN   \n",
       "7048                   NaN                   NaN                     NaN   \n",
       "\n",
       "      mouth_center_top_lip_y  mouth_center_bottom_lip_x  \\\n",
       "0                  72.935455                  43.130707   \n",
       "1                  70.266556                  45.467915   \n",
       "2                  70.191788                  47.274948   \n",
       "3                  70.091690                  51.561184   \n",
       "4                  73.707390                  44.227142   \n",
       "...                      ...                        ...   \n",
       "7044                     NaN                  50.426636   \n",
       "7045                     NaN                  50.287395   \n",
       "7046                     NaN                  49.462570   \n",
       "7047                     NaN                  50.065186   \n",
       "7048                     NaN                  45.900478   \n",
       "\n",
       "      mouth_center_bottom_lip_y  \\\n",
       "0                     84.485771   \n",
       "1                     85.480171   \n",
       "2                     78.659370   \n",
       "3                     78.268379   \n",
       "4                     86.871162   \n",
       "...                         ...   \n",
       "7044                  79.683922   \n",
       "7045                  77.983025   \n",
       "7046                  78.117119   \n",
       "7047                  79.586449   \n",
       "7048                  82.773094   \n",
       "\n",
       "                                                  image   check_sum  \n",
       "0     [238, 236, 237, 238, 240, 240, 239, 241, 241, ...  3990298755  \n",
       "1     [219, 215, 204, 196, 204, 211, 212, 200, 180, ...  1359000491  \n",
       "2     [144, 142, 159, 180, 188, 188, 184, 180, 167, ...  3822334647  \n",
       "3     [193, 192, 193, 194, 194, 194, 193, 192, 168, ...  3001797594  \n",
       "4     [147, 148, 160, 196, 215, 214, 216, 217, 219, ...  2161940314  \n",
       "...                                                 ...         ...  \n",
       "7044  [71, 74, 85, 105, 116, 128, 139, 150, 170, 187...   585994373  \n",
       "7045  [60, 60, 62, 57, 55, 51, 49, 48, 50, 53, 56, 5...   191806966  \n",
       "7046  [74, 74, 74, 78, 79, 79, 79, 81, 77, 78, 80, 7...  3036254932  \n",
       "7047  [254, 254, 254, 254, 254, 238, 193, 145, 121, ...   260257816  \n",
       "7048  [53, 62, 67, 76, 86, 91, 97, 105, 105, 106, 10...  3023155920  \n",
       "\n",
       "[7049 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a copy of the train data in train_data in case you want to add columns back in from df[train]\n",
    "train_data=train.copy(deep=True)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Identification\n",
    "As we saw in the EDA, there are a variety of types of images with a variety of keypoints. Below, we will remove some of the images we saw as outliers in the EDA.\n",
    "\n",
    "Outlier types:\n",
    "- Mislabelled images\n",
    "- Weird/bad images\n",
    "- All outliers (i.e. images that contain keypoints that are greater than 3 standard deviations away from the mean for that keypoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CELL FOR JOANIE\n",
    "\n",
    "#This block is identifying and counting all outliers\n",
    "#Outliers are images that contain keypoints > 3std from mean\n",
    "def find_outliers():\n",
    "    train=train_data.drop([\"image\"],axis=1)\n",
    "    described_train=train.describe().T\n",
    "    std=described_train[\"std\"]\n",
    "    mean=described_train[\"mean\"]\n",
    "    q1=described_train[\"25%\"]\n",
    "    q3=described_train[\"75%\"]\n",
    "    iqr=q3-q1\n",
    "\n",
    "    #If we define outliers using IQR\n",
    "    #outlier_low=q1-1.5*iqr\n",
    "    #outlier_high=q3+1.5*iqr\n",
    "\n",
    "    #If we define outliers using std\n",
    "    outlier_low=mean-3*std\n",
    "    outlier_high=mean+3*std\n",
    "\n",
    "\n",
    "\n",
    "    #Keep track of these images in a list\n",
    "    outlier_images=[]\n",
    "    outlier_dict={}\n",
    "\n",
    "    #Iterate through the data to find outliers based on whether they are lower/higher than defined outlier boundaries\n",
    "    for col in train.columns:\n",
    "        indices=list(np.where((train[col] < outlier_low[col]) | (train[col] > outlier_high[col]))[0])\n",
    "        outlier_images.extend(indices)\n",
    "        for i in indices:\n",
    "            temp=outlier_dict.get(i,[])\n",
    "            temp.append(col[:-1])\n",
    "            outlier_dict[i]=temp\n",
    "\n",
    "    #Only count each index once\n",
    "    outliers=np.unique(outlier_images)\n",
    "    outliers\n",
    "    print(\"Finding points 3 standard deviations away from the mean results in \",len(outliers),\n",
    "        \"images being classified as outliers\")\n",
    "    print(\"This represents\",len(outliers)/train.shape[0]*100,\"% of our total data\")\n",
    "\n",
    "    print(train.shape)\n",
    "    \n",
    "    return outliers\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CELL FOR JOANIE\n",
    "\n",
    "#This function is removing the worst outliers\n",
    "#The worst outliers are the mislabelled images and the weird/bad images\n",
    "def drop_worst_outliers():\n",
    "\n",
    "    print(\"Before dropping worst outliers train shape is: \", train.shape)\n",
    "    print(\"Before dropping worst outliers train duplicates shape is: \", train_duplicates.shape)\n",
    "    miss_labelled = [1747, 1877, 1907,2199] #These are the images with keypoints that are not right\n",
    "    bad_images = [6492,6493,2430,3697] #These are the two collages and the two cartoons\n",
    "\n",
    "    worst_outliers = miss_labelled + bad_images\n",
    "\n",
    "    #Drop with inplace drops inplace\n",
    "    #train_data.drop(index=worst_outliers,inplace=True)\n",
    "    train.drop(index=worst_outliers,inplace=True,errors='ignore')\n",
    "    train_duplicates.drop(index=worst_outliers,inplace=True,errors='ignore')\n",
    "    print(\"After dropping worst outliers train shape is: \", train.shape)\n",
    "    print(\"After dropping worst outliers train duplicates shape is: \", train_duplicates.shape)\n",
    "\n",
    "#This function is for removing all outliers as defined above\n",
    "def drop_all_outliers():\n",
    "    print(\"Before dropping all outliers train shape is: \", train.shape)\n",
    "    print(train.shape)\n",
    "    outliers = find_outliers()\n",
    "    train.drop(index=outliers,inplace=True, errors='ignore')\n",
    "    train_duplicates.drop(index=worst_outliers,inplace=True,errors='ignore')\n",
    "    print(\"After dropping all outliers train shape is: \", train.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Code for Duplicate Data in Train and Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CELL FOR JACKIE\n",
    "# Remove duplicates in the train dataset by taking the mean of all values for that image in each label \n",
    "def remove_train_duplicates(verbose=True):\n",
    "    # First let's reset the index since we've been working on the df \n",
    "        \n",
    "    train = reset_train_df()\n",
    "    #train_duplicates.reset_index()\n",
    "\n",
    "    #Get all of the coordinates\n",
    "    coordinates = get_coordinate_columns()\n",
    "\n",
    "    #Create an empty df with the coordinate columns in place\n",
    "    final_images = train[(train.index == -1)][coordinates].copy()\n",
    "\n",
    "    #For each unique check_sum in duplicates...\n",
    "    for check_sum in train_duplicates.check_sum.unique():\n",
    "        #Get all of the duplicates with the same check_sum\n",
    "        duplicates = train_duplicates[(train_duplicates.check_sum == check_sum)]['index'].values\n",
    "        \n",
    "        #Get the first image that appears in the train dataset with this check_sum\n",
    "        image = train[(train['index'].isin(duplicates))].image.values[0]\n",
    "        #Take the mean of all the coordinate columns - this is what we will use for the final single image\n",
    "        fixed = pd.DataFrame(pd.DataFrame(train[(train['index'].isin(duplicates))], columns=coordinates).mean(axis = 0)).T\n",
    "        #Make sure to include the actual image (lol)\n",
    "        fixed['image'] = [image]\n",
    "        #Append it to the list of final_images\n",
    "        final_images = final_images.append(fixed, ignore_index = True)\n",
    "        \n",
    "        \n",
    "    #For reporting purposes: \n",
    "    if verbose: print(\"=\"*13 + \"Train\" + \"=\"*13)\n",
    "    if verbose: print(\"Before delete:     %s\" % str(train.shape))\n",
    "\n",
    "    #Remove the duplicates from train - danger, danger, must replace them\n",
    "    train = train[~(train['index'].isin(train_duplicates['index'].values))]\n",
    "    if verbose: print(\"After  delete:     %s\" % str(train.shape))\n",
    "\n",
    "    #Replace removed duplicates with final_images\n",
    "    train = train.append(final_images, ignore_index = True).reset_index()\n",
    "    train.drop(columns=['index'], inplace = True)\n",
    "    if verbose: print(\"After  append:     %s\" % str(train.shape))\n",
    "    return train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CELL FOR JACKIE\n",
    "##########Test Data set\n",
    "\n",
    "#Now do the same for test, this will be easier since we don't need\n",
    "#to deal with points and taking the mean\n",
    "def remove_test_duplicates(verbose=True):\n",
    "#We can do this differently since we don't need to take the mean. \n",
    "#Go through the test and only add items to the final test image if\n",
    "#we do not already have the check_sum. If we find the check_sum, don't\n",
    "#add it it's a duplicate. \n",
    "    test = reset_test_df()\n",
    "    if verbose: print(\"=\"*13 + \"Test=\" + \"=\"*13)\n",
    "    if verbose: print(\"Before delete:     %s\" % str(test.shape))\n",
    "    test = reset_test_df()\n",
    "    #Create an empty df with the coordinate columns in place\n",
    "    final_test_images = test[(test.index == -1)]\n",
    "    \n",
    "    for test_index, check_sum in zip(test['index'], test.check_sum):\n",
    "        if not (check_sum in list(final_test_images.check_sum.values)):\n",
    "            final_test_images = final_test_images.append(test.loc[(test['index'] == test_index)], ignore_index = True)\n",
    "    \n",
    "    if verbose: print(\"After  delete:     %s\" % str(final_test_images.shape))\n",
    "    return final_test_images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove worst outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dropping worst outliers train shape is:  (7049, 33)\n",
      "Before dropping worst outliers train duplicates shape is:  (1098, 3)\n",
      "After dropping worst outliers train shape is:  (7041, 33)\n",
      "After dropping worst outliers train duplicates shape is:  (1095, 3)\n"
     ]
    }
   ],
   "source": [
    "#CODE CELL FOR JOANIE\n",
    "#only drop the worst outliers for now\n",
    "drop_worst_outliers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying EDA fix for duplicates\n",
      "\n",
      "=============Train=============\n",
      "Before delete:     (7041, 33)\n",
      "After  delete:     (5946, 33)\n",
      "After  append:     (6488, 33)\n",
      "\n",
      "=============Test==============\n",
      "Before delete:     (1783, 4)\n",
      "After  delete:     (1752, 4)\n"
     ]
    }
   ],
   "source": [
    "#CODE CELL FOR JACKIE\n",
    "print(\"Applying EDA fix for duplicates\")\n",
    "print()\n",
    "train = remove_train_duplicates()\n",
    "print()\n",
    "test = remove_test_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Clean Data to a Pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6488, 33)\n",
      "(1752, 4)\n"
     ]
    }
   ],
   "source": [
    "#CODE CELL FOR JACKIE\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "#Pickle train and test so that we can jump in with cleaning this data\n",
    "pickle.dump( train, open( \"data/clean_train.p\", \"wb\" ) )\n",
    "pickle.dump(test, open( \"data/clean_test.p\", \"wb\" ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
