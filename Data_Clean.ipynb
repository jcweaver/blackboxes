{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# W207 Final Project : Facial Keypoint Detection \r\n",
        "# Team: Joanie Weaver, Sandip Panesar, Jackie Nichols, Rakesh Walisheter\r\n",
        "W207 Tuesday @4pm\r\n",
        "\r\n",
        "ref: https://www.kaggle.com/c/facial-keypoints-detection"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning File"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "Imports, reading in files, etc.."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "from tqdm import tqdm\n",
        "import zlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib import rc\n",
        "from matplotlib.ticker import PercentFormatter\n",
        "import pickle\n"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1615669714648
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the pickle files\n",
        "\n",
        "train = pickle.load( open( \"data/train.p\", \"rb\" ) )\n",
        "test = pickle.load( open(\"data/test.p\", \"rb\"))\n",
        "\n",
        "train.rename(columns = {'level_0' : 'index'}, inplace = True)\n",
        "\n",
        "train_duplicates = pickle.load( open(\"data/traindup.p\", \"rb\"))\n",
        "test_duplicates = pickle.load( open(\"data/testdup.p\", \"rb\"))\n",
        "\n",
        "train_duplicates.set_index('index', inplace=True, drop=False)\n",
        "print(\"Test shape is: \", test.shape)\n",
        "print(\"Train shape is: \", train.shape)\n",
        "\n",
        "print(\"Test duplicates shape is: \", test_duplicates.shape)\n",
        "print(\"Train duplicates shape is: \", train_duplicates.shape)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test shape is:  (1783, 4)\n",
            "Train shape is:  (7049, 33)\n",
            "Test duplicates shape is:  (60, 3)\n",
            "Train duplicates shape is:  (1098, 3)\n"
          ]
        }
      ],
      "execution_count": 72,
      "metadata": {
        "gather": {
          "logged": 1615673329717
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#HELPER FUNCTIONS to reset the train and test dataframes\n",
        "\n",
        "def reset_train_df():\n",
        "    #train = df['train'].reset_index().copy()\n",
        "    new_train = train.reset_index().copy()\n",
        "    #Get the images and perform a checksum on every image in train: https://www.geeksforgeeks.org/zlib-adler32-in-python/\n",
        "    new_train['check_sum'] = train.image.map(lambda x: zlib.adler32(x))\n",
        "    new_train.pop('level_0')\n",
        "    return new_train\n",
        "\n",
        "def reset_test_df():\n",
        "    #test = df['test'].reset_index().copy()\n",
        "    new_test = test.reset_index().copy()\n",
        "    #Get the images and perform a checksum on every image in train: https://www.geeksforgeeks.org/zlib-adler32-in-python/\n",
        "    new_test['check_sum'] = test.image.map(lambda x: zlib.adler32(x))\n",
        "    new_test.pop('level_0')\n",
        "    return new_test\n",
        "\n",
        "def get_coordinate_columns():\n",
        "    coordinates = [c for c in train.columns if c.endswith('_x') | c.endswith('_y')]\n",
        "    return coordinates"
      ],
      "outputs": [],
      "execution_count": 73,
      "metadata": {
        "gather": {
          "logged": 1615673340927
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a copy of the train data in train_data in case you want to add columns back in from df[train]\n",
        "train_data=train.copy(deep=True)\n",
        "train_data"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 74,
          "data": {
            "text/plain": "      index  left_eye_center_x  left_eye_center_y  right_eye_center_x  \\\n0         0          66.033562          39.002274           30.227007   \n1         1          64.332939          34.970078           29.949276   \n2         2          65.057053          34.909641           30.903790   \n3         3          65.225739          37.261772           32.023094   \n4         4          66.725304          39.621262           32.244808   \n...     ...                ...                ...                 ...   \n7044   7044          67.402550          31.842550           29.746750   \n7045   7045          66.134399          38.365501           30.478626   \n7046   7046          66.690735          36.845222           31.666420   \n7047   7047          70.965080          39.853664           30.543285   \n7048   7048          66.938309          43.424511           31.096060   \n\n      right_eye_center_y  left_eye_inner_corner_x  left_eye_inner_corner_y  \\\n0              36.421677                59.582077                39.647423   \n1              33.448715                58.856171                35.274349   \n2              34.909641                59.411999                36.320969   \n3              37.261772                60.003338                39.127178   \n4              38.042030                58.565891                39.621262   \n...                  ...                      ...                      ...   \n7044           38.632942                      NaN                      NaN   \n7045           39.950199                      NaN                      NaN   \n7046           39.685043                      NaN                      NaN   \n7047           40.772339                      NaN                      NaN   \n7048           39.528603                      NaN                      NaN   \n\n      left_eye_outer_corner_x  left_eye_outer_corner_y  \\\n0                   73.130348                39.969997   \n1                   70.722725                36.187164   \n2                   70.984421                36.320969   \n3                   72.314713                38.380966   \n4                   72.515930                39.884468   \n...                       ...                      ...   \n7044                      NaN                      NaN   \n7045                      NaN                      NaN   \n7046                      NaN                      NaN   \n7047                      NaN                      NaN   \n7048                      NaN                      NaN   \n\n      right_eye_inner_corner_x  ...  mouth_left_corner_x  mouth_left_corner_y  \\\n0                    36.356571  ...            61.195309            79.970169   \n1                    36.034725  ...            56.421448            76.351997   \n2                    37.678104  ...            60.822948            73.014313   \n3                    37.618645  ...            65.598885            72.703720   \n4                    36.982380  ...            60.671410            77.523239   \n...                        ...  ...                  ...                  ...   \n7044                       NaN  ...                  NaN                  NaN   \n7045                       NaN  ...                  NaN                  NaN   \n7046                       NaN  ...                  NaN                  NaN   \n7047                       NaN  ...                  NaN                  NaN   \n7048                       NaN  ...                  NaN                  NaN   \n\n      mouth_right_corner_x  mouth_right_corner_y  mouth_center_top_lip_x  \\\n0                28.614496             77.388992               43.312603   \n1                35.122383             76.047661               46.684597   \n2                33.726315             72.732002               47.274948   \n3                37.245495             74.195480               50.303165   \n4                31.191755             76.997299               44.962749   \n...                    ...                   ...                     ...   \n7044                   NaN                   NaN                     NaN   \n7045                   NaN                   NaN                     NaN   \n7046                   NaN                   NaN                     NaN   \n7047                   NaN                   NaN                     NaN   \n7048                   NaN                   NaN                     NaN   \n\n      mouth_center_top_lip_y  mouth_center_bottom_lip_x  \\\n0                  72.935455                  43.130707   \n1                  70.266556                  45.467915   \n2                  70.191788                  47.274948   \n3                  70.091690                  51.561184   \n4                  73.707390                  44.227142   \n...                      ...                        ...   \n7044                     NaN                  50.426636   \n7045                     NaN                  50.287395   \n7046                     NaN                  49.462570   \n7047                     NaN                  50.065186   \n7048                     NaN                  45.900478   \n\n      mouth_center_bottom_lip_y  \\\n0                     84.485771   \n1                     85.480171   \n2                     78.659370   \n3                     78.268379   \n4                     86.871162   \n...                         ...   \n7044                  79.683922   \n7045                  77.983025   \n7046                  78.117119   \n7047                  79.586449   \n7048                  82.773094   \n\n                                                  image   check_sum  \n0     [238, 236, 237, 238, 240, 240, 239, 241, 241, ...  3990298755  \n1     [219, 215, 204, 196, 204, 211, 212, 200, 180, ...  1359000491  \n2     [144, 142, 159, 180, 188, 188, 184, 180, 167, ...  3822334647  \n3     [193, 192, 193, 194, 194, 194, 193, 192, 168, ...  3001797594  \n4     [147, 148, 160, 196, 215, 214, 216, 217, 219, ...  2161940314  \n...                                                 ...         ...  \n7044  [71, 74, 85, 105, 116, 128, 139, 150, 170, 187...   585994373  \n7045  [60, 60, 62, 57, 55, 51, 49, 48, 50, 53, 56, 5...   191806966  \n7046  [74, 74, 74, 78, 79, 79, 79, 81, 77, 78, 80, 7...  3036254932  \n7047  [254, 254, 254, 254, 254, 238, 193, 145, 121, ...   260257816  \n7048  [53, 62, 67, 76, 86, 91, 97, 105, 105, 106, 10...  3023155920  \n\n[7049 rows x 33 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>left_eye_center_x</th>\n      <th>left_eye_center_y</th>\n      <th>right_eye_center_x</th>\n      <th>right_eye_center_y</th>\n      <th>left_eye_inner_corner_x</th>\n      <th>left_eye_inner_corner_y</th>\n      <th>left_eye_outer_corner_x</th>\n      <th>left_eye_outer_corner_y</th>\n      <th>right_eye_inner_corner_x</th>\n      <th>...</th>\n      <th>mouth_left_corner_x</th>\n      <th>mouth_left_corner_y</th>\n      <th>mouth_right_corner_x</th>\n      <th>mouth_right_corner_y</th>\n      <th>mouth_center_top_lip_x</th>\n      <th>mouth_center_top_lip_y</th>\n      <th>mouth_center_bottom_lip_x</th>\n      <th>mouth_center_bottom_lip_y</th>\n      <th>image</th>\n      <th>check_sum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>66.033562</td>\n      <td>39.002274</td>\n      <td>30.227007</td>\n      <td>36.421677</td>\n      <td>59.582077</td>\n      <td>39.647423</td>\n      <td>73.130348</td>\n      <td>39.969997</td>\n      <td>36.356571</td>\n      <td>...</td>\n      <td>61.195309</td>\n      <td>79.970169</td>\n      <td>28.614496</td>\n      <td>77.388992</td>\n      <td>43.312603</td>\n      <td>72.935455</td>\n      <td>43.130707</td>\n      <td>84.485771</td>\n      <td>[238, 236, 237, 238, 240, 240, 239, 241, 241, ...</td>\n      <td>3990298755</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>64.332939</td>\n      <td>34.970078</td>\n      <td>29.949276</td>\n      <td>33.448715</td>\n      <td>58.856171</td>\n      <td>35.274349</td>\n      <td>70.722725</td>\n      <td>36.187164</td>\n      <td>36.034725</td>\n      <td>...</td>\n      <td>56.421448</td>\n      <td>76.351997</td>\n      <td>35.122383</td>\n      <td>76.047661</td>\n      <td>46.684597</td>\n      <td>70.266556</td>\n      <td>45.467915</td>\n      <td>85.480171</td>\n      <td>[219, 215, 204, 196, 204, 211, 212, 200, 180, ...</td>\n      <td>1359000491</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>65.057053</td>\n      <td>34.909641</td>\n      <td>30.903790</td>\n      <td>34.909641</td>\n      <td>59.411999</td>\n      <td>36.320969</td>\n      <td>70.984421</td>\n      <td>36.320969</td>\n      <td>37.678104</td>\n      <td>...</td>\n      <td>60.822948</td>\n      <td>73.014313</td>\n      <td>33.726315</td>\n      <td>72.732002</td>\n      <td>47.274948</td>\n      <td>70.191788</td>\n      <td>47.274948</td>\n      <td>78.659370</td>\n      <td>[144, 142, 159, 180, 188, 188, 184, 180, 167, ...</td>\n      <td>3822334647</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>65.225739</td>\n      <td>37.261772</td>\n      <td>32.023094</td>\n      <td>37.261772</td>\n      <td>60.003338</td>\n      <td>39.127178</td>\n      <td>72.314713</td>\n      <td>38.380966</td>\n      <td>37.618645</td>\n      <td>...</td>\n      <td>65.598885</td>\n      <td>72.703720</td>\n      <td>37.245495</td>\n      <td>74.195480</td>\n      <td>50.303165</td>\n      <td>70.091690</td>\n      <td>51.561184</td>\n      <td>78.268379</td>\n      <td>[193, 192, 193, 194, 194, 194, 193, 192, 168, ...</td>\n      <td>3001797594</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>66.725304</td>\n      <td>39.621262</td>\n      <td>32.244808</td>\n      <td>38.042030</td>\n      <td>58.565891</td>\n      <td>39.621262</td>\n      <td>72.515930</td>\n      <td>39.884468</td>\n      <td>36.982380</td>\n      <td>...</td>\n      <td>60.671410</td>\n      <td>77.523239</td>\n      <td>31.191755</td>\n      <td>76.997299</td>\n      <td>44.962749</td>\n      <td>73.707390</td>\n      <td>44.227142</td>\n      <td>86.871162</td>\n      <td>[147, 148, 160, 196, 215, 214, 216, 217, 219, ...</td>\n      <td>2161940314</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7044</th>\n      <td>7044</td>\n      <td>67.402550</td>\n      <td>31.842550</td>\n      <td>29.746750</td>\n      <td>38.632942</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>50.426636</td>\n      <td>79.683922</td>\n      <td>[71, 74, 85, 105, 116, 128, 139, 150, 170, 187...</td>\n      <td>585994373</td>\n    </tr>\n    <tr>\n      <th>7045</th>\n      <td>7045</td>\n      <td>66.134399</td>\n      <td>38.365501</td>\n      <td>30.478626</td>\n      <td>39.950199</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>50.287395</td>\n      <td>77.983025</td>\n      <td>[60, 60, 62, 57, 55, 51, 49, 48, 50, 53, 56, 5...</td>\n      <td>191806966</td>\n    </tr>\n    <tr>\n      <th>7046</th>\n      <td>7046</td>\n      <td>66.690735</td>\n      <td>36.845222</td>\n      <td>31.666420</td>\n      <td>39.685043</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>49.462570</td>\n      <td>78.117119</td>\n      <td>[74, 74, 74, 78, 79, 79, 79, 81, 77, 78, 80, 7...</td>\n      <td>3036254932</td>\n    </tr>\n    <tr>\n      <th>7047</th>\n      <td>7047</td>\n      <td>70.965080</td>\n      <td>39.853664</td>\n      <td>30.543285</td>\n      <td>40.772339</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>50.065186</td>\n      <td>79.586449</td>\n      <td>[254, 254, 254, 254, 254, 238, 193, 145, 121, ...</td>\n      <td>260257816</td>\n    </tr>\n    <tr>\n      <th>7048</th>\n      <td>7048</td>\n      <td>66.938309</td>\n      <td>43.424511</td>\n      <td>31.096060</td>\n      <td>39.528603</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>45.900478</td>\n      <td>82.773094</td>\n      <td>[53, 62, 67, 76, 86, 91, 97, 105, 105, 106, 10...</td>\n      <td>3023155920</td>\n    </tr>\n  </tbody>\n</table>\n<p>7049 rows Ã— 33 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 74,
      "metadata": {
        "gather": {
          "logged": 1615673344152
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Outlier Identification\n",
        "As we saw in the EDA, there are a variety of types of images with a variety of keypoints. Below, we will remove some of the images we saw as outliers in the EDA.\n",
        "\n",
        "Outlier types:\n",
        "- Mislabelled images\n",
        "- Weird/bad images\n",
        "- All outliers (i.e. images that contain keypoints that are greater than 3 standard deviations away from the mean for that keypoint)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#CODE CELL FOR JOANIE\n",
        "\n",
        "#This block is identifying and counting all outliers\n",
        "#Outliers are images that contain keypoints > 3std from mean\n",
        "def find_outliers():\n",
        "    train=train_data.drop([\"image\"],axis=1)\n",
        "    described_train=train.describe().T\n",
        "    std=described_train[\"std\"]\n",
        "    mean=described_train[\"mean\"]\n",
        "    q1=described_train[\"25%\"]\n",
        "    q3=described_train[\"75%\"]\n",
        "    iqr=q3-q1\n",
        "\n",
        "    #If we define outliers using IQR\n",
        "    #outlier_low=q1-1.5*iqr\n",
        "    #outlier_high=q3+1.5*iqr\n",
        "\n",
        "    #If we define outliers using std\n",
        "    outlier_low=mean-3*std\n",
        "    outlier_high=mean+3*std\n",
        "\n",
        "\n",
        "\n",
        "    #Keep track of these images in a list\n",
        "    outlier_images=[]\n",
        "    outlier_dict={}\n",
        "\n",
        "    #Iterate through the data to find outliers based on whether they are lower/higher than defined outlier boundaries\n",
        "    for col in train.columns:\n",
        "        indices=list(np.where((train[col] < outlier_low[col]) | (train[col] > outlier_high[col]))[0])\n",
        "        outlier_images.extend(indices)\n",
        "        for i in indices:\n",
        "            temp=outlier_dict.get(i,[])\n",
        "            temp.append(col[:-1])\n",
        "            outlier_dict[i]=temp\n",
        "\n",
        "    #Only count each index once\n",
        "    outliers=np.unique(outlier_images)\n",
        "    outliers\n",
        "    print(\"Finding points 3 standard deviations away from the mean results in \",len(outliers),\n",
        "        \"images being classified as outliers\")\n",
        "    print(\"This represents\",len(outliers)/train.shape[0]*100,\"% of our total data\")\n",
        "\n",
        "    #print(train.shape)\n",
        "    \n",
        "    return outliers\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 75,
      "metadata": {
        "gather": {
          "logged": 1615673350812
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CODE CELL FOR JOANIE\n",
        "\n",
        "#This function is removing the worst outliers\n",
        "#The worst outliers are the mislabelled images and the weird/bad images\n",
        "def drop_worst_outliers():\n",
        "\n",
        "    print(\"Before dropping worst outliers train shape is: \", train.shape)\n",
        "    print(\"Before dropping worst outliers train duplicates shape is: \", train_duplicates.shape)\n",
        "    miss_labelled = [1747, 1877, 1907,2199] #These are the images with keypoints that are not right\n",
        "    bad_images = [6492,6493,2430,3697] #These are the two collages and the two cartoons\n",
        "\n",
        "    worst_outliers = miss_labelled + bad_images\n",
        "\n",
        "    #Drop with inplace drops inplace\n",
        "    #train_data.drop(index=worst_outliers,inplace=True)\n",
        "    train.drop(index=worst_outliers,inplace=True,errors='ignore')\n",
        "    train_duplicates.drop(index=worst_outliers,inplace=True,errors='ignore')\n",
        "    print(\"After dropping worst outliers train shape is: \", train.shape)\n",
        "    print(\"After dropping worst outliers train duplicates shape is: \", train_duplicates.shape)\n",
        "\n",
        "#This function is for removing all outliers as defined above\n",
        "def drop_all_outliers():\n",
        "    print(\"Before dropping all outliers train shape is: \", train.shape)\n",
        "    print(\"Before dropping all outliers train duplicates shape is: \", train_duplicates.shape)\n",
        "    \n",
        "    outliers = find_outliers()\n",
        "    overlap = [bad for bad in outliers if bad in train_duplicates.index]\n",
        "\n",
        "    train.drop(index=outliers,inplace=True, errors='ignore')\n",
        "    #Drop the overlap outliers and duplicates\n",
        "    train_duplicates.drop(index=overlap,inplace=True,errors='ignore')\n",
        "    print(\"After dropping all outliers train shape is: \", train.shape)\n",
        "    print(\"After dropping all outliers train duplicates shape is: \", train_duplicates.shape)\n",
        "\n",
        "def drop_overlap_outliers():\n",
        "    print(\"Before dropping overlap outliers train shape is: \", train.shape)\n",
        "    print(\"Before dropping overlap outliers train duplicates shape is: \", train_duplicates.shape)\n",
        "    \n",
        "    outliers = find_outliers()\n",
        "    overlap = [bad for bad in outliers if bad in train_duplicates.index]\n",
        "\n",
        "    print(\"There are\", len( overlap), \" images that are outliers that appear in train duplicates\")\n",
        "    \n",
        "    train.drop(index=overlap,inplace=True, errors='ignore')\n",
        "    #Drop the overlap outliers and duplicates\n",
        "    train_duplicates.drop(index=overlap,inplace=True,errors='ignore')\n",
        "    print(\"After dropping overlap outliers train shape is: \", train.shape)\n",
        "    print(\"After dropping overlap outliers train duplicates shape is: \", train_duplicates.shape)\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 76,
      "metadata": {
        "gather": {
          "logged": 1615673354984
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Code for Duplicate Data in Train and Test datasets"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#CODE CELL FOR JACKIE\n",
        "# Remove duplicates in the train dataset by taking the mean of all values for that image in each label \n",
        "def remove_train_duplicates( train_duplicates,verbose=True):\n",
        "    # First let's reset the index since we've been working on the df \n",
        "        \n",
        "    train = reset_train_df()\n",
        "    #train_duplicates.reset_index()\n",
        "\n",
        "    #Get all of the coordinates\n",
        "    coordinates = get_coordinate_columns()\n",
        "\n",
        "    #Create an empty df with the coordinate columns in place\n",
        "    final_images = train[(train.index == -1)][coordinates].copy()\n",
        "    final_check_sum = train_duplicates.check_sum.unique()\n",
        "\n",
        "    #For each unique check_sum in duplicates...\n",
        "    for check_sum in train_duplicates.check_sum.unique():\n",
        "        #Get all of the duplicates with the same check_sum\n",
        "        duplicates = train_duplicates[(train_duplicates.check_sum == check_sum)]['index'].values\n",
        "        \n",
        "        #Get the first image that appears in the train dataset with this check_sum\n",
        "        image = train[(train['index'].isin(duplicates))].image.values[0]\n",
        "        #Take the mean of all the coordinate columns - this is what we will use for the final single image\n",
        "        fixed = pd.DataFrame(pd.DataFrame(train[(train['index'].isin(duplicates))], columns=coordinates).mean(axis = 0)).T\n",
        "        #Make sure to include the actual image (lol)\n",
        "        fixed['image'] = [image]\n",
        "        #Append it to the list of final_images\n",
        "        final_images = final_images.append(fixed, ignore_index = True)\n",
        "        \n",
        "        \n",
        "        \n",
        "    #For reporting purposes: \n",
        "    if verbose: print(\"=\"*13 + \"Train\" + \"=\"*13)\n",
        "    if verbose: print(\"Before delete:     %s\" % str(train.shape))\n",
        "\n",
        "    #Remove the duplicates from train - danger, danger, must replace them\n",
        "    train = train[~(train['index'].isin(train_duplicates['index'].values))]\n",
        "    if verbose: print(\"After  delete:     %s\" % str(train.shape))\n",
        "\n",
        "    #Dump the final images that were duplicates so we can take a look at them after the processing. \n",
        "    pickle.dump(final_check_sum, open( \"data/final_check_sum.p\", \"wb\" ) )\n",
        " \n",
        "\n",
        "    #Replace removed duplicates with final_images\n",
        "    train = train.append(final_images, ignore_index = True).reset_index()\n",
        "    train.drop(columns=['index'], inplace = True)\n",
        "    if verbose: print(\"After  append:     %s\" % str(train.shape))\n",
        "    return train\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 85,
      "metadata": {
        "gather": {
          "logged": 1615673670438
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CODE CELL FOR JACKIE\n",
        "##########Test Data set\n",
        "\n",
        "#Now do the same for test, this will be easier since we don't need\n",
        "#to deal with points and taking the mean\n",
        "def remove_test_duplicates(verbose=True):\n",
        "#We can do this differently since we don't need to take the mean. \n",
        "#Go through the test and only add items to the final test image if\n",
        "#we do not already have the check_sum. If we find the check_sum, don't\n",
        "#add it it's a duplicate. \n",
        "    test = reset_test_df()\n",
        "    if verbose: print(\"=\"*13 + \"Test=\" + \"=\"*13)\n",
        "    if verbose: print(\"Before delete:     %s\" % str(test.shape))\n",
        "    test = reset_test_df()\n",
        "    #Create an empty df with the coordinate columns in place\n",
        "    final_test_images = test[(test.index == -1)]\n",
        "    \n",
        "    for test_index, check_sum in zip(test['index'], test.check_sum):\n",
        "        if not (check_sum in list(final_test_images.check_sum.values)):\n",
        "            final_test_images = final_test_images.append(test.loc[(test['index'] == test_index)], ignore_index = True)\n",
        "    \n",
        "    if verbose: print(\"After  delete:     %s\" % str(final_test_images.shape))\n",
        "    return final_test_images\n"
      ],
      "outputs": [],
      "execution_count": 78,
      "metadata": {
        "gather": {
          "logged": 1615673389959
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove worst outliers"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#CODE CELL FOR JOANIE\n",
        "#only drop the worst outliers for now\n",
        "#drop_worst_outliers()\n",
        "\n",
        "drop_overlap_outliers()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before dropping overlap outliers train shape is:  (7049, 33)\n",
            "Before dropping overlap outliers train duplicates shape is:  (1098, 3)\n",
            "Finding points 3 standard deviations away from the mean results in  409 images being classified as outliers\n",
            "This represents 5.802241452688325 % of our total data\n",
            "There are 29  images that are outliers that appear in train duplicates\n",
            "After dropping overlap outliers train shape is:  (7020, 33)\n",
            "After dropping overlap outliers train duplicates shape is:  (1069, 3)\n"
          ]
        }
      ],
      "execution_count": 79,
      "metadata": {
        "gather": {
          "logged": 1615673394948
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove duplicates"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#CODE CELL FOR JACKIE\n",
        "print(\"Applying EDA fix for duplicates\")\n",
        "print()\n",
        "train = remove_train_duplicates(train_duplicates)\n",
        "print()\n",
        "test = remove_test_duplicates()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying EDA fix for duplicates\n",
            "\n",
            "=============Train=============\n",
            "Before delete:     (7020, 33)\n",
            "After  delete:     (5951, 33)\n",
            "After  append:     (6483, 33)\n",
            "\n",
            "=============Test==============\n",
            "Before delete:     (1783, 4)\n",
            "After  delete:     (1752, 4)\n"
          ]
        }
      ],
      "execution_count": 86,
      "metadata": {
        "gather": {
          "logged": 1615673683856
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Clean Data to a Pickle file"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#CODE CELL FOR JACKIE\n",
        "print(train.shape)\n",
        "print(test.shape)\n",
        "#Pickle train and test so that we can jump in with cleaning this data\n",
        "pickle.dump( train, open( \"data/clean_train.p\", \"wb\" ) )\n",
        "pickle.dump(test, open( \"data/clean_test.p\", \"wb\" ))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6483, 33)\n",
            "(1752, 4)\n"
          ]
        }
      ],
      "execution_count": 38,
      "metadata": {
        "gather": {
          "logged": 1615671049893
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_duplicates.shape)\r\n",
        "#Load the fixed images from the duplication process\r\n",
        "fixed_images = pickle.load( open( \"data/final_check_sum.p\", \"rb\" ) )\r\n",
        "print(fixed_images.shape)\r\n",
        "print(fixed_images)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1069, 3)\n",
            "(532,)\n",
            "[2227719099 1759475250 3225265811 2501495581 2039551639  263535868\n",
            " 4267325263 4238875132 4238381626 4229913460 4227403669 4206228168\n",
            " 4193943220 4179463428 4175292717 4171737335 4167988278 4161621162\n",
            " 4159437731 4156810575 4120323984 4106322975 4104472597 4097744695\n",
            " 4092999084 4092226262 4087266659 4077195328 4072546378 4071379171\n",
            " 4070187275 4064607896 4054608955 4038618488 4037167896 4029527387\n",
            " 4026442209 4025211595 4017893982 4005944034 3997490547 3992979985\n",
            " 3984808463 3967776129 3956794385 3950830325 3949931077 3940392213\n",
            " 3934391535 3930611777 3922222526 3908145108 3903347068 3878421787\n",
            " 3861889972 3861537195 3842434619 3835683269 3834388347 3832545311\n",
            " 3831959508 3828544714 3827134289 3809728175 3793953353 3793487658\n",
            " 3782788908 3769737153 3763057871 3758662479 3755877745 3747518398\n",
            " 3736589863 3704497029 3690743813 3681196529 3671575594 3669771141\n",
            " 3668161122 3661496059 3642849837 3627039688 3609390935 3590236302\n",
            " 3579279731 3577270086 3577121019 3563131119 3558687752 3557822640\n",
            " 3554242438 3548498340 3547211334 3546451986 3545885504 3542455436\n",
            " 3542018218 3537019460 3534932979 3530683742 3524655282 3516963789\n",
            " 3516257866 3515959960 3515104247 3488754790 3479991559 3472481556\n",
            " 3471315946 3439270828 3439106671 3429387810 3428958777 3422178405\n",
            " 3416925528 3414439288 3410487119 3408891320 3404824477 3399660184\n",
            " 3397102043 3384457782 3384114599 3383066278 3375895105 3364154828\n",
            " 3352249523 3335428070 3334428022 3332438931 3326426588 3315761147\n",
            " 3313976080 3312625720 3305011793 3291670642 3286487041 3266179915\n",
            " 3261555521 3255990710 3254351254 3236651544 3233102854 3225855577\n",
            " 3218503929 3209285651 3199124514 3183843703 3179806185 3165700602\n",
            " 3146401865 3144683432 3136001751 3125204612 3107724557 3084672527\n",
            " 3072144898 3068006200 3058682079 3058413827 3055417213 3053666658\n",
            " 3041357691 3023155920 3022166438 3010972472 3009478797 2999444461\n",
            " 2994989990 2992013064 2982111884 2975036654 2970670564 2959462119\n",
            " 2958478965 2945023451 2942202224 2923262272 2911908222 2911509936\n",
            " 2909983440 2893470430 2884200160 2871480214 2865602484 2847092149\n",
            " 2845825199 2837958215 2828996108 2795300671 2775432734 2769651145\n",
            " 2766469475 2763913658 2759292602 2739445037 2692157708 2690647381\n",
            " 2684278732 2653398449 2652929099 2638331261 2635998627 2619936711\n",
            " 2618057382 2613595284 2603438939 2603393458 2597298104 2597168148\n",
            " 2573615434 2573192058 2564328041 2534429582 2503129380 2502587718\n",
            " 2500558659 2487257177 2485298668 2478149911 2477320410 2463678423\n",
            " 2463054912 2448526053 2416480991 2411339545 2401574371 2400081234\n",
            " 2388370437 2376233769 2366093838 2360099922 2357679222 2343215151\n",
            " 2331897931 2331804309 2312943556 2308957061 2308127891 2306565191\n",
            " 2298295177 2287924651 2279018895 2258735058 2251207923 2222096962\n",
            " 2215414937 2203665256 2171438233 2170942362 2162727154 2152875774\n",
            " 2150747203 2148093170 2140430313 2126670492 2120793022 2108564820\n",
            " 2105310596 2096325469 2080785888 2074615560 2072786203 2068025003\n",
            " 2038093363 2030967440 2019004029 2014106575 2011488231 2002141826\n",
            " 1999799036 1992891251 1987876724 1985683703 1976013841 1959541064\n",
            " 1954277848 1936224954 1930326151 1929620165 1918836582 1916482220\n",
            " 1908340819 1906241501 1904734121 1904054195 1896715719 1890750013\n",
            " 1877133104 1874541468 1871577207 1862483778 1857147314 1844818401\n",
            " 1842769816 1832694743 1823420841 1807472308 1802776869 1798465640\n",
            " 1766769190 1765889042 1758427675 1748150414 1747454180 1745432404\n",
            " 1743960357 1734587624 1730091576 1728253551 1727102707 1718534086\n",
            " 1716532850 1711148795 1707172257 1696789505 1694263632 1693896374\n",
            " 1639672603 1634878637 1634761148 1618085798 1616241086 1611534222\n",
            " 1595084735 1590858079 1573187272 1562855888 1546777085 1536304875\n",
            " 1505821040 1498972022 1493137325 1492249608 1492109439 1479042592\n",
            " 1475001972 1473072618 1468886785 1468769369 1463212358 1455142193\n",
            " 1441195397 1440017956 1411525601 1411078671 1407225054 1401221629\n",
            " 1392575667 1392213177 1387393659 1380244461 1374950792 1370870380\n",
            " 1368489444 1361959369 1361763216 1353766712 1349596311 1345852944\n",
            " 1327838738 1325368204 1323286722 1318502986 1312438112 1277258476\n",
            " 1274594410 1274538199 1272523013 1267843798 1250566249 1240772040\n",
            " 1237413439 1235542508 1233744375 1233283394 1231955389 1231893210\n",
            " 1228318971 1219843628 1215025846 1210029414 1208247133 1190445699\n",
            " 1187283626 1181797740 1173960034 1172100946 1170176407 1164679701\n",
            " 1145562062 1137216806 1133749495 1126384783 1122350906 1110603795\n",
            " 1106550899 1092447985 1091759931 1087804928 1086371489 1085733756\n",
            " 1083134857 1055513358 1052359822 1037810220 1036028224 1035758946\n",
            " 1034119421 1031500931 1023789057 1017418652 1000623621  995629308\n",
            "  977500424  965958625  951718946  947157849  937489132  932125347\n",
            "  908322562  906857870  899460979  885025422  882337986  866198585\n",
            "  859304213  844749712  833176005  832631455  831842174  829308491\n",
            "  828611515  814188271  813896315  800009195  797940360  784974947\n",
            "  783621881  775610381  768194219  758609025  748138665  741314582\n",
            "  732810254  718258826  710154688  705954213  702083693  701037212\n",
            "  686025275  675698894  674433761  671777776  671192785  661468219\n",
            "  661132610  656282209  641371163  632920983  630836054  615885532\n",
            "  602144094  595247377  593187224  585994373  585344237  583338586\n",
            "  577627892  574034962  570304319  559199998  552787337  534043759\n",
            "  533649562  521141904  518943669  513979634  504303010  502937602\n",
            "  496705337  485278958  470821552  461961256  459224649  417785658\n",
            "  407962985  401504308  395189811  390170224  379700921  359200243\n",
            "  356665092  351618990  344619254  344120913  325161852  324091987\n",
            "  318139453  311995886  310864759  301309178  294294516  288878313\n",
            "  280532367  267684046  256883173  246851569  226618245  205176159\n",
            "  205066433  191806966  188005127  160583347  160075377  152564576\n",
            "  125571698  115902256  105153118  102254077   80557202   69562877\n",
            "   67493046   63736848   54846201   40648654   34493184   34299674\n",
            "   22568820   21965156    7439125    5518700]\n"
          ]
        }
      ],
      "execution_count": 87,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615673735440
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Print clean images:\r\n",
        "\r\n",
        "def show_fixed_images(fixed_images):\r\n",
        "    ## TRAIN \r\n",
        "    # Let's view some of these duplicated train images\r\n",
        "    fig = plt.figure(figsize=(18,18))\r\n",
        "    fig.suptitle('Sample of duplicate images from the Train dataset\\n n= ??', size = 20,  y = 1.04, weight = 'bold')\r\n",
        "    #Get the point coordinates for example: mouth_center_top_lip_x\r\n",
        "    coordinates = get_coordinate_columns()\r\n",
        "    #print(coordinates)\r\n",
        "    \r\n",
        "\r\n",
        "    match_pts = pd.DataFrame(columns =['Points_Found', 'Count'])\r\n",
        "\r\n",
        "    #For each unique check_sum in duplicates...\r\n",
        "    for i, check_sum in enumerate (fixed_images):\r\n",
        "        plt.subplot(1297,5,i+1)   \r\n",
        "        img = train[(train['check_sum'] == check_sum)].image.values[0].reshape(96,96)\r\n",
        "        #These are the points that have been identified on the images\r\n",
        "        points = train[(train['check_sum'] == check_sum)][coordinates].values[0]\r\n",
        "        train[(train['check_sum'] == check_sum)]\r\n",
        "        plt.imshow(img, cmap = 'gray')\r\n",
        "        plt.axis('off')\r\n",
        "        matching_pts = 0         \r\n",
        "        #Get the first image that appears in the train dataset with this check_sum\r\n",
        "        for pts in range(0, 30, 2):\r\n",
        "            x_point, y_point = (points[pts], points[pts+1])\r\n",
        "            if not (np.isnan(x_point)) and not (np.isnan(y_point)):\r\n",
        "                matching_pts += 1\r\n",
        "                #Add the point to the plot\r\n",
        "                plt.plot(x_point, y_point, 'o', color = \"red\", markersize = 5)\r\n",
        "\r\n",
        "        plt.title(\"Image #:[%d]\\n#Points:[%d]\" % (idx, matching_pts))\r\n",
        "        if matching_pts in match_pts[\"Points_Found\"].values:\r\n",
        "                match_pts.loc[match_pts['Points_Found'] == matching_pts, 'Count'] = match_pts.loc[match_pts['Points_Found'] == matching_pts, 'Count'] + 1\r\n",
        "        else:\r\n",
        "            match_pts = match_pts.append({'Points_Found':matching_pts,'Count': 1},ignore_index=True)\r\n",
        "\r\n",
        "        plt.title(\"Image #:[%d]\\n#Points:[%d]\" % (idx, matching_pts))\r\n",
        "        if matching_pts in match_pts[\"Points_Found\"].values:\r\n",
        "                match_pts.loc[match_pts['Points_Found'] == matching_pts, 'Count'] = match_pts.loc[match_pts['Points_Found'] == matching_pts, 'Count'] + 1\r\n",
        "        else:\r\n",
        "            match_pts = match_pts.append({'Points_Found':matching_pts,'Count': 1},ignore_index=True)\r\n",
        "\r\n",
        "\r\n",
        "    plt.tight_layout()\r\n",
        "    plt.show()"
      ],
      "outputs": [],
      "execution_count": 88,
      "metadata": {
        "gather": {
          "logged": 1615673819617
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show_fixed_images(fixed_images)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'idx' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-57710b77379a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_fixed_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfixed_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-88-854a645ca56d>\u001b[0m in \u001b[0;36mshow_fixed_images\u001b[0;34m(fixed_images)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_point\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_point\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'o'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"red\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarkersize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image #:[%d]\\n#Points:[%d]\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatching_pts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmatching_pts\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmatch_pts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Points_Found\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mmatch_pts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmatch_pts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Points_Found'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmatching_pts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Count'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch_pts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmatch_pts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Points_Found'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmatching_pts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Count'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'idx' is not defined"
          ]
        }
      ],
      "execution_count": 90,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615671676096
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.index)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RangeIndex(start=0, stop=6483, step=1)\n"
          ]
        }
      ],
      "execution_count": 93,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615673999133
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}