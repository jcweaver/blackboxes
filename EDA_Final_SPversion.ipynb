{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1614473345343
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "from tqdm import tqdm\n",
    "import zlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import rc\n",
    "from matplotlib.ticker import PercentFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1614473347869
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INSTALLED VERSIONS\n",
      "------------------\n",
      "commit           : None\n",
      "python           : 3.7.7.final.0\n",
      "python-bits      : 64\n",
      "OS               : Darwin\n",
      "OS-release       : 19.6.0\n",
      "machine          : x86_64\n",
      "processor        : i386\n",
      "byteorder        : little\n",
      "LC_ALL           : en_US.UTF-8\n",
      "LANG             : en_US.UTF-8\n",
      "LOCALE           : en_US.UTF-8\n",
      "\n",
      "pandas           : 1.0.3\n",
      "numpy            : 1.18.1\n",
      "pytz             : 2020.1\n",
      "dateutil         : 2.8.1\n",
      "pip              : 20.0.2\n",
      "setuptools       : 47.1.1.post20200604\n",
      "Cython           : 0.29.17\n",
      "pytest           : 5.4.2\n",
      "hypothesis       : 5.11.0\n",
      "sphinx           : 3.0.4\n",
      "blosc            : None\n",
      "feather          : None\n",
      "xlsxwriter       : 1.2.8\n",
      "lxml.etree       : 4.5.0\n",
      "html5lib         : 1.0.1\n",
      "pymysql          : None\n",
      "psycopg2         : None\n",
      "jinja2           : 2.11.2\n",
      "IPython          : 7.13.0\n",
      "pandas_datareader: None\n",
      "bs4              : 4.8.2\n",
      "bottleneck       : 1.3.2\n",
      "fastparquet      : None\n",
      "gcsfs            : None\n",
      "lxml.etree       : 4.5.0\n",
      "matplotlib       : 3.1.3\n",
      "numexpr          : 2.7.1\n",
      "odfpy            : None\n",
      "openpyxl         : 3.0.3\n",
      "pandas_gbq       : None\n",
      "pyarrow          : None\n",
      "pytables         : None\n",
      "pytest           : 5.4.2\n",
      "pyxlsb           : None\n",
      "s3fs             : None\n",
      "scipy            : 1.4.1\n",
      "sqlalchemy       : 1.3.17\n",
      "tables           : 3.6.1\n",
      "tabulate         : None\n",
      "xarray           : None\n",
      "xlrd             : 1.2.0\n",
      "xlwt             : 1.3.0\n",
      "xlsxwriter       : 1.2.8\n",
      "numba            : 0.49.1\n"
     ]
    }
   ],
   "source": [
    "pd.show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data For EDA\n",
    "There are 4 files found in the data directory:\n",
    "\n",
    "- IdLookupTable - TBD\n",
    "- SampleSubmission - TBD\n",
    "- test - TBD\n",
    "- training - TBD \n",
    "\n",
    "We must load this data in order to perform EDA.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "gather": {
     "logged": 1614473383715
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load files.\n",
      "Begin loading file 'https://github.com/jcweaver/blackboxes/tree/master/datatest.csv' \n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-84aeaa29831f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Begin loading file '%s' \"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgit_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m#print(file_ref)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_ref\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgit_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m#If the file contains an image column like in the case of test.csv store those images now.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;31m# See https://github.com/python/mypy/issues/1297\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     fp_or_buf, _, compression, should_close = get_filepath_or_buffer(\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m     )\n\u001b[1;32m    433\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Content-Encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"gzip\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 641\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "\n",
    "#https://realpython.com/python-zip-function/#:~:text=%20Using%20the%20Python%20zip%20()%20Function%20for,zip%20()%20function%20works%20differently%20in...%20More\n",
    "\n",
    "df, git_path = {}, 'data/'\n",
    "for file_name, file_ref, n, t in zip(['test.csv', 'training.csv', 'IdLookupTable.csv', 'SampleSubmission.csv'],\n",
    "                        ['test', 'train', 'id_lookup', 'sample_submission', ],\n",
    "                        [   #test\n",
    "                            ['image_id', 'image'], \n",
    "                            #train\n",
    "                            ['left_eye_center_x', 'left_eye_center_y',  \n",
    "                            'right_eye_center_x', 'right_eye_center_y', \n",
    "                            'left_eye_inner_corner_x', 'left_eye_inner_corner_y', \n",
    "                            'left_eye_outer_corner_x', 'left_eye_outer_corner_y', \n",
    "                            'right_eye_inner_corner_x', 'right_eye_inner_corner_y', \n",
    "                            'right_eye_outer_corner_x', 'right_eye_outer_corner_y', \n",
    "                            'left_eyebrow_inner_end_x', 'left_eyebrow_inner_end_y', \n",
    "                            'left_eyebrow_outer_end_x', 'left_eyebrow_outer_end_y', \n",
    "                            'right_eyebrow_inner_end_x', 'right_eyebrow_inner_end_y', \n",
    "                            'right_eyebrow_outer_end_x', 'right_eyebrow_outer_end_y', \n",
    "                            'nose_tip_x', 'nose_tip_y', \n",
    "                            'mouth_left_corner_x', 'mouth_left_corner_y', \n",
    "                            'mouth_right_corner_x', 'mouth_right_corner_y', \n",
    "                            'mouth_center_top_lip_x', 'mouth_center_top_lip_y', \n",
    "                            'mouth_center_bottom_lip_x', 'mouth_center_bottom_lip_y', 'image'],\n",
    "                            #IdLookupTable\n",
    "                            ['row_id', 'image_id', 'feature_name', 'location'],\n",
    "                            #SampleSubmission\n",
    "                            ['row_id', 'location']\n",
    "                        ],\n",
    "\n",
    "                        [\n",
    "                             #test   \n",
    "                            {'image_id':'uint16', 'image':'object'},\n",
    "                            #train\n",
    "                            {'left_eye_center_x':'float32', 'left_eye_center_y':'float32', \n",
    "                            'right_eye_center_x':'float32', 'right_eye_center_y':'float32', \n",
    "                            'left_eye_inner_corner_x':'float32', 'left_eye_inner_corner_y':'float32', \n",
    "                            'left_eye_outer_corner_x':'float32', 'left_eye_outer_corner_y':'float32', \n",
    "                            'right_eye_inner_corner_x':'float32', 'right_eye_inner_corner_y':'float32',\n",
    "                            'right_eye_outer_corner_x':'float32', 'right_eye_outer_corner_y':'float32', \n",
    "                            'left_eyebrow_inner_end_x':'float32', 'left_eyebrow_inner_end_y':'float32',\n",
    "                            'left_eyebrow_outer_end_x':'float32', 'left_eyebrow_outer_end_y':'float32', \n",
    "                            'right_eyebrow_inner_end_x':'float32', 'right_eyebrow_inner_end_y':'float32',\n",
    "                            'right_eyebrow_outer_end_x':'float32', 'right_eyebrow_outer_end_y':'float32', \n",
    "                            'nose_tip_x':'float32', 'nose_tip_y':'float32', 'mouth_left_corner_x':'float32',\n",
    "                            'mouth_left_corner_y':'float32', 'mouth_right_corner_x':'float32', \n",
    "                            'mouth_right_corner_y':'float32', 'mouth_center_top_lip_x':'float32', \n",
    "                            'mouth_center_top_lip_y':'float32','mouth_center_bottom_lip_x':'float32', \n",
    "                            'mouth_center_bottom_lip_y':'float32', 'image':'object'},\n",
    "                             #IdLookupTable\n",
    "                            {'row_id':'uint16', 'image_id':'uint16', 'location':'float32'},\n",
    "                            #SampleSubmission\n",
    "                            {'row_id':'uint16', 'location':'float32'}\n",
    "                        ],\n",
    "                        ):\n",
    "    #This is the begining of the for loop for each file:\n",
    "    print(\"Load files.\")\n",
    "    print(\"Begin loading file '%s' \" % \"\".join( (git_path, file_name)))\n",
    "    #print(file_ref)\n",
    "    df[file_ref] = pd.read_csv(\"\".join( (git_path,file_name) ), names = n, dtype = t, skiprows = 1)\n",
    "    \n",
    "    #If the file contains an image column like in the case of test.csv store those images now. \n",
    "    if \"image\" in df[file_ref]:\n",
    "        print(\"\\tFound %d images. Processing. \" % df[file_ref].shape[0])\n",
    "        #Get the row with the image data and store it in the dataframe \n",
    "        df[file_ref]['image'] = df[file_ref][\"image\"].map(lambda x: np.array(list(map(int, x.split(\" \")))))\n",
    "    print(\"\\tFile\", file_ref, \" with shape:\", df[file_ref].shape, \" load complete\\n\")\n",
    "\n",
    "print(\"Load files complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1614473624022
    }
   },
   "outputs": [],
   "source": [
    "train, test = df['train'][['image']], df['test'][['image']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1614473627155
    }
   },
   "outputs": [],
   "source": [
    "# Check for duplicate train images\n",
    "train = df['train'].reset_index().copy()\n",
    "#Get the images and perform a checksum on every image in train: https://www.geeksforgeeks.org/zlib-adler32-in-python/\n",
    "train['check_sum'] = train.image.map(lambda x: zlib.adler32(x))\n",
    "\n",
    "#Create a DF to store duplicates, grouping them together and sorting them\n",
    "train_duplicates = pd.DataFrame(train.groupby(by='check_sum').index.count().sort_values()).reset_index()\n",
    "#Add a column to keep track of how many of each check sum there are\n",
    "train_duplicates.columns = ['check_sum', 'number_found']\n",
    "#Keep the ones where we have > 1 number_found\n",
    "train_duplicates = train_duplicates[(train_duplicates.number_found > 1)]\n",
    "#Now do a left outer join back to train_duplicates.  This should only keep the duplicates \n",
    "# https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html#:~:text=merge%20is%20a%20function%20in%20the%20pandas%20namespace,,the%20index-on-index%20(by%20default)%20and%20column%20(s)-on-index%20join.\n",
    "train_duplicates = pd.merge(train_duplicates, train[['index', 'check_sum']],  how = 'left', on=['check_sum']).sort_values(by=['number_found', 'check_sum'], ascending = False)\n",
    "\n",
    "\n",
    "#Now do the same for test:\n",
    "# Check for duplicate train images\n",
    "test = df['test'].reset_index().copy()\n",
    "#Get the images and perform a checksum on every image in train: https://www.geeksforgeeks.org/zlib-adler32-in-python/\n",
    "test['check_sum'] = test.image.map(lambda x: zlib.adler32(x))\n",
    "#Create a DF to store duplicates, grouping them together and sorting them\n",
    "test_duplicates = pd.DataFrame(test.groupby(by='check_sum').index.count().sort_values()).reset_index()\n",
    "#Add a column to keep track of how many of each check sum there are\n",
    "test_duplicates.columns = ['check_sum', 'number_found']\n",
    "#Keep the ones where we have > 1 number_found\n",
    "test_duplicates = test_duplicates[(test_duplicates.number_found > 1)]\n",
    "#Now do a left outer join back to train_duplicates.  This should only keep the duplicates \n",
    "# https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html#:~:text=merge%20is%20a%20function%20in%20the%20pandas%20namespace,,the%20index-on-index%20(by%20default)%20and%20column%20(s)-on-index%20join.\n",
    "test_duplicates = pd.merge(test_duplicates, test[['index', 'check_sum']],  how = 'left', on=['check_sum']).sort_values(by=['number_found', 'check_sum'], ascending = False)\n",
    "\n",
    "print(\"EDA on duplicate data in train and test datasets: \")\n",
    "print(\"The train dataset has %d unique images out of the %d duplicate images from the total of %d images\" % (len(np.unique(train_duplicates.check_sum)), len(train_duplicates), train.size))\n",
    "print(\"The test dataset has %d unique images out of %d duplicate images from the total of %d images\" % (len(np.unique(test_duplicates.check_sum)),len(test_duplicates), test.size))\n",
    "\n",
    "#Clean up:\n",
    "#We don't really need the check_sum column anymore...so drop it\n",
    "train.drop(columns=['check_sum'], inplace=True)\n",
    "test.drop(columns=['check_sum'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1614473630874
    }
   },
   "outputs": [],
   "source": [
    "print(train.size)\n",
    "print(train_duplicates.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1614473635241
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "## TRAIN \n",
    "# Let's view some of these duplicated train images\n",
    "fig = plt.figure(figsize=(18,18))\n",
    "fig.suptitle('Sample of duplicate images from the Train dataset\\n n= 35', size = 20,  y = 1.04, weight = 'bold')\n",
    "#Get the point coordinates for example: mouth_center_top_lip_x\n",
    "coordinates = [c for c in train.columns if c.endswith('_x') | c.endswith('_y')]\n",
    "#print(coordinates)\n",
    "#Get the top 35 duplicate images\n",
    "idx = train_duplicates.head(35)['index'].values\n",
    "#For testing, these are the duplicate ID's\n",
    "print(idx)\n",
    "\n",
    "match_pts = pd.DataFrame(columns =['Points_Found', 'Count'])\n",
    "\n",
    "#Loop through and plot each of the 35 images.  \n",
    "for i, idx in enumerate(idx):\n",
    "    plt.subplot(7,5,i+1)\n",
    "    img = train[(train['index'] == idx)].image.values[0].reshape(96,96)\n",
    "    #These are the points that have been identified on the images\n",
    "    points = train[(train['index'] == idx)][coordinates].values[0]\n",
    "    plt.imshow(img, cmap = 'gray')\n",
    "    plt.axis('off')\n",
    "    matching_pts = 0\n",
    "\n",
    "    for pts in range(0, 30, 2):\n",
    "        x_point, y_point = (points[pts], points[pts+1])\n",
    "        if not (np.isnan(x_point)) and not (np.isnan(y_point)):\n",
    "            matching_pts += 1\n",
    "            #Add the point to the plot\n",
    "            plt.plot(x_point, y_point, 'o', color = \"red\", markersize = 5)\n",
    "\n",
    "    plt.title(\"Image #:[%d]\\n#Points:[%d]\" % (idx, matching_pts))\n",
    "    if matching_pts in match_pts[\"Points_Found\"].values:\n",
    "            match_pts.loc[match_pts['Points_Found'] == matching_pts, 'Count'] = match_pts.loc[match_pts['Points_Found'] == matching_pts, 'Count'] + 1\n",
    "    else:\n",
    "        match_pts = match_pts.append({'Points_Found':matching_pts,'Count': 1},ignore_index=True)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1614473641847
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = train_duplicates['index'].values\n",
    "#For testing, these are the duplicate ID's\n",
    "print(idx)\n",
    "match_pts = pd.DataFrame(columns =['Points_Found', 'Count'])\n",
    "coordinates = [c for c in train.columns if c.endswith('_x') | c.endswith('_y')]\n",
    "#Loop through and plot each of the 35 images.  \n",
    "for i, idx in enumerate(idx):\n",
    "    img = train[(train['index'] == idx)].image.values[0].reshape(96,96)\n",
    "    #These are the points that have been identified on the images\n",
    "    points = train[(train['index'] == idx)][coordinates].values[0]\n",
    "    matching_pts = 0\n",
    "\n",
    "    for pts in range(0, 30, 2):\n",
    "        x_point, y_point = (points[pts], points[pts+1])\n",
    "        if not (np.isnan(x_point)) and not (np.isnan(y_point)):\n",
    "            matching_pts += 1\n",
    "            \n",
    "    if matching_pts in match_pts[\"Points_Found\"].values:\n",
    "            match_pts.loc[match_pts['Points_Found'] == matching_pts, 'Count'] = match_pts.loc[match_pts['Points_Found'] == matching_pts, 'Count'] + 1\n",
    "            \n",
    "    else:\n",
    "        match_pts = match_pts.append({'Points_Found': matching_pts,'Count': 1},ignore_index=True)\n",
    "        \n",
    "print(match_pts)\n",
    "\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.set_title('Number of Points Found on Train Duplicate Data', fontsize = 20, fontweight = 'bold')\n",
    "ax.bar(match_pts.Points_Found, match_pts.Count, width = 1.7)\n",
    "ax.set_xticks(range(0,18,1))\n",
    "for i, r in match_pts.iterrows():\n",
    "    plt.text(r.Points_Found, r.Count + 25, format(r.Count, \",d\"), \n",
    "        horizontalalignment = 'center', verticalalignment = 'center', fontweight ='bold')\n",
    "ax.spines[\"top\"].set_alpha(.0)\n",
    "ax.spines[\"bottom\"].set_alpha(.3)\n",
    "ax.spines[\"right\"].set_alpha(.0)\n",
    "ax.spines[\"left\"].set_alpha(.0)\n",
    "ax.set_xlabel(\"Number Of Points Found On Image\", fontsize = 12, horizontalalignment='center')\n",
    "ax.set_ylabel(\"Number of Duplicate Train Images\", fontsize = 12, horizontalalignment='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1614473646017
    }
   },
   "outputs": [],
   "source": [
    "print(train_duplicates.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1614473685710
    }
   },
   "outputs": [],
   "source": [
    "#Do the duplicate Train images have the same labels? Let's test one out. \n",
    "\n",
    "#Get only the first images checksum from duplicate train and then get the images that match the check_sum\n",
    "duplicate_image_chksum = train_duplicates.iloc[0, train_duplicates.columns.get_loc('check_sum')] \n",
    "\n",
    "duplicate_image_index = train_duplicates.loc[(train_duplicates.check_sum == duplicate_image_chksum)]['index'].values\n",
    "\n",
    "#Create an array of all of the coumns with x,y in them\n",
    "coordinate_columns = [c for c in train.columns if c.endswith('_x') | c.endswith('_y')]\n",
    "\n",
    "#Get the df so we can display something meaningful\n",
    "duplicate_image_df = train.loc[(train['index'].isin(duplicate_image_index))][coordinate_columns]\n",
    "\n",
    "#https://mode.com/example-gallery/python_dataframe_styling/\n",
    "duplicate_image_df.style\\\n",
    "    .highlight_max(subset=coordinate_columns,color='green')\\\n",
    "    .set_na_rep(\"N/A\").format(None, na_rep=\"Missing\")\\\n",
    "    .highlight_null('yellow')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1614473696107
    }
   },
   "outputs": [],
   "source": [
    "#The lables do not match exactly in the duplicate Train images.  The challenge would be to determine which of the images to keep if we remove all but one of the duplicate images. We have two options:\n",
    "\n",
    "#1 - Keep the first duplicate and disregard the others - Easy to do, low cost but we risk losing data.\n",
    "#2 - Take the average for all coordiantes across the duplicate image and apply those coordinates moving forward. A little more work invovled and risk of introducing more errors to the lables. \n",
    "\n",
    "#If we were to do #2 this is how the above image would reconcile:\n",
    "#Take the mean of the columns and create a new DF\n",
    "duplicate_image_df = pd.DataFrame(train.loc[(train['index'].isin(duplicate_image_index))][coordinate_columns].mean())\n",
    "\n",
    "#Display results\n",
    "duplicate_image_df.T.style\\\n",
    "    .set_na_rep(\"N/A\").format(None, na_rep=\"Missing\")\\\n",
    "    .highlight_null('yellow')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dataset Duplicate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1614473702097
    }
   },
   "outputs": [],
   "source": [
    "test = df['test'].reset_index().copy()\n",
    "print(test.size)\n",
    "print(test_duplicates.size)\n",
    "print(test.size/test_duplicates.size, \"% of test data is duplicates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gather": {
     "logged": 1614473706915
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_duplicates' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-83937eb718cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#Get the top 35 duplicate images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_duplicates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m#For testing, these are the duplicate ID's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_duplicates' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1296 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## TEST \n",
    "# Let's view some of these duplicated train images\n",
    "fig = plt.figure(figsize=(18,18))\n",
    "fig.suptitle('Sample of duplicate images from the Test dataset\\n n= 35', size = 20,  y = 1.04, weight = 'bold')\n",
    "#Get the point coordinates for example: mouth_center_top_lip_x\n",
    "\n",
    "#Get the top 35 duplicate images\n",
    "idx = test_duplicates.head(35)['index'].values\n",
    "#For testing, these are the duplicate ID's\n",
    "print(idx)\n",
    "\n",
    "#Loop through and plot each of the 35 images.  \n",
    "for i, idx in enumerate(idx):\n",
    "    plt.subplot(7,5,i+1)\n",
    "    img = test[(test['index'] == idx)].image.values[0].reshape(96,96)\n",
    "    plt.imshow(img, cmap = 'gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Image #:[%d]\" % (idx))\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplication Conclusions -EDA on duplicate data in train and test datasets:\n",
    "Train:\n",
    "\n",
    "1. The train dataset has 543 unique images out of the 1098 duplicate images from the total of 232617 images\n",
    "\n",
    "2. Of the 1098 duplicate images:\n",
    "    - 1096 of them had 4 points\n",
    "    - 1 had  13 points\n",
    "    - 1 had 15 points\n",
    "\n",
    "Test:\n",
    "\n",
    "1. The test dataset has 29 unique images out of 60 duplicate images from the total of 7132 images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3536571a9bc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
